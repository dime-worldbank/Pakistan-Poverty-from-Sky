{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poverty Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_NAME = \"DHS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import json\n",
    "#import rasterio\n",
    "#from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (BaggingClassifier, AdaBoostClassifier,\n",
    "                              AdaBoostRegressor,\n",
    "                              GradientBoostingClassifier, RandomForestClassifier,\n",
    "                              RandomForestRegressor,\n",
    "                             BaggingRegressor, GradientBoostingRegressor)\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, \n",
    "                             recall_score, classification_report,\n",
    "                            r2_score, mean_absolute_error, mean_squared_error)\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import logging, os \n",
    "\n",
    "import grid_params as grids\n",
    "import config as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = os.path.join(cf.DROPBOX_DIRECTORY, 'data', SURVEY_NAME, 'FinalData', 'pov_estimation_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robmarty/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (47,51,54,57,58,59,61) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(cf.DROPBOX_DIRECTORY, 'data', SURVEY_NAME, \"FinalData\", \"Merged Datasets\", \"survey_alldata_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gadm_uid</th>\n",
       "      <th>uid</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_year</th>\n",
       "      <th>urban_rural</th>\n",
       "      <th>year</th>\n",
       "      <th>most_recent_survey</th>\n",
       "      <th>educ_years_hh_max</th>\n",
       "      <th>educ_years_hh_mean</th>\n",
       "      <th>water_time_to_get</th>\n",
       "      <th>...</th>\n",
       "      <th>osm_dist_track</th>\n",
       "      <th>osm_dist_path</th>\n",
       "      <th>osm_length_all_5000m</th>\n",
       "      <th>osm_N_segments_any_5000m</th>\n",
       "      <th>osm_dist_any</th>\n",
       "      <th>iso2</th>\n",
       "      <th>continent</th>\n",
       "      <th>un_region</th>\n",
       "      <th>un_subregion</th>\n",
       "      <th>continent_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AL201700000001</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL_2017-18_DHS_09092021_165_82518</td>\n",
       "      <td>U</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>15.291667</td>\n",
       "      <td>10.859722</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>117.344652</td>\n",
       "      <td>54.112282</td>\n",
       "      <td>347461.146812</td>\n",
       "      <td>1104</td>\n",
       "      <td>22.714830</td>\n",
       "      <td>AL</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Eurasia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AL201700000002</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL_2017-18_DHS_09092021_165_82518</td>\n",
       "      <td>U</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>14.318182</td>\n",
       "      <td>12.049242</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>15.875410</td>\n",
       "      <td>1062.050826</td>\n",
       "      <td>316750.367862</td>\n",
       "      <td>1021</td>\n",
       "      <td>15.875410</td>\n",
       "      <td>AL</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Eurasia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>AL201700000003</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL_2017-18_DHS_09092021_165_82518</td>\n",
       "      <td>U</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>14.823529</td>\n",
       "      <td>10.858824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>146.705601</td>\n",
       "      <td>2.501082</td>\n",
       "      <td>314586.631326</td>\n",
       "      <td>1028</td>\n",
       "      <td>2.501082</td>\n",
       "      <td>AL</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Eurasia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AL201700000004</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL_2017-18_DHS_09092021_165_82518</td>\n",
       "      <td>U</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>10.215575</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>300.303562</td>\n",
       "      <td>652.519259</td>\n",
       "      <td>319270.394940</td>\n",
       "      <td>1029</td>\n",
       "      <td>30.081477</td>\n",
       "      <td>AL</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Eurasia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AL201700000005</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL_2017-18_DHS_09092021_165_82518</td>\n",
       "      <td>U</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.084314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>108.278757</td>\n",
       "      <td>19.394781</td>\n",
       "      <td>347761.488908</td>\n",
       "      <td>1099</td>\n",
       "      <td>19.394781</td>\n",
       "      <td>AL</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Eurasia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gadm_uid             uid country_code                       country_year  \\\n",
       "0         1  AL201700000001           AL  AL_2017-18_DHS_09092021_165_82518   \n",
       "1         1  AL201700000002           AL  AL_2017-18_DHS_09092021_165_82518   \n",
       "2         1  AL201700000003           AL  AL_2017-18_DHS_09092021_165_82518   \n",
       "3         1  AL201700000004           AL  AL_2017-18_DHS_09092021_165_82518   \n",
       "4         1  AL201700000005           AL  AL_2017-18_DHS_09092021_165_82518   \n",
       "\n",
       "  urban_rural  year  most_recent_survey  educ_years_hh_max  \\\n",
       "0           U  2017                True          15.291667   \n",
       "1           U  2017                True          14.318182   \n",
       "2           U  2017                True          14.823529   \n",
       "3           U  2017                True          13.875000   \n",
       "4           U  2017                True          16.000000   \n",
       "\n",
       "   educ_years_hh_mean  water_time_to_get  ...  osm_dist_track  osm_dist_path  \\\n",
       "0           10.859722           1.250000  ...      117.344652      54.112282   \n",
       "1           12.049242           1.363636  ...       15.875410    1062.050826   \n",
       "2           10.858824           0.000000  ...      146.705601       2.501082   \n",
       "3           10.215575           0.416667  ...      300.303562     652.519259   \n",
       "4           14.084314           0.000000  ...      108.278757      19.394781   \n",
       "\n",
       "   osm_length_all_5000m  osm_N_segments_any_5000m  osm_dist_any  iso2  \\\n",
       "0         347461.146812                      1104     22.714830    AL   \n",
       "1         316750.367862                      1021     15.875410    AL   \n",
       "2         314586.631326                      1028      2.501082    AL   \n",
       "3         319270.394940                      1029     30.081477    AL   \n",
       "4         347761.488908                      1099     19.394781    AL   \n",
       "\n",
       "   continent  un_region     un_subregion  continent_adj  \n",
       "0     Europe     Europe  Southern Europe        Eurasia  \n",
       "1     Europe     Europe  Southern Europe        Eurasia  \n",
       "2     Europe     Europe  Southern Europe        Eurasia  \n",
       "3     Europe     Europe  Southern Europe        Eurasia  \n",
       "4     Europe     Europe  Southern Europe        Eurasia  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#df = df[df.country_code != 'IA']\n",
    "#df = df[df.country_code != 'TL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel_valresult(df, country, est_type, target, parameters, feature_type):\n",
    "    # DESCRIPTION: Estimate poverty for a specific country, feature set and \n",
    "    # poverty variable across a number of parameters\n",
    "    # ARGS:\n",
    "    # df: Dataframe\n",
    "    # country: iso2\n",
    "    # est_type: within_country or other_countries\n",
    "    # target: dependent variable to predict\n",
    "    # feature_type: features to use\n",
    "\n",
    "    # Within country prediction; predict across folds within a country\n",
    "    if est_type == 'within_country_cv':\n",
    "        df_traintest = df[df.country_code == country]\n",
    "        df_traintest.reset_index()\n",
    "        \n",
    "        df_traintest['fold'] = df_traintest['within_country_fold']\n",
    "    else:\n",
    "        df['fold'] = 'fold_1'\n",
    "        \n",
    "    # Train model on all countries except country i; predict on country i\n",
    "    if est_type == 'global_country_pred':\n",
    "        df_traintest = df\n",
    "        df_traintest.reset_index()\n",
    "    \n",
    "    # Train model on all countries in a continent, except country i; predict\n",
    "    # on country x\n",
    "    if est_type == 'continent_africa_country_pred':\n",
    "        df_traintest = df[(df.country_code == country) | (df.continent_adj == 'Africa')]\n",
    "        df_traintest.reset_index()\n",
    "        \n",
    "    if est_type == 'continent_americas_country_pred':\n",
    "        df_traintest = df[(df.country_code == country) | (df.continent_adj == 'Americas')]\n",
    "        df_traintest.reset_index()\n",
    "        \n",
    "    if est_type == 'continent_eurasia_country_pred':\n",
    "        df_traintest = df[(df.country_code == country) | (df.continent_adj == 'Eurasia')]\n",
    "        df_traintest.reset_index()\n",
    "        \n",
    "    # Train on all countries in continent x and predict on countries in continent y\n",
    "    if est_type == 'continent':\n",
    "        df_traintest = df\n",
    "        df['fold'] = df['continent_adj']\n",
    "           \n",
    "    # Initialize results and predictions dataframes\n",
    "    results_df = pd.DataFrame() # results iterating over params\n",
    "    \n",
    "    y_df = df_traintest[['uid', 'country_code']]\n",
    "    y_df = y_df.copy()\n",
    "    y_df['y'] = df_traintest[target]\n",
    "    #y_df['y'] = df_traintest.loc[:, (target)]\n",
    "    y_df['target'] = target\n",
    "    y_df['feature_type'] = feature_type\n",
    "    y_df['est_type'] = est_type\n",
    "    \n",
    "    model_i = 0\n",
    "    for i in parameters['regressors']:\n",
    "        for j in parameters[i]:\n",
    "            \n",
    "            pred_dict = {\n",
    "                'regressor': i,\n",
    "                'params': j,\n",
    "                'country': country,\n",
    "                'est_type': est_type,\n",
    "                'target': target,\n",
    "                'model_i': model_i,\n",
    "                'feature_type': feature_type\n",
    "             }\n",
    "\n",
    "            fold = 0\n",
    "            y_df_parami = pd.DataFrame()\n",
    "            for split_id in df_traintest.fold.unique():\n",
    "                \n",
    "                #### Separate into train and test\n",
    "                if 'country_pred' in est_type:\n",
    "                    df_train = df_traintest[df_traintest.country_code != country]\n",
    "                    df_test = df_traintest[df_traintest.country_code == country]\n",
    "                elif est_type == 'continent':\n",
    "                    df_train = df_traintest[df_traintest['fold'] == split_id]\n",
    "                    df_test = df_traintest[df_traintest['fold'] != split_id]\n",
    "                else:\n",
    "                    df_train = df_traintest[df_traintest['fold'] != split_id]\n",
    "                    df_test = df_traintest[df_traintest['fold'] == split_id]\n",
    "\n",
    "                #### Select features\n",
    "                if (feature_type == \"fb\"):\n",
    "                    x_train = df_train.filter(regex='^fb_', axis=1)\n",
    "                    x_test = df_test.filter(regex='^fb_', axis=1)\n",
    "                    \n",
    "                if (feature_type == \"osm\"):\n",
    "                    x_train = df_train.filter(regex='^osm_', axis=1)\n",
    "                    x_test = df_test.filter(regex='^osm_', axis=1)\n",
    "                    \n",
    "                if (feature_type == \"l8\"):\n",
    "                    x_train = df_train.filter(regex='^l8_', axis=1)\n",
    "                    x_test = df_test.filter(regex='^l8_', axis=1)\n",
    "                    \n",
    "                if (feature_type == \"l8_viirs\"):\n",
    "                    x_train = df_train.filter(regex='^l8_|^viirs_', axis=1)\n",
    "                    x_test = df_test.filter(regex='^l8_|^viirs_', axis=1)\n",
    "                    \n",
    "                if (feature_type == \"all\"):\n",
    "                    x_train = df_train.filter(regex ='^fb_|^l8_|^viirs_|^osm_|^worldpop_', axis=1)\n",
    "                    x_test  = df_test.filter(regex  ='^fb_|^l8_|^viirs_|^osm_|^worldpop_', axis=1)\n",
    "                    \n",
    "                #### Prep Y Data\n",
    "                y_train = df_train[target]\n",
    "                y_test = df_test[target]\n",
    "\n",
    "                #### Prep X Data: Normalize\n",
    "                x_scaler = StandardScaler().fit(x_train)\n",
    "\n",
    "                x_train = x_scaler.transform(x_train)\n",
    "                x_test = x_scaler.transform(x_test)\n",
    "\n",
    "                ### Initialize regressor, fit data, then append model to list\n",
    "                regressor = eval(i)(**j)\n",
    "                trained = regressor.fit(x_train, y_train)\n",
    "\n",
    "                ### Results\n",
    "                y_pred = trained.predict(x_test)\n",
    "                \n",
    "                pred_dict['r2_score_' + str(split_id)] = r2_score(y_test, y_pred)\n",
    "                \n",
    "                y_dict_foldi = {\n",
    "                    'uid': df_test.uid\n",
    "                 }\n",
    "                y_dict_foldi['y_' + str(model_i)] = y_pred\n",
    "                \n",
    "                y_df_foldi = pd.DataFrame.from_dict(y_dict_foldi)\n",
    "                y_df_parami = y_df_parami.append(y_df_foldi, ignore_index=True)\n",
    "\n",
    "                fold += 1\n",
    "\n",
    "            y_df = y_df.merge(y_df_parami, on = 'uid', how = 'right')\n",
    "            y_df.to_csv(os.path.join(OUT_DIR, 'country_withincv',\n",
    "                               'withincv_predicted_values_' + \n",
    "                               country + '_' +\n",
    "                               est_type + '_' +\n",
    "                               feature_type + '_' +\n",
    "                               target + \n",
    "                               '_fbonly.csv'))\n",
    "                \n",
    "            results_df = results_df.append(pred_dict, ignore_index=True)\n",
    "            results_df.to_csv(os.path.join(OUT_DIR, 'country_withincv',\n",
    "                                           'withincv_results_' + \n",
    "                                           country + '_' +\n",
    "                                           est_type + '_' +\n",
    "                                           feature_type + '_' +\n",
    "                                           target + \n",
    "                                           '_fbonly.csv'))\n",
    "            model_i += 1\n",
    "        \n",
    "    return results_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = grids.GRID_REGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osm // continent // AL // pca_allvars\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n",
      "b\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b5056e6c1974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# Run ML Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresults_df_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainmodel_valresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_type_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_type_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m# Grab results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d2bbcc4762ca>\u001b[0m in \u001b[0;36mtrainmodel_valresult\u001b[0;34m(df, country, est_type, target, parameters, feature_type)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m### Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mpred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r2_score_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 delayed_query(\n\u001b[1;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             )\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_all_df = pd.DataFrame()\n",
    "y_all_df = pd.DataFrame()\n",
    "\n",
    "# 'fb', 'osm', 'l8', 'l8_viirs', 'all'\n",
    "for feature_type_i in ['osm']:\n",
    "    for est_type_i in ['continent', 'continent_americas_country_pred', 'within_country_cv']:\n",
    "        for cc_i in df.country_code.unique():\n",
    "            for target in ['pca_allvars']: # 'wealth_index_score'\n",
    "                      \n",
    "                # For predicting country i using continent x, only use\n",
    "                # other countries in the continent.\n",
    "                if est_type_i == 'continent_africa_country_pred':\n",
    "                    continent_i = df.continent_adj[df.country_code == cc_i].tolist()[0]\n",
    "                    if continent_i != 'Africa':\n",
    "                        continue\n",
    "                        \n",
    "                if est_type_i == 'continent_americas_country_pred':\n",
    "                    continent_i = df.continent_adj[df.country_code == cc_i].tolist()[0]\n",
    "                    if continent_i != 'Americas':\n",
    "                        continue\n",
    "                        \n",
    "                if est_type_i == 'continent_eurasia_country_pred':\n",
    "                    continent_i = df.continent_adj[df.country_code == cc_i].tolist()[0]\n",
    "                    if continent_i != 'Eurasia':\n",
    "                        continue\n",
    "                        \n",
    "                # Only need to run 'continent' once\n",
    "                if est_type_i == 'continent':\n",
    "                    if cc_i != 'AL':\n",
    "                        continue\n",
    "                \n",
    "                # Print where at\n",
    "                print(feature_type_i + ' // ' + est_type_i + ' // ' + cc_i + ' // ' + target)\n",
    "\n",
    "                # Run ML Model\n",
    "                results_df_i, y_df_i = trainmodel_valresult(df, cc_i, est_type_i, target, parameters, feature_type_i)\n",
    "\n",
    "                # Grab results\n",
    "                results_all_df = results_all_df.append(results_df_i, ignore_index=True)\n",
    "                y_all_df = y_all_df.append(y_df_i, ignore_index=True)\n",
    "                \n",
    "                # Export CSVs; replace as process more models\n",
    "                results_all_df.to_csv(os.path.join(OUT_DIR, 'results_fbonly_withincv.csv'))\n",
    "                y_all_df.to_csv(os.path.join(OUT_DIR, 'ypred_fbonly_withincv.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_df.to_csv(os.path.join(OUT_DIR, 'results_fbonly_withincv.csv'))\n",
    "y_all_df.to_csv(os.path.join(OUT_DIR, 'ypred_fbonly_withincv.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_type = 'hello_country_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'country_pred' in est_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
