{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict household income from satellite imagery data\n",
    "\n",
    "First pass.\n",
    "\n",
    "General ML pipeline steps:\n",
    "1. Import data\n",
    "2. Split data into test/train sets\n",
    "3. Preprocess test/train sets separately\n",
    "4. Generate features from data\n",
    "5. For each regressor-hyperparameter combination:\n",
    "    - Train regressor with given hyperparameters and training data and labels\n",
    "    - Generate predicted labels for test data with trained regressor\n",
    "    - Evaluate regressor-hyperparameter performance against actual test labels and get $R^2$\n",
    "6. Explore best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import configuration file\n",
    "import config as cf\n",
    "\n",
    "# Display options \n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = -1\n",
    "\n",
    "# Turn off big pink warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data file path \n",
    "final_data_file_path = \"/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/FinalData\"\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test grid to make sure everything works - limited models and parameters\n",
    "# 'BaggingClassifier'\n",
    "\n",
    "GRID_TEST_CLASS = {\n",
    "    'regressors': ['AdaBoostClassifier',\n",
    "                   'KNeighborsClassifier', \n",
    "                   'RandomForestClassifier', \n",
    "                   'GradientBoostingClassifier', \n",
    "                   'LinearSVC',\n",
    "                   'SVC', \n",
    "                   'DecisionTreeClassifier'],\n",
    "    'KNeighborsClassifier': [\n",
    "        {'n_neighbors': n_neighbors} \\\n",
    "        for n_neighbors in (2,5,10,15,) \n",
    "    ],\n",
    "    'LinearSVC': [\n",
    "        {'penalty': penalty, 'C': C, 'loss': loss, 'max_iter': max_iter,\n",
    "        'random_state': 0} \\\n",
    "        for penalty in ('l2', ) \\\n",
    "        for C in (1e-2,1,2) \\\n",
    "        for loss in ('epsilon_insensitive','squared_hinge', ) \\\n",
    "        for max_iter in (1e1, )\n",
    "    ],\n",
    "    'SVC': [\n",
    "        {'kernel': kernel, 'C': C, 'class_weight': class_weight,         \n",
    "        'random_state': 0} \\\n",
    "        for C in (1e-2,1,2) \\\n",
    "        for class_weight in (None, 'balanced',) \\\n",
    "        for kernel in ('linear','poly','rbf','sigmoid', ) \\\n",
    "    ],\n",
    "    'DecisionTreeClassifier': [\n",
    "        {'criterion': criterion, 'splitter': splitter, 'max_depth': max_depth,\n",
    "        'max_features': max_features, 'random_state': 0} \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for splitter in ('best', ) \\\n",
    "        for max_depth in (1,2,3,4, 5, 10, 20, 30, 50, 70, 100, ) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ],\n",
    "    'BaggingClassifier': [\n",
    "        {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "        'random_state': 0, 'n_jobs': -1} \\\n",
    "        for n_estimators in (10, 50, 100, 1000,) \\\n",
    "        for max_features in (0.1, 0.2, 0.3,0.4, 0.5, 1.0,)\n",
    "    ],\n",
    "    'AdaBoostClassifier': [\n",
    "        {'n_estimators': n_estimators, \n",
    "         'base_estimator': base_estimator,\n",
    "        'random_state': 0} \\\n",
    "        for n_estimators in (5, 10, 50, 100) \\\n",
    "        for base_estimator in (None, \n",
    "                                DecisionTreeClassifier(max_depth=2), \n",
    "                                DecisionTreeClassifier(max_depth=5))\n",
    "    ],\n",
    "    'RandomForestClassifier': [\n",
    "        {'n_estimators': n_estimators, 'criterion': criterion,\n",
    "        'max_depth': max_depth, 'max_features': max_features, 'n_jobs': -1,\n",
    "        'random_state': 0} \\\n",
    "        for n_estimators in (5, 10, 100, 1000, 5000) \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for max_depth in (1,2,3,4,5,6,7,8,9,10, ) \\\n",
    "        for max_features in ('sqrt','log2',None, )\n",
    "    ],\n",
    "    'GradientBoostingClassifier': [\n",
    "        {'loss': loss, 'learning_rate': rate, 'n_estimators': n_estimators,\n",
    "        'criterion': criterion, 'max_features': max_features,\n",
    "        'random_state': 0} \\\n",
    "        for loss in ('deviance', ) \\\n",
    "        for rate in (1e-4, )\n",
    "        for n_estimators in (100, ) \\\n",
    "        for criterion in ('friedman_mse', ) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data and drop \"future\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4528, 502)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Predict Changes\n",
    "#DATA_PATH = os.path.join(final_data_file_path, 'BISP','Merged Datasets', 'bisp_socioeconomic_satellite_firstdiff_r13.csv')\n",
    "#DATA_PATH = os.path.join('/Users/robmarty/Desktop/', 'bisp_socioeconomic_satellite_firstdiff_r13.csv')\n",
    "\n",
    "#### Predict Levels\n",
    "DATA_PATH = os.path.join(final_data_file_path, 'BISP','Merged Datasets', 'bisp_socioeconomic_satellite_panel_full_satPovNAsRemoved_1hh.csv')\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>survey_round</th>\n",
       "      <th>province</th>\n",
       "      <th>psu</th>\n",
       "      <th>locality</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>panel</th>\n",
       "      <th>present11</th>\n",
       "      <th>present13</th>\n",
       "      <th>present16</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>income_last_month_N_NAs</th>\n",
       "      <th>income_last_month</th>\n",
       "      <th>income_last_year_N_NAs</th>\n",
       "      <th>income_last_year</th>\n",
       "      <th>pscores</th>\n",
       "      <th>year</th>\n",
       "      <th>b1_buff_0.1km_mean</th>\n",
       "      <th>b2_buff_0.1km_mean</th>\n",
       "      <th>b3_buff_0.1km_mean</th>\n",
       "      <th>b4_buff_0.1km_mean</th>\n",
       "      <th>b5_buff_0.1km_mean</th>\n",
       "      <th>b6_buff_0.1km_mean</th>\n",
       "      <th>b7_buff_0.1km_mean</th>\n",
       "      <th>b12_buff_0.1km_mean</th>\n",
       "      <th>b13_buff_0.1km_mean</th>\n",
       "      <th>b14_buff_0.1km_mean</th>\n",
       "      <th>b15_buff_0.1km_mean</th>\n",
       "      <th>b16_buff_0.1km_mean</th>\n",
       "      <th>b17_buff_0.1km_mean</th>\n",
       "      <th>b23_buff_0.1km_mean</th>\n",
       "      <th>b24_buff_0.1km_mean</th>\n",
       "      <th>b25_buff_0.1km_mean</th>\n",
       "      <th>b26_buff_0.1km_mean</th>\n",
       "      <th>b27_buff_0.1km_mean</th>\n",
       "      <th>b34_buff_0.1km_mean</th>\n",
       "      <th>b35_buff_0.1km_mean</th>\n",
       "      <th>b36_buff_0.1km_mean</th>\n",
       "      <th>b37_buff_0.1km_mean</th>\n",
       "      <th>b45_buff_0.1km_mean</th>\n",
       "      <th>b46_buff_0.1km_mean</th>\n",
       "      <th>b47_buff_0.1km_mean</th>\n",
       "      <th>b56_buff_0.1km_mean</th>\n",
       "      <th>b57_buff_0.1km_mean</th>\n",
       "      <th>b67_buff_0.1km_mean</th>\n",
       "      <th>b1_buff_0.5km_mean</th>\n",
       "      <th>b2_buff_0.5km_mean</th>\n",
       "      <th>b3_buff_0.5km_mean</th>\n",
       "      <th>b4_buff_0.5km_mean</th>\n",
       "      <th>b5_buff_0.5km_mean</th>\n",
       "      <th>b6_buff_0.5km_mean</th>\n",
       "      <th>b7_buff_0.5km_mean</th>\n",
       "      <th>b12_buff_0.5km_mean</th>\n",
       "      <th>b13_buff_0.5km_mean</th>\n",
       "      <th>b14_buff_0.5km_mean</th>\n",
       "      <th>b15_buff_0.5km_mean</th>\n",
       "      <th>b16_buff_0.5km_mean</th>\n",
       "      <th>b17_buff_0.5km_mean</th>\n",
       "      <th>b23_buff_0.5km_mean</th>\n",
       "      <th>b24_buff_0.5km_mean</th>\n",
       "      <th>b25_buff_0.5km_mean</th>\n",
       "      <th>b26_buff_0.5km_mean</th>\n",
       "      <th>b27_buff_0.5km_mean</th>\n",
       "      <th>b34_buff_0.5km_mean</th>\n",
       "      <th>b35_buff_0.5km_mean</th>\n",
       "      <th>b36_buff_0.5km_mean</th>\n",
       "      <th>b37_buff_0.5km_mean</th>\n",
       "      <th>b45_buff_0.5km_mean</th>\n",
       "      <th>b46_buff_0.5km_mean</th>\n",
       "      <th>b47_buff_0.5km_mean</th>\n",
       "      <th>b56_buff_0.5km_mean</th>\n",
       "      <th>b57_buff_0.5km_mean</th>\n",
       "      <th>b67_buff_0.5km_mean</th>\n",
       "      <th>b1_buff_1km_mean</th>\n",
       "      <th>b2_buff_1km_mean</th>\n",
       "      <th>b3_buff_1km_mean</th>\n",
       "      <th>b4_buff_1km_mean</th>\n",
       "      <th>b5_buff_1km_mean</th>\n",
       "      <th>b6_buff_1km_mean</th>\n",
       "      <th>b7_buff_1km_mean</th>\n",
       "      <th>b12_buff_1km_mean</th>\n",
       "      <th>b13_buff_1km_mean</th>\n",
       "      <th>b14_buff_1km_mean</th>\n",
       "      <th>b15_buff_1km_mean</th>\n",
       "      <th>b16_buff_1km_mean</th>\n",
       "      <th>b17_buff_1km_mean</th>\n",
       "      <th>b23_buff_1km_mean</th>\n",
       "      <th>b24_buff_1km_mean</th>\n",
       "      <th>b25_buff_1km_mean</th>\n",
       "      <th>b26_buff_1km_mean</th>\n",
       "      <th>b27_buff_1km_mean</th>\n",
       "      <th>b34_buff_1km_mean</th>\n",
       "      <th>b35_buff_1km_mean</th>\n",
       "      <th>b36_buff_1km_mean</th>\n",
       "      <th>b37_buff_1km_mean</th>\n",
       "      <th>b45_buff_1km_mean</th>\n",
       "      <th>b46_buff_1km_mean</th>\n",
       "      <th>b47_buff_1km_mean</th>\n",
       "      <th>b56_buff_1km_mean</th>\n",
       "      <th>b57_buff_1km_mean</th>\n",
       "      <th>b67_buff_1km_mean</th>\n",
       "      <th>b1_buff_1.5km_mean</th>\n",
       "      <th>b2_buff_1.5km_mean</th>\n",
       "      <th>b3_buff_1.5km_mean</th>\n",
       "      <th>b4_buff_1.5km_mean</th>\n",
       "      <th>b5_buff_1.5km_mean</th>\n",
       "      <th>b6_buff_1.5km_mean</th>\n",
       "      <th>b7_buff_1.5km_mean</th>\n",
       "      <th>b12_buff_1.5km_mean</th>\n",
       "      <th>b13_buff_1.5km_mean</th>\n",
       "      <th>b14_buff_1.5km_mean</th>\n",
       "      <th>b15_buff_1.5km_mean</th>\n",
       "      <th>b16_buff_1.5km_mean</th>\n",
       "      <th>b17_buff_1.5km_mean</th>\n",
       "      <th>b23_buff_1.5km_mean</th>\n",
       "      <th>b24_buff_1.5km_mean</th>\n",
       "      <th>b25_buff_1.5km_mean</th>\n",
       "      <th>b26_buff_1.5km_mean</th>\n",
       "      <th>b27_buff_1.5km_mean</th>\n",
       "      <th>b34_buff_1.5km_mean</th>\n",
       "      <th>b35_buff_1.5km_mean</th>\n",
       "      <th>b36_buff_1.5km_mean</th>\n",
       "      <th>b37_buff_1.5km_mean</th>\n",
       "      <th>b45_buff_1.5km_mean</th>\n",
       "      <th>b46_buff_1.5km_mean</th>\n",
       "      <th>b47_buff_1.5km_mean</th>\n",
       "      <th>b56_buff_1.5km_mean</th>\n",
       "      <th>b57_buff_1.5km_mean</th>\n",
       "      <th>b67_buff_1.5km_mean</th>\n",
       "      <th>b1_buff_2km_mean</th>\n",
       "      <th>b2_buff_2km_mean</th>\n",
       "      <th>b3_buff_2km_mean</th>\n",
       "      <th>b4_buff_2km_mean</th>\n",
       "      <th>b5_buff_2km_mean</th>\n",
       "      <th>b6_buff_2km_mean</th>\n",
       "      <th>b7_buff_2km_mean</th>\n",
       "      <th>b12_buff_2km_mean</th>\n",
       "      <th>b13_buff_2km_mean</th>\n",
       "      <th>b14_buff_2km_mean</th>\n",
       "      <th>b15_buff_2km_mean</th>\n",
       "      <th>b16_buff_2km_mean</th>\n",
       "      <th>b17_buff_2km_mean</th>\n",
       "      <th>b23_buff_2km_mean</th>\n",
       "      <th>b24_buff_2km_mean</th>\n",
       "      <th>b25_buff_2km_mean</th>\n",
       "      <th>b26_buff_2km_mean</th>\n",
       "      <th>b27_buff_2km_mean</th>\n",
       "      <th>b34_buff_2km_mean</th>\n",
       "      <th>b35_buff_2km_mean</th>\n",
       "      <th>b36_buff_2km_mean</th>\n",
       "      <th>b37_buff_2km_mean</th>\n",
       "      <th>b45_buff_2km_mean</th>\n",
       "      <th>b46_buff_2km_mean</th>\n",
       "      <th>b47_buff_2km_mean</th>\n",
       "      <th>b56_buff_2km_mean</th>\n",
       "      <th>b57_buff_2km_mean</th>\n",
       "      <th>b67_buff_2km_mean</th>\n",
       "      <th>b1_buff_0.1km_min</th>\n",
       "      <th>b2_buff_0.1km_min</th>\n",
       "      <th>b3_buff_0.1km_min</th>\n",
       "      <th>b4_buff_0.1km_min</th>\n",
       "      <th>b5_buff_0.1km_min</th>\n",
       "      <th>b6_buff_0.1km_min</th>\n",
       "      <th>b7_buff_0.1km_min</th>\n",
       "      <th>b12_buff_0.1km_min</th>\n",
       "      <th>b13_buff_0.1km_min</th>\n",
       "      <th>b14_buff_0.1km_min</th>\n",
       "      <th>b15_buff_0.1km_min</th>\n",
       "      <th>b16_buff_0.1km_min</th>\n",
       "      <th>b17_buff_0.1km_min</th>\n",
       "      <th>b23_buff_0.1km_min</th>\n",
       "      <th>b24_buff_0.1km_min</th>\n",
       "      <th>b25_buff_0.1km_min</th>\n",
       "      <th>b26_buff_0.1km_min</th>\n",
       "      <th>b27_buff_0.1km_min</th>\n",
       "      <th>b34_buff_0.1km_min</th>\n",
       "      <th>b35_buff_0.1km_min</th>\n",
       "      <th>b36_buff_0.1km_min</th>\n",
       "      <th>b37_buff_0.1km_min</th>\n",
       "      <th>b45_buff_0.1km_min</th>\n",
       "      <th>b46_buff_0.1km_min</th>\n",
       "      <th>b47_buff_0.1km_min</th>\n",
       "      <th>b56_buff_0.1km_min</th>\n",
       "      <th>b57_buff_0.1km_min</th>\n",
       "      <th>b67_buff_0.1km_min</th>\n",
       "      <th>b1_buff_0.5km_min</th>\n",
       "      <th>b2_buff_0.5km_min</th>\n",
       "      <th>b3_buff_0.5km_min</th>\n",
       "      <th>b4_buff_0.5km_min</th>\n",
       "      <th>b5_buff_0.5km_min</th>\n",
       "      <th>b6_buff_0.5km_min</th>\n",
       "      <th>b7_buff_0.5km_min</th>\n",
       "      <th>b12_buff_0.5km_min</th>\n",
       "      <th>b13_buff_0.5km_min</th>\n",
       "      <th>b14_buff_0.5km_min</th>\n",
       "      <th>b15_buff_0.5km_min</th>\n",
       "      <th>b16_buff_0.5km_min</th>\n",
       "      <th>b17_buff_0.5km_min</th>\n",
       "      <th>b23_buff_0.5km_min</th>\n",
       "      <th>b24_buff_0.5km_min</th>\n",
       "      <th>b25_buff_0.5km_min</th>\n",
       "      <th>b26_buff_0.5km_min</th>\n",
       "      <th>b27_buff_0.5km_min</th>\n",
       "      <th>b34_buff_0.5km_min</th>\n",
       "      <th>b35_buff_0.5km_min</th>\n",
       "      <th>b36_buff_0.5km_min</th>\n",
       "      <th>b37_buff_0.5km_min</th>\n",
       "      <th>b45_buff_0.5km_min</th>\n",
       "      <th>b46_buff_0.5km_min</th>\n",
       "      <th>b47_buff_0.5km_min</th>\n",
       "      <th>b56_buff_0.5km_min</th>\n",
       "      <th>b57_buff_0.5km_min</th>\n",
       "      <th>b67_buff_0.5km_min</th>\n",
       "      <th>b1_buff_1km_min</th>\n",
       "      <th>b2_buff_1km_min</th>\n",
       "      <th>b3_buff_1km_min</th>\n",
       "      <th>b4_buff_1km_min</th>\n",
       "      <th>b5_buff_1km_min</th>\n",
       "      <th>b6_buff_1km_min</th>\n",
       "      <th>b7_buff_1km_min</th>\n",
       "      <th>b12_buff_1km_min</th>\n",
       "      <th>b13_buff_1km_min</th>\n",
       "      <th>b14_buff_1km_min</th>\n",
       "      <th>b15_buff_1km_min</th>\n",
       "      <th>b16_buff_1km_min</th>\n",
       "      <th>b17_buff_1km_min</th>\n",
       "      <th>b23_buff_1km_min</th>\n",
       "      <th>b24_buff_1km_min</th>\n",
       "      <th>b25_buff_1km_min</th>\n",
       "      <th>b26_buff_1km_min</th>\n",
       "      <th>b27_buff_1km_min</th>\n",
       "      <th>b34_buff_1km_min</th>\n",
       "      <th>b35_buff_1km_min</th>\n",
       "      <th>b36_buff_1km_min</th>\n",
       "      <th>b37_buff_1km_min</th>\n",
       "      <th>b45_buff_1km_min</th>\n",
       "      <th>b46_buff_1km_min</th>\n",
       "      <th>b47_buff_1km_min</th>\n",
       "      <th>b56_buff_1km_min</th>\n",
       "      <th>b57_buff_1km_min</th>\n",
       "      <th>b67_buff_1km_min</th>\n",
       "      <th>b1_buff_1.5km_min</th>\n",
       "      <th>b2_buff_1.5km_min</th>\n",
       "      <th>b3_buff_1.5km_min</th>\n",
       "      <th>b4_buff_1.5km_min</th>\n",
       "      <th>b5_buff_1.5km_min</th>\n",
       "      <th>b6_buff_1.5km_min</th>\n",
       "      <th>b7_buff_1.5km_min</th>\n",
       "      <th>b12_buff_1.5km_min</th>\n",
       "      <th>b13_buff_1.5km_min</th>\n",
       "      <th>b14_buff_1.5km_min</th>\n",
       "      <th>b15_buff_1.5km_min</th>\n",
       "      <th>b16_buff_1.5km_min</th>\n",
       "      <th>b17_buff_1.5km_min</th>\n",
       "      <th>b23_buff_1.5km_min</th>\n",
       "      <th>b24_buff_1.5km_min</th>\n",
       "      <th>b25_buff_1.5km_min</th>\n",
       "      <th>b26_buff_1.5km_min</th>\n",
       "      <th>b27_buff_1.5km_min</th>\n",
       "      <th>b34_buff_1.5km_min</th>\n",
       "      <th>b35_buff_1.5km_min</th>\n",
       "      <th>b36_buff_1.5km_min</th>\n",
       "      <th>b37_buff_1.5km_min</th>\n",
       "      <th>b45_buff_1.5km_min</th>\n",
       "      <th>b46_buff_1.5km_min</th>\n",
       "      <th>b47_buff_1.5km_min</th>\n",
       "      <th>b56_buff_1.5km_min</th>\n",
       "      <th>b57_buff_1.5km_min</th>\n",
       "      <th>b67_buff_1.5km_min</th>\n",
       "      <th>b1_buff_2km_min</th>\n",
       "      <th>b2_buff_2km_min</th>\n",
       "      <th>b3_buff_2km_min</th>\n",
       "      <th>b4_buff_2km_min</th>\n",
       "      <th>b5_buff_2km_min</th>\n",
       "      <th>b6_buff_2km_min</th>\n",
       "      <th>b7_buff_2km_min</th>\n",
       "      <th>b12_buff_2km_min</th>\n",
       "      <th>b13_buff_2km_min</th>\n",
       "      <th>b14_buff_2km_min</th>\n",
       "      <th>b15_buff_2km_min</th>\n",
       "      <th>b16_buff_2km_min</th>\n",
       "      <th>b17_buff_2km_min</th>\n",
       "      <th>b23_buff_2km_min</th>\n",
       "      <th>b24_buff_2km_min</th>\n",
       "      <th>b25_buff_2km_min</th>\n",
       "      <th>b26_buff_2km_min</th>\n",
       "      <th>b27_buff_2km_min</th>\n",
       "      <th>b34_buff_2km_min</th>\n",
       "      <th>b35_buff_2km_min</th>\n",
       "      <th>b36_buff_2km_min</th>\n",
       "      <th>b37_buff_2km_min</th>\n",
       "      <th>b45_buff_2km_min</th>\n",
       "      <th>b46_buff_2km_min</th>\n",
       "      <th>b47_buff_2km_min</th>\n",
       "      <th>b56_buff_2km_min</th>\n",
       "      <th>b57_buff_2km_min</th>\n",
       "      <th>b67_buff_2km_min</th>\n",
       "      <th>b1_buff_0.1km_max</th>\n",
       "      <th>b2_buff_0.1km_max</th>\n",
       "      <th>b3_buff_0.1km_max</th>\n",
       "      <th>b4_buff_0.1km_max</th>\n",
       "      <th>b5_buff_0.1km_max</th>\n",
       "      <th>b6_buff_0.1km_max</th>\n",
       "      <th>b7_buff_0.1km_max</th>\n",
       "      <th>b12_buff_0.1km_max</th>\n",
       "      <th>b13_buff_0.1km_max</th>\n",
       "      <th>b14_buff_0.1km_max</th>\n",
       "      <th>b15_buff_0.1km_max</th>\n",
       "      <th>b16_buff_0.1km_max</th>\n",
       "      <th>b17_buff_0.1km_max</th>\n",
       "      <th>b23_buff_0.1km_max</th>\n",
       "      <th>b24_buff_0.1km_max</th>\n",
       "      <th>b25_buff_0.1km_max</th>\n",
       "      <th>b26_buff_0.1km_max</th>\n",
       "      <th>b27_buff_0.1km_max</th>\n",
       "      <th>b34_buff_0.1km_max</th>\n",
       "      <th>b35_buff_0.1km_max</th>\n",
       "      <th>b36_buff_0.1km_max</th>\n",
       "      <th>b37_buff_0.1km_max</th>\n",
       "      <th>b45_buff_0.1km_max</th>\n",
       "      <th>b46_buff_0.1km_max</th>\n",
       "      <th>b47_buff_0.1km_max</th>\n",
       "      <th>b56_buff_0.1km_max</th>\n",
       "      <th>b57_buff_0.1km_max</th>\n",
       "      <th>b67_buff_0.1km_max</th>\n",
       "      <th>b1_buff_0.5km_max</th>\n",
       "      <th>b2_buff_0.5km_max</th>\n",
       "      <th>b3_buff_0.5km_max</th>\n",
       "      <th>b4_buff_0.5km_max</th>\n",
       "      <th>b5_buff_0.5km_max</th>\n",
       "      <th>b6_buff_0.5km_max</th>\n",
       "      <th>b7_buff_0.5km_max</th>\n",
       "      <th>b12_buff_0.5km_max</th>\n",
       "      <th>b13_buff_0.5km_max</th>\n",
       "      <th>b14_buff_0.5km_max</th>\n",
       "      <th>b15_buff_0.5km_max</th>\n",
       "      <th>b16_buff_0.5km_max</th>\n",
       "      <th>b17_buff_0.5km_max</th>\n",
       "      <th>b23_buff_0.5km_max</th>\n",
       "      <th>b24_buff_0.5km_max</th>\n",
       "      <th>b25_buff_0.5km_max</th>\n",
       "      <th>b26_buff_0.5km_max</th>\n",
       "      <th>b27_buff_0.5km_max</th>\n",
       "      <th>b34_buff_0.5km_max</th>\n",
       "      <th>b35_buff_0.5km_max</th>\n",
       "      <th>b36_buff_0.5km_max</th>\n",
       "      <th>b37_buff_0.5km_max</th>\n",
       "      <th>b45_buff_0.5km_max</th>\n",
       "      <th>b46_buff_0.5km_max</th>\n",
       "      <th>b47_buff_0.5km_max</th>\n",
       "      <th>b56_buff_0.5km_max</th>\n",
       "      <th>b57_buff_0.5km_max</th>\n",
       "      <th>b67_buff_0.5km_max</th>\n",
       "      <th>b1_buff_1km_max</th>\n",
       "      <th>b2_buff_1km_max</th>\n",
       "      <th>b3_buff_1km_max</th>\n",
       "      <th>b4_buff_1km_max</th>\n",
       "      <th>b5_buff_1km_max</th>\n",
       "      <th>b6_buff_1km_max</th>\n",
       "      <th>b7_buff_1km_max</th>\n",
       "      <th>b12_buff_1km_max</th>\n",
       "      <th>b13_buff_1km_max</th>\n",
       "      <th>b14_buff_1km_max</th>\n",
       "      <th>b15_buff_1km_max</th>\n",
       "      <th>b16_buff_1km_max</th>\n",
       "      <th>b17_buff_1km_max</th>\n",
       "      <th>b23_buff_1km_max</th>\n",
       "      <th>b24_buff_1km_max</th>\n",
       "      <th>b25_buff_1km_max</th>\n",
       "      <th>b26_buff_1km_max</th>\n",
       "      <th>b27_buff_1km_max</th>\n",
       "      <th>b34_buff_1km_max</th>\n",
       "      <th>b35_buff_1km_max</th>\n",
       "      <th>b36_buff_1km_max</th>\n",
       "      <th>b37_buff_1km_max</th>\n",
       "      <th>b45_buff_1km_max</th>\n",
       "      <th>b46_buff_1km_max</th>\n",
       "      <th>b47_buff_1km_max</th>\n",
       "      <th>b56_buff_1km_max</th>\n",
       "      <th>b57_buff_1km_max</th>\n",
       "      <th>b67_buff_1km_max</th>\n",
       "      <th>b1_buff_1.5km_max</th>\n",
       "      <th>b2_buff_1.5km_max</th>\n",
       "      <th>b3_buff_1.5km_max</th>\n",
       "      <th>b4_buff_1.5km_max</th>\n",
       "      <th>b5_buff_1.5km_max</th>\n",
       "      <th>b6_buff_1.5km_max</th>\n",
       "      <th>b7_buff_1.5km_max</th>\n",
       "      <th>b12_buff_1.5km_max</th>\n",
       "      <th>b13_buff_1.5km_max</th>\n",
       "      <th>b14_buff_1.5km_max</th>\n",
       "      <th>b15_buff_1.5km_max</th>\n",
       "      <th>b16_buff_1.5km_max</th>\n",
       "      <th>b17_buff_1.5km_max</th>\n",
       "      <th>b23_buff_1.5km_max</th>\n",
       "      <th>b24_buff_1.5km_max</th>\n",
       "      <th>b25_buff_1.5km_max</th>\n",
       "      <th>b26_buff_1.5km_max</th>\n",
       "      <th>b27_buff_1.5km_max</th>\n",
       "      <th>b34_buff_1.5km_max</th>\n",
       "      <th>b35_buff_1.5km_max</th>\n",
       "      <th>b36_buff_1.5km_max</th>\n",
       "      <th>b37_buff_1.5km_max</th>\n",
       "      <th>b45_buff_1.5km_max</th>\n",
       "      <th>b46_buff_1.5km_max</th>\n",
       "      <th>b47_buff_1.5km_max</th>\n",
       "      <th>b56_buff_1.5km_max</th>\n",
       "      <th>b57_buff_1.5km_max</th>\n",
       "      <th>b67_buff_1.5km_max</th>\n",
       "      <th>b1_buff_2km_max</th>\n",
       "      <th>b2_buff_2km_max</th>\n",
       "      <th>b3_buff_2km_max</th>\n",
       "      <th>b4_buff_2km_max</th>\n",
       "      <th>b5_buff_2km_max</th>\n",
       "      <th>b6_buff_2km_max</th>\n",
       "      <th>b7_buff_2km_max</th>\n",
       "      <th>b12_buff_2km_max</th>\n",
       "      <th>b13_buff_2km_max</th>\n",
       "      <th>b14_buff_2km_max</th>\n",
       "      <th>b15_buff_2km_max</th>\n",
       "      <th>b16_buff_2km_max</th>\n",
       "      <th>b17_buff_2km_max</th>\n",
       "      <th>b23_buff_2km_max</th>\n",
       "      <th>b24_buff_2km_max</th>\n",
       "      <th>b25_buff_2km_max</th>\n",
       "      <th>b26_buff_2km_max</th>\n",
       "      <th>b27_buff_2km_max</th>\n",
       "      <th>b34_buff_2km_max</th>\n",
       "      <th>b35_buff_2km_max</th>\n",
       "      <th>b36_buff_2km_max</th>\n",
       "      <th>b37_buff_2km_max</th>\n",
       "      <th>b45_buff_2km_max</th>\n",
       "      <th>b46_buff_2km_max</th>\n",
       "      <th>b47_buff_2km_max</th>\n",
       "      <th>b56_buff_2km_max</th>\n",
       "      <th>b57_buff_2km_max</th>\n",
       "      <th>b67_buff_2km_max</th>\n",
       "      <th>viirs_spatialmean_monthlymean_buff_1km</th>\n",
       "      <th>viirs_spatialmean_monthlysd_buff_1km</th>\n",
       "      <th>viirs_spatialmean_monthlymean_buff_2km</th>\n",
       "      <th>viirs_spatialmean_monthlysd_buff_2km</th>\n",
       "      <th>viirs_spatialmean_monthlymean_buff_3km</th>\n",
       "      <th>viirs_spatialmean_monthlysd_buff_3km</th>\n",
       "      <th>viirs_spatialmean_monthlymean_buff_5km</th>\n",
       "      <th>viirs_spatialmean_monthlysd_buff_5km</th>\n",
       "      <th>viirs_spatialmean_monthlymean_buff_10km</th>\n",
       "      <th>viirs_spatialmean_monthlysd_buff_10km</th>\n",
       "      <th>viirs_spatialmax_monthlymean_buff_1km</th>\n",
       "      <th>viirs_spatialmax_monthlysd_buff_1km</th>\n",
       "      <th>viirs_spatialmax_monthlymean_buff_2km</th>\n",
       "      <th>viirs_spatialmax_monthlysd_buff_2km</th>\n",
       "      <th>viirs_spatialmax_monthlymean_buff_3km</th>\n",
       "      <th>viirs_spatialmax_monthlysd_buff_3km</th>\n",
       "      <th>viirs_spatialmax_monthlymean_buff_5km</th>\n",
       "      <th>viirs_spatialmax_monthlysd_buff_5km</th>\n",
       "      <th>viirs_spatialmax_monthlymean_buff_10km</th>\n",
       "      <th>viirs_spatialmax_monthlysd_buff_10km</th>\n",
       "      <th>viirs_spatialmin_monthlymean_buff_1km</th>\n",
       "      <th>viirs_spatialmin_monthlysd_buff_1km</th>\n",
       "      <th>viirs_spatialmin_monthlymean_buff_2km</th>\n",
       "      <th>viirs_spatialmin_monthlysd_buff_2km</th>\n",
       "      <th>viirs_spatialmin_monthlymean_buff_3km</th>\n",
       "      <th>viirs_spatialmin_monthlysd_buff_3km</th>\n",
       "      <th>viirs_spatialmin_monthlymean_buff_5km</th>\n",
       "      <th>viirs_spatialmin_monthlysd_buff_5km</th>\n",
       "      <th>viirs_spatialmin_monthlymean_buff_10km</th>\n",
       "      <th>viirs_spatialmin_monthlysd_buff_10km</th>\n",
       "      <th>viirs_spatialsd_monthlymean_buff_1km</th>\n",
       "      <th>viirs_spatialsd_monthlysd_buff_1km</th>\n",
       "      <th>viirs_spatialsd_monthlymean_buff_2km</th>\n",
       "      <th>viirs_spatialsd_monthlysd_buff_2km</th>\n",
       "      <th>viirs_spatialsd_monthlymean_buff_3km</th>\n",
       "      <th>viirs_spatialsd_monthlysd_buff_3km</th>\n",
       "      <th>viirs_spatialsd_monthlymean_buff_5km</th>\n",
       "      <th>viirs_spatialsd_monthlysd_buff_5km</th>\n",
       "      <th>viirs_spatialsd_monthlymean_buff_10km</th>\n",
       "      <th>viirs_spatialsd_monthlysd_buff_10km</th>\n",
       "      <th>dist_osm_fclass_tertiary_meters</th>\n",
       "      <th>dist_osm_fclass_secondary_meters</th>\n",
       "      <th>dist_osm_fclass_residential_meters</th>\n",
       "      <th>dist_osm_fclass_trunk_meters</th>\n",
       "      <th>dist_osm_fclass_primary_meters</th>\n",
       "      <th>dist_osm_fclass_unclassified_meters</th>\n",
       "      <th>dist_osm_fclass_service_meters</th>\n",
       "      <th>dist_osm_fclass_motorway_meters</th>\n",
       "      <th>dist_osm_fclass_living_street_meters</th>\n",
       "      <th>estimate_dau_all</th>\n",
       "      <th>estimate_mau_all</th>\n",
       "      <th>estimate_dau_male</th>\n",
       "      <th>estimate_mau_male</th>\n",
       "      <th>estimate_dau_female</th>\n",
       "      <th>estimate_mau_female</th>\n",
       "      <th>pscores_poor</th>\n",
       "      <th>distance_road_meters</th>\n",
       "      <th>distance_road_kms</th>\n",
       "      <th>dist_osm_fclass_residential_kms</th>\n",
       "      <th>viirs_NA</th>\n",
       "      <th>landsat_NA</th>\n",
       "      <th>pscores_NA</th>\n",
       "      <th>N_uid</th>\n",
       "      <th>keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100389</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.920000</td>\n",
       "      <td>2014</td>\n",
       "      <td>1056.785714</td>\n",
       "      <td>1373.214286</td>\n",
       "      <td>1540.428571</td>\n",
       "      <td>2611.642857</td>\n",
       "      <td>2525.228571</td>\n",
       "      <td>2972.257143</td>\n",
       "      <td>2108.014286</td>\n",
       "      <td>0.130218</td>\n",
       "      <td>0.186216</td>\n",
       "      <td>0.423848</td>\n",
       "      <td>0.409949</td>\n",
       "      <td>0.475416</td>\n",
       "      <td>0.332163</td>\n",
       "      <td>0.057390</td>\n",
       "      <td>0.310784</td>\n",
       "      <td>0.295506</td>\n",
       "      <td>0.367979</td>\n",
       "      <td>0.211075</td>\n",
       "      <td>0.257995</td>\n",
       "      <td>0.242224</td>\n",
       "      <td>0.317290</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>-0.016822</td>\n",
       "      <td>0.064581</td>\n",
       "      <td>-0.106709</td>\n",
       "      <td>0.081315</td>\n",
       "      <td>-0.090048</td>\n",
       "      <td>-0.170117</td>\n",
       "      <td>891.881366</td>\n",
       "      <td>1193.380208</td>\n",
       "      <td>1297.281250</td>\n",
       "      <td>2676.481481</td>\n",
       "      <td>2382.572338</td>\n",
       "      <td>2977.039931</td>\n",
       "      <td>1781.468750</td>\n",
       "      <td>0.144586</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.500117</td>\n",
       "      <td>0.455249</td>\n",
       "      <td>0.538951</td>\n",
       "      <td>0.332761</td>\n",
       "      <td>0.041716</td>\n",
       "      <td>0.383244</td>\n",
       "      <td>0.332553</td>\n",
       "      <td>0.427693</td>\n",
       "      <td>0.197687</td>\n",
       "      <td>0.347077</td>\n",
       "      <td>0.294928</td>\n",
       "      <td>0.392988</td>\n",
       "      <td>0.157268</td>\n",
       "      <td>-0.058096</td>\n",
       "      <td>0.053163</td>\n",
       "      <td>-0.200768</td>\n",
       "      <td>0.110916</td>\n",
       "      <td>-0.144356</td>\n",
       "      <td>-0.251249</td>\n",
       "      <td>864.196688</td>\n",
       "      <td>1170.219059</td>\n",
       "      <td>1269.005375</td>\n",
       "      <td>2682.513655</td>\n",
       "      <td>2375.380593</td>\n",
       "      <td>2975.853428</td>\n",
       "      <td>1738.178385</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.189766</td>\n",
       "      <td>0.512677</td>\n",
       "      <td>0.466476</td>\n",
       "      <td>0.549903</td>\n",
       "      <td>0.335840</td>\n",
       "      <td>0.040499</td>\n",
       "      <td>0.392525</td>\n",
       "      <td>0.339903</td>\n",
       "      <td>0.435505</td>\n",
       "      <td>0.195283</td>\n",
       "      <td>0.357713</td>\n",
       "      <td>0.303583</td>\n",
       "      <td>0.402098</td>\n",
       "      <td>0.156017</td>\n",
       "      <td>-0.060724</td>\n",
       "      <td>0.051842</td>\n",
       "      <td>-0.213617</td>\n",
       "      <td>0.112212</td>\n",
       "      <td>-0.154903</td>\n",
       "      <td>-0.262551</td>\n",
       "      <td>896.841959</td>\n",
       "      <td>1224.147199</td>\n",
       "      <td>1349.684047</td>\n",
       "      <td>2677.504646</td>\n",
       "      <td>2473.518715</td>\n",
       "      <td>2977.033880</td>\n",
       "      <td>1849.332279</td>\n",
       "      <td>0.154317</td>\n",
       "      <td>0.201574</td>\n",
       "      <td>0.498179</td>\n",
       "      <td>0.467807</td>\n",
       "      <td>0.536980</td>\n",
       "      <td>0.346843</td>\n",
       "      <td>0.048774</td>\n",
       "      <td>0.372498</td>\n",
       "      <td>0.337881</td>\n",
       "      <td>0.417237</td>\n",
       "      <td>0.203413</td>\n",
       "      <td>0.329714</td>\n",
       "      <td>0.293951</td>\n",
       "      <td>0.376116</td>\n",
       "      <td>0.156188</td>\n",
       "      <td>-0.039601</td>\n",
       "      <td>0.052971</td>\n",
       "      <td>-0.182947</td>\n",
       "      <td>0.092379</td>\n",
       "      <td>-0.144392</td>\n",
       "      <td>-0.233654</td>\n",
       "      <td>936.888325</td>\n",
       "      <td>1283.219033</td>\n",
       "      <td>1430.618932</td>\n",
       "      <td>2740.887780</td>\n",
       "      <td>2596.078695</td>\n",
       "      <td>2979.461795</td>\n",
       "      <td>1965.636674</td>\n",
       "      <td>0.155997</td>\n",
       "      <td>0.208544</td>\n",
       "      <td>0.490514</td>\n",
       "      <td>0.469631</td>\n",
       "      <td>0.521550</td>\n",
       "      <td>0.354432</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>0.362234</td>\n",
       "      <td>0.338427</td>\n",
       "      <td>0.397929</td>\n",
       "      <td>0.210049</td>\n",
       "      <td>0.314100</td>\n",
       "      <td>0.289433</td>\n",
       "      <td>0.351205</td>\n",
       "      <td>0.157532</td>\n",
       "      <td>-0.027133</td>\n",
       "      <td>0.041706</td>\n",
       "      <td>-0.164718</td>\n",
       "      <td>0.068762</td>\n",
       "      <td>-0.138203</td>\n",
       "      <td>-0.205016</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>2327.5</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.242115</td>\n",
       "      <td>0.480363</td>\n",
       "      <td>0.473243</td>\n",
       "      <td>0.566233</td>\n",
       "      <td>0.381997</td>\n",
       "      <td>0.088618</td>\n",
       "      <td>0.349862</td>\n",
       "      <td>0.341750</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.239484</td>\n",
       "      <td>0.269603</td>\n",
       "      <td>0.261038</td>\n",
       "      <td>0.375612</td>\n",
       "      <td>0.154138</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>0.117954</td>\n",
       "      <td>-0.120472</td>\n",
       "      <td>0.127030</td>\n",
       "      <td>-0.111381</td>\n",
       "      <td>-0.235085</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.460630</td>\n",
       "      <td>0.419184</td>\n",
       "      <td>0.68569</td>\n",
       "      <td>0.177794</td>\n",
       "      <td>-0.05007</td>\n",
       "      <td>0.325592</td>\n",
       "      <td>0.278892</td>\n",
       "      <td>0.591229</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.369635</td>\n",
       "      <td>0.324431</td>\n",
       "      <td>0.622860</td>\n",
       "      <td>0.069482</td>\n",
       "      <td>-0.051364</td>\n",
       "      <td>0.328962</td>\n",
       "      <td>-0.308065</td>\n",
       "      <td>0.374007</td>\n",
       "      <td>-0.260829</td>\n",
       "      <td>-0.57841</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2934.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.43766</td>\n",
       "      <td>0.337364</td>\n",
       "      <td>0.685238</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>-0.050800</td>\n",
       "      <td>0.299629</td>\n",
       "      <td>0.188608</td>\n",
       "      <td>0.590675</td>\n",
       "      <td>-0.047157</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>0.237136</td>\n",
       "      <td>0.622788</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>-0.117671</td>\n",
       "      <td>0.353633</td>\n",
       "      <td>-0.341954</td>\n",
       "      <td>0.452475</td>\n",
       "      <td>-0.233687</td>\n",
       "      <td>-0.620547</td>\n",
       "      <td>528.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>967.5</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>580.5</td>\n",
       "      <td>0.130148</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.293882</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.047361</td>\n",
       "      <td>-0.066874</td>\n",
       "      <td>0.318599</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.619365</td>\n",
       "      <td>-0.0833</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.23445</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.391509</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.668191</td>\n",
       "      <td>528.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>967.5</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>579.5</td>\n",
       "      <td>0.130148</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.293882</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.046501</td>\n",
       "      <td>-0.066874</td>\n",
       "      <td>0.318599</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.619365</td>\n",
       "      <td>-0.084156</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.234450</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.017380</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.392239</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>-0.250808</td>\n",
       "      <td>-0.668668</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1572.5</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>2874.0</td>\n",
       "      <td>2779.5</td>\n",
       "      <td>3041.5</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.132313</td>\n",
       "      <td>0.171252</td>\n",
       "      <td>0.409169</td>\n",
       "      <td>0.395156</td>\n",
       "      <td>0.432474</td>\n",
       "      <td>0.344574</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>0.292702</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.318379</td>\n",
       "      <td>0.222401</td>\n",
       "      <td>0.255844</td>\n",
       "      <td>0.240156</td>\n",
       "      <td>0.282116</td>\n",
       "      <td>0.184192</td>\n",
       "      <td>-0.016715</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>-0.075196</td>\n",
       "      <td>0.045009</td>\n",
       "      <td>-0.058555</td>\n",
       "      <td>-0.103292</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.172762</td>\n",
       "      <td>0.423539</td>\n",
       "      <td>0.430268</td>\n",
       "      <td>0.373423</td>\n",
       "      <td>0.335086</td>\n",
       "      <td>0.061356</td>\n",
       "      <td>0.326511</td>\n",
       "      <td>0.333843</td>\n",
       "      <td>0.272272</td>\n",
       "      <td>0.231210</td>\n",
       "      <td>0.270575</td>\n",
       "      <td>0.278184</td>\n",
       "      <td>0.214499</td>\n",
       "      <td>0.172298</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>-0.059531</td>\n",
       "      <td>-0.103083</td>\n",
       "      <td>-0.067727</td>\n",
       "      <td>-0.111217</td>\n",
       "      <td>-0.043821</td>\n",
       "      <td>1566.5</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3644.0</td>\n",
       "      <td>3114.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.108550</td>\n",
       "      <td>0.184433</td>\n",
       "      <td>0.373588</td>\n",
       "      <td>0.398714</td>\n",
       "      <td>0.330627</td>\n",
       "      <td>0.437169</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>0.276240</td>\n",
       "      <td>0.303290</td>\n",
       "      <td>0.230344</td>\n",
       "      <td>0.344990</td>\n",
       "      <td>0.203152</td>\n",
       "      <td>0.231289</td>\n",
       "      <td>0.155688</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>0.075992</td>\n",
       "      <td>-0.078426</td>\n",
       "      <td>0.046572</td>\n",
       "      <td>0.124543</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>3447.0</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>4572.0</td>\n",
       "      <td>0.164826</td>\n",
       "      <td>0.273601</td>\n",
       "      <td>0.358774</td>\n",
       "      <td>0.486013</td>\n",
       "      <td>0.226593</td>\n",
       "      <td>0.398593</td>\n",
       "      <td>0.113912</td>\n",
       "      <td>0.206138</td>\n",
       "      <td>0.349157</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.250205</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.244990</td>\n",
       "      <td>-0.050114</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.154112</td>\n",
       "      <td>-0.143877</td>\n",
       "      <td>0.046464</td>\n",
       "      <td>-0.291525</td>\n",
       "      <td>-0.108424</td>\n",
       "      <td>0.189077</td>\n",
       "      <td>2177.5</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>6460.5</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>5562.5</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>0.26776</td>\n",
       "      <td>0.35904</td>\n",
       "      <td>0.495832</td>\n",
       "      <td>0.181775</td>\n",
       "      <td>0.437339</td>\n",
       "      <td>0.119193</td>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.370565</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.304297</td>\n",
       "      <td>0.10099</td>\n",
       "      <td>0.262988</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.189642</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>-0.345167</td>\n",
       "      <td>-0.07469</td>\n",
       "      <td>0.277634</td>\n",
       "      <td>2.058431</td>\n",
       "      <td>0.212049</td>\n",
       "      <td>2.703993</td>\n",
       "      <td>0.442176</td>\n",
       "      <td>3.183021</td>\n",
       "      <td>0.458820</td>\n",
       "      <td>2.959563</td>\n",
       "      <td>0.357889</td>\n",
       "      <td>1.835716</td>\n",
       "      <td>0.216637</td>\n",
       "      <td>4.138187</td>\n",
       "      <td>0.889063</td>\n",
       "      <td>7.454411</td>\n",
       "      <td>2.258553</td>\n",
       "      <td>11.129500</td>\n",
       "      <td>2.579266</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>0.192531</td>\n",
       "      <td>0.599399</td>\n",
       "      <td>0.161676</td>\n",
       "      <td>0.475024</td>\n",
       "      <td>0.146881</td>\n",
       "      <td>0.320060</td>\n",
       "      <td>0.169679</td>\n",
       "      <td>0.151178</td>\n",
       "      <td>0.144790</td>\n",
       "      <td>1.199479</td>\n",
       "      <td>0.357367</td>\n",
       "      <td>2.054746</td>\n",
       "      <td>0.646521</td>\n",
       "      <td>2.763771</td>\n",
       "      <td>0.654013</td>\n",
       "      <td>3.277391</td>\n",
       "      <td>0.772987</td>\n",
       "      <td>2.362731</td>\n",
       "      <td>0.534068</td>\n",
       "      <td>707.590360</td>\n",
       "      <td>691.084276</td>\n",
       "      <td>290.853957</td>\n",
       "      <td>301.885996</td>\n",
       "      <td>4213.933117</td>\n",
       "      <td>61.828224</td>\n",
       "      <td>1892.079096</td>\n",
       "      <td>5496.035379</td>\n",
       "      <td>445.707495</td>\n",
       "      <td>21718</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>16463</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3696</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>61.828224</td>\n",
       "      <td>0.061828</td>\n",
       "      <td>0.290854</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100401</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.150000</td>\n",
       "      <td>2014</td>\n",
       "      <td>743.375000</td>\n",
       "      <td>1016.652778</td>\n",
       "      <td>1042.680556</td>\n",
       "      <td>2921.305556</td>\n",
       "      <td>2363.236111</td>\n",
       "      <td>2977.208333</td>\n",
       "      <td>1601.250000</td>\n",
       "      <td>0.155269</td>\n",
       "      <td>0.167579</td>\n",
       "      <td>0.594303</td>\n",
       "      <td>0.521424</td>\n",
       "      <td>0.600399</td>\n",
       "      <td>0.365890</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>0.483665</td>\n",
       "      <td>0.398411</td>\n",
       "      <td>0.490892</td>\n",
       "      <td>0.223307</td>\n",
       "      <td>0.473923</td>\n",
       "      <td>0.387724</td>\n",
       "      <td>0.481239</td>\n",
       "      <td>0.211265</td>\n",
       "      <td>-0.105604</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>-0.291883</td>\n",
       "      <td>0.114967</td>\n",
       "      <td>-0.192203</td>\n",
       "      <td>-0.300529</td>\n",
       "      <td>878.931634</td>\n",
       "      <td>1192.610081</td>\n",
       "      <td>1304.334878</td>\n",
       "      <td>2695.401506</td>\n",
       "      <td>2430.099073</td>\n",
       "      <td>2975.713789</td>\n",
       "      <td>1801.095017</td>\n",
       "      <td>0.151423</td>\n",
       "      <td>0.194847</td>\n",
       "      <td>0.508198</td>\n",
       "      <td>0.468768</td>\n",
       "      <td>0.543962</td>\n",
       "      <td>0.344087</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>0.386519</td>\n",
       "      <td>0.341592</td>\n",
       "      <td>0.427775</td>\n",
       "      <td>0.203255</td>\n",
       "      <td>0.347790</td>\n",
       "      <td>0.301455</td>\n",
       "      <td>0.390505</td>\n",
       "      <td>0.159965</td>\n",
       "      <td>-0.051761</td>\n",
       "      <td>0.049428</td>\n",
       "      <td>-0.198890</td>\n",
       "      <td>0.100931</td>\n",
       "      <td>-0.148659</td>\n",
       "      <td>-0.245900</td>\n",
       "      <td>852.733208</td>\n",
       "      <td>1156.635061</td>\n",
       "      <td>1255.240012</td>\n",
       "      <td>2644.950926</td>\n",
       "      <td>2367.389548</td>\n",
       "      <td>2973.689346</td>\n",
       "      <td>1724.653445</td>\n",
       "      <td>0.151242</td>\n",
       "      <td>0.190945</td>\n",
       "      <td>0.512401</td>\n",
       "      <td>0.470372</td>\n",
       "      <td>0.554292</td>\n",
       "      <td>0.338296</td>\n",
       "      <td>0.040883</td>\n",
       "      <td>0.391499</td>\n",
       "      <td>0.343572</td>\n",
       "      <td>0.439930</td>\n",
       "      <td>0.197140</td>\n",
       "      <td>0.356319</td>\n",
       "      <td>0.307001</td>\n",
       "      <td>0.406356</td>\n",
       "      <td>0.157527</td>\n",
       "      <td>-0.055376</td>\n",
       "      <td>0.058509</td>\n",
       "      <td>-0.210613</td>\n",
       "      <td>0.113516</td>\n",
       "      <td>-0.157070</td>\n",
       "      <td>-0.265846</td>\n",
       "      <td>900.591837</td>\n",
       "      <td>1231.457892</td>\n",
       "      <td>1361.784293</td>\n",
       "      <td>2699.590287</td>\n",
       "      <td>2523.612439</td>\n",
       "      <td>2976.143245</td>\n",
       "      <td>1873.686321</td>\n",
       "      <td>0.155187</td>\n",
       "      <td>0.203853</td>\n",
       "      <td>0.499697</td>\n",
       "      <td>0.473985</td>\n",
       "      <td>0.535386</td>\n",
       "      <td>0.350756</td>\n",
       "      <td>0.050256</td>\n",
       "      <td>0.373471</td>\n",
       "      <td>0.344109</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.206827</td>\n",
       "      <td>0.329397</td>\n",
       "      <td>0.299024</td>\n",
       "      <td>0.372150</td>\n",
       "      <td>0.158216</td>\n",
       "      <td>-0.033692</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>-0.180593</td>\n",
       "      <td>0.082282</td>\n",
       "      <td>-0.147801</td>\n",
       "      <td>-0.227319</td>\n",
       "      <td>935.139042</td>\n",
       "      <td>1282.843795</td>\n",
       "      <td>1434.237337</td>\n",
       "      <td>2749.286865</td>\n",
       "      <td>2610.672206</td>\n",
       "      <td>2978.904935</td>\n",
       "      <td>1973.593795</td>\n",
       "      <td>0.156766</td>\n",
       "      <td>0.210645</td>\n",
       "      <td>0.492383</td>\n",
       "      <td>0.472539</td>\n",
       "      <td>0.522162</td>\n",
       "      <td>0.357013</td>\n",
       "      <td>0.055719</td>\n",
       "      <td>0.363689</td>\n",
       "      <td>0.341036</td>\n",
       "      <td>0.397973</td>\n",
       "      <td>0.212118</td>\n",
       "      <td>0.314340</td>\n",
       "      <td>0.290843</td>\n",
       "      <td>0.350015</td>\n",
       "      <td>0.158270</td>\n",
       "      <td>-0.025861</td>\n",
       "      <td>0.040086</td>\n",
       "      <td>-0.164242</td>\n",
       "      <td>0.065878</td>\n",
       "      <td>-0.138971</td>\n",
       "      <td>-0.202991</td>\n",
       "      <td>604.5</td>\n",
       "      <td>852.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>2518.5</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>2945.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>0.169928</td>\n",
       "      <td>0.067489</td>\n",
       "      <td>0.612872</td>\n",
       "      <td>0.532392</td>\n",
       "      <td>0.659389</td>\n",
       "      <td>0.287356</td>\n",
       "      <td>-0.103627</td>\n",
       "      <td>0.494437</td>\n",
       "      <td>0.398517</td>\n",
       "      <td>0.551225</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.568914</td>\n",
       "      <td>0.482230</td>\n",
       "      <td>0.619467</td>\n",
       "      <td>0.224215</td>\n",
       "      <td>-0.119458</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>-0.395098</td>\n",
       "      <td>0.195696</td>\n",
       "      <td>-0.289294</td>\n",
       "      <td>-0.459004</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.575687</td>\n",
       "      <td>0.419184</td>\n",
       "      <td>0.68569</td>\n",
       "      <td>0.177794</td>\n",
       "      <td>-0.05080</td>\n",
       "      <td>0.458781</td>\n",
       "      <td>0.278892</td>\n",
       "      <td>0.591229</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.497976</td>\n",
       "      <td>0.325087</td>\n",
       "      <td>0.623308</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>-0.206283</td>\n",
       "      <td>0.181745</td>\n",
       "      <td>-0.443262</td>\n",
       "      <td>0.374007</td>\n",
       "      <td>-0.260829</td>\n",
       "      <td>-0.57841</td>\n",
       "      <td>548.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1056.5</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>0.152359</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.43766</td>\n",
       "      <td>0.316921</td>\n",
       "      <td>0.684059</td>\n",
       "      <td>0.075885</td>\n",
       "      <td>-0.044149</td>\n",
       "      <td>0.305685</td>\n",
       "      <td>0.172911</td>\n",
       "      <td>0.593562</td>\n",
       "      <td>-0.077368</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>0.215416</td>\n",
       "      <td>0.621427</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.140183</td>\n",
       "      <td>0.351689</td>\n",
       "      <td>-0.374203</td>\n",
       "      <td>0.468762</td>\n",
       "      <td>-0.246976</td>\n",
       "      <td>-0.641472</td>\n",
       "      <td>528.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>967.5</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>580.5</td>\n",
       "      <td>0.130148</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.293882</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.047361</td>\n",
       "      <td>-0.066874</td>\n",
       "      <td>0.318599</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.619365</td>\n",
       "      <td>-0.0833</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.23445</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.391509</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.668191</td>\n",
       "      <td>528.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.125104</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.305720</td>\n",
       "      <td>0.217198</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.061767</td>\n",
       "      <td>0.187799</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.622516</td>\n",
       "      <td>-0.190184</td>\n",
       "      <td>0.246704</td>\n",
       "      <td>0.155524</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.129944</td>\n",
       "      <td>-0.094818</td>\n",
       "      <td>0.492266</td>\n",
       "      <td>-0.364948</td>\n",
       "      <td>0.560904</td>\n",
       "      <td>-0.279813</td>\n",
       "      <td>-0.726668</td>\n",
       "      <td>1120.5</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>1626.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.184052</td>\n",
       "      <td>0.508067</td>\n",
       "      <td>0.415264</td>\n",
       "      <td>0.459675</td>\n",
       "      <td>0.360901</td>\n",
       "      <td>0.053450</td>\n",
       "      <td>0.403186</td>\n",
       "      <td>0.299784</td>\n",
       "      <td>0.348930</td>\n",
       "      <td>0.240447</td>\n",
       "      <td>0.357439</td>\n",
       "      <td>0.250346</td>\n",
       "      <td>0.301096</td>\n",
       "      <td>0.189432</td>\n",
       "      <td>-0.117618</td>\n",
       "      <td>-0.063138</td>\n",
       "      <td>-0.180210</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>-0.063947</td>\n",
       "      <td>-0.118419</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1666.5</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>3048.5</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>0.132710</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.458289</td>\n",
       "      <td>0.464765</td>\n",
       "      <td>0.409874</td>\n",
       "      <td>0.377105</td>\n",
       "      <td>0.096870</td>\n",
       "      <td>0.346663</td>\n",
       "      <td>0.353882</td>\n",
       "      <td>0.293107</td>\n",
       "      <td>0.257270</td>\n",
       "      <td>0.258472</td>\n",
       "      <td>0.266135</td>\n",
       "      <td>0.201971</td>\n",
       "      <td>0.164499</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>-0.059613</td>\n",
       "      <td>-0.098146</td>\n",
       "      <td>-0.067808</td>\n",
       "      <td>-0.106289</td>\n",
       "      <td>-0.038760</td>\n",
       "      <td>1566.5</td>\n",
       "      <td>2042.5</td>\n",
       "      <td>2759.5</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>4762.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>4023.0</td>\n",
       "      <td>0.131892</td>\n",
       "      <td>0.275774</td>\n",
       "      <td>0.386228</td>\n",
       "      <td>0.504938</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.439485</td>\n",
       "      <td>0.149313</td>\n",
       "      <td>0.267987</td>\n",
       "      <td>0.399662</td>\n",
       "      <td>0.197682</td>\n",
       "      <td>0.326519</td>\n",
       "      <td>0.123620</td>\n",
       "      <td>0.266237</td>\n",
       "      <td>0.049841</td>\n",
       "      <td>0.186288</td>\n",
       "      <td>0.147470</td>\n",
       "      <td>-0.074237</td>\n",
       "      <td>0.064145</td>\n",
       "      <td>-0.219306</td>\n",
       "      <td>-0.084121</td>\n",
       "      <td>0.137726</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>3566.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>3114.0</td>\n",
       "      <td>4610.0</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>0.289226</td>\n",
       "      <td>0.364474</td>\n",
       "      <td>0.486013</td>\n",
       "      <td>0.225984</td>\n",
       "      <td>0.402068</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>0.206345</td>\n",
       "      <td>0.343576</td>\n",
       "      <td>0.057206</td>\n",
       "      <td>0.248139</td>\n",
       "      <td>0.084115</td>\n",
       "      <td>0.228973</td>\n",
       "      <td>-0.067665</td>\n",
       "      <td>0.127691</td>\n",
       "      <td>0.147703</td>\n",
       "      <td>-0.150920</td>\n",
       "      <td>0.044049</td>\n",
       "      <td>-0.292112</td>\n",
       "      <td>-0.104333</td>\n",
       "      <td>0.193682</td>\n",
       "      <td>2177.5</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>6460.5</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>5562.5</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>0.26776</td>\n",
       "      <td>0.35904</td>\n",
       "      <td>0.495832</td>\n",
       "      <td>0.181775</td>\n",
       "      <td>0.437339</td>\n",
       "      <td>0.119193</td>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.370565</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.304297</td>\n",
       "      <td>0.10099</td>\n",
       "      <td>0.262988</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.189642</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>-0.345167</td>\n",
       "      <td>-0.07469</td>\n",
       "      <td>0.277634</td>\n",
       "      <td>2.117678</td>\n",
       "      <td>0.201614</td>\n",
       "      <td>2.842941</td>\n",
       "      <td>0.437466</td>\n",
       "      <td>3.841434</td>\n",
       "      <td>0.654410</td>\n",
       "      <td>3.031431</td>\n",
       "      <td>0.364188</td>\n",
       "      <td>1.919555</td>\n",
       "      <td>0.231518</td>\n",
       "      <td>4.138187</td>\n",
       "      <td>0.889063</td>\n",
       "      <td>8.700871</td>\n",
       "      <td>1.975251</td>\n",
       "      <td>14.672931</td>\n",
       "      <td>4.762204</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>0.192531</td>\n",
       "      <td>0.676076</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.526063</td>\n",
       "      <td>0.164093</td>\n",
       "      <td>0.353151</td>\n",
       "      <td>0.126836</td>\n",
       "      <td>0.153663</td>\n",
       "      <td>0.146517</td>\n",
       "      <td>1.114580</td>\n",
       "      <td>0.318461</td>\n",
       "      <td>2.305804</td>\n",
       "      <td>0.647746</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>1.005897</td>\n",
       "      <td>3.264376</td>\n",
       "      <td>0.782375</td>\n",
       "      <td>2.434603</td>\n",
       "      <td>0.605651</td>\n",
       "      <td>949.344371</td>\n",
       "      <td>821.615637</td>\n",
       "      <td>173.271184</td>\n",
       "      <td>135.784050</td>\n",
       "      <td>4011.442510</td>\n",
       "      <td>71.969127</td>\n",
       "      <td>2002.804245</td>\n",
       "      <td>5577.352264</td>\n",
       "      <td>254.089102</td>\n",
       "      <td>21718</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>16463</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3696</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>True</td>\n",
       "      <td>71.969127</td>\n",
       "      <td>0.071969</td>\n",
       "      <td>0.173271</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100581</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2014</td>\n",
       "      <td>871.454545</td>\n",
       "      <td>1210.090909</td>\n",
       "      <td>1327.393939</td>\n",
       "      <td>2671.969697</td>\n",
       "      <td>2431.469697</td>\n",
       "      <td>2966.969697</td>\n",
       "      <td>1777.166667</td>\n",
       "      <td>0.162685</td>\n",
       "      <td>0.207354</td>\n",
       "      <td>0.508129</td>\n",
       "      <td>0.472313</td>\n",
       "      <td>0.545931</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>0.046228</td>\n",
       "      <td>0.376573</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.420602</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.336197</td>\n",
       "      <td>0.293726</td>\n",
       "      <td>0.381797</td>\n",
       "      <td>0.144875</td>\n",
       "      <td>-0.047125</td>\n",
       "      <td>0.052315</td>\n",
       "      <td>-0.201118</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.155467</td>\n",
       "      <td>-0.250794</td>\n",
       "      <td>844.847725</td>\n",
       "      <td>1150.935239</td>\n",
       "      <td>1252.122520</td>\n",
       "      <td>2744.125438</td>\n",
       "      <td>2381.855893</td>\n",
       "      <td>2974.625438</td>\n",
       "      <td>1747.780630</td>\n",
       "      <td>0.153367</td>\n",
       "      <td>0.194221</td>\n",
       "      <td>0.529198</td>\n",
       "      <td>0.476340</td>\n",
       "      <td>0.557610</td>\n",
       "      <td>0.348269</td>\n",
       "      <td>0.042108</td>\n",
       "      <td>0.409028</td>\n",
       "      <td>0.348427</td>\n",
       "      <td>0.442047</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.373351</td>\n",
       "      <td>0.310881</td>\n",
       "      <td>0.407524</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>-0.070673</td>\n",
       "      <td>0.040306</td>\n",
       "      <td>-0.221809</td>\n",
       "      <td>0.110664</td>\n",
       "      <td>-0.153543</td>\n",
       "      <td>-0.259792</td>\n",
       "      <td>853.438755</td>\n",
       "      <td>1166.697992</td>\n",
       "      <td>1275.906314</td>\n",
       "      <td>2675.079430</td>\n",
       "      <td>2387.659878</td>\n",
       "      <td>2975.803317</td>\n",
       "      <td>1760.362671</td>\n",
       "      <td>0.155068</td>\n",
       "      <td>0.198403</td>\n",
       "      <td>0.516262</td>\n",
       "      <td>0.473365</td>\n",
       "      <td>0.554252</td>\n",
       "      <td>0.346975</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>0.392626</td>\n",
       "      <td>0.343511</td>\n",
       "      <td>0.436718</td>\n",
       "      <td>0.202819</td>\n",
       "      <td>0.354133</td>\n",
       "      <td>0.303462</td>\n",
       "      <td>0.399815</td>\n",
       "      <td>0.159556</td>\n",
       "      <td>-0.056772</td>\n",
       "      <td>0.053217</td>\n",
       "      <td>-0.206229</td>\n",
       "      <td>0.109657</td>\n",
       "      <td>-0.151228</td>\n",
       "      <td>-0.256630</td>\n",
       "      <td>886.069310</td>\n",
       "      <td>1217.299871</td>\n",
       "      <td>1349.368150</td>\n",
       "      <td>2682.571631</td>\n",
       "      <td>2485.190135</td>\n",
       "      <td>2976.657834</td>\n",
       "      <td>1857.821019</td>\n",
       "      <td>0.157476</td>\n",
       "      <td>0.207252</td>\n",
       "      <td>0.503414</td>\n",
       "      <td>0.474339</td>\n",
       "      <td>0.541221</td>\n",
       "      <td>0.354151</td>\n",
       "      <td>0.051455</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.342443</td>\n",
       "      <td>0.419498</td>\n",
       "      <td>0.208291</td>\n",
       "      <td>0.330661</td>\n",
       "      <td>0.296207</td>\n",
       "      <td>0.376163</td>\n",
       "      <td>0.158535</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.051966</td>\n",
       "      <td>-0.181647</td>\n",
       "      <td>0.089982</td>\n",
       "      <td>-0.144455</td>\n",
       "      <td>-0.231429</td>\n",
       "      <td>920.696670</td>\n",
       "      <td>1265.622987</td>\n",
       "      <td>1411.402917</td>\n",
       "      <td>2734.977180</td>\n",
       "      <td>2576.445799</td>\n",
       "      <td>2978.413655</td>\n",
       "      <td>1940.046220</td>\n",
       "      <td>0.157766</td>\n",
       "      <td>0.210414</td>\n",
       "      <td>0.496292</td>\n",
       "      <td>0.473458</td>\n",
       "      <td>0.527740</td>\n",
       "      <td>0.356323</td>\n",
       "      <td>0.054456</td>\n",
       "      <td>0.367283</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.403576</td>\n",
       "      <td>0.210385</td>\n",
       "      <td>0.319212</td>\n",
       "      <td>0.292148</td>\n",
       "      <td>0.356965</td>\n",
       "      <td>0.157736</td>\n",
       "      <td>-0.029847</td>\n",
       "      <td>0.042608</td>\n",
       "      <td>-0.170038</td>\n",
       "      <td>0.072363</td>\n",
       "      <td>-0.140906</td>\n",
       "      <td>-0.211116</td>\n",
       "      <td>690.5</td>\n",
       "      <td>995.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>2413.5</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>2960.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.180659</td>\n",
       "      <td>0.174290</td>\n",
       "      <td>0.555090</td>\n",
       "      <td>0.480143</td>\n",
       "      <td>0.621696</td>\n",
       "      <td>0.277153</td>\n",
       "      <td>-0.006576</td>\n",
       "      <td>0.416165</td>\n",
       "      <td>0.327930</td>\n",
       "      <td>0.496839</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.421587</td>\n",
       "      <td>0.333786</td>\n",
       "      <td>0.501776</td>\n",
       "      <td>0.108084</td>\n",
       "      <td>-0.102181</td>\n",
       "      <td>0.101703</td>\n",
       "      <td>-0.328471</td>\n",
       "      <td>0.201786</td>\n",
       "      <td>-0.234149</td>\n",
       "      <td>-0.416268</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.613131</td>\n",
       "      <td>0.419184</td>\n",
       "      <td>0.68569</td>\n",
       "      <td>0.177794</td>\n",
       "      <td>-0.05007</td>\n",
       "      <td>0.503289</td>\n",
       "      <td>0.278892</td>\n",
       "      <td>0.591229</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.539757</td>\n",
       "      <td>0.324431</td>\n",
       "      <td>0.622860</td>\n",
       "      <td>0.069482</td>\n",
       "      <td>-0.261038</td>\n",
       "      <td>0.125191</td>\n",
       "      <td>-0.488599</td>\n",
       "      <td>0.374007</td>\n",
       "      <td>-0.260829</td>\n",
       "      <td>-0.57841</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2934.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.43766</td>\n",
       "      <td>0.337364</td>\n",
       "      <td>0.685238</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>-0.050800</td>\n",
       "      <td>0.299629</td>\n",
       "      <td>0.188608</td>\n",
       "      <td>0.590675</td>\n",
       "      <td>-0.047157</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>0.237136</td>\n",
       "      <td>0.622788</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>-0.117671</td>\n",
       "      <td>0.353633</td>\n",
       "      <td>-0.341954</td>\n",
       "      <td>0.452475</td>\n",
       "      <td>-0.233687</td>\n",
       "      <td>-0.620547</td>\n",
       "      <td>528.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>967.5</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>580.5</td>\n",
       "      <td>0.130148</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.293882</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.047361</td>\n",
       "      <td>-0.066874</td>\n",
       "      <td>0.318599</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.619365</td>\n",
       "      <td>-0.0833</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.23445</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.391509</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.668191</td>\n",
       "      <td>528.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>821.0</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.125104</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.217198</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.061767</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.622516</td>\n",
       "      <td>-0.190184</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.155524</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.129944</td>\n",
       "      <td>-0.235746</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.483655</td>\n",
       "      <td>0.560904</td>\n",
       "      <td>-0.279813</td>\n",
       "      <td>-0.726668</td>\n",
       "      <td>1006.5</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>2871.0</td>\n",
       "      <td>2812.5</td>\n",
       "      <td>2975.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>0.166977</td>\n",
       "      <td>0.261962</td>\n",
       "      <td>0.480851</td>\n",
       "      <td>0.472899</td>\n",
       "      <td>0.494412</td>\n",
       "      <td>0.383367</td>\n",
       "      <td>0.099329</td>\n",
       "      <td>0.341275</td>\n",
       "      <td>0.332149</td>\n",
       "      <td>0.356899</td>\n",
       "      <td>0.231189</td>\n",
       "      <td>0.250436</td>\n",
       "      <td>0.240763</td>\n",
       "      <td>0.267036</td>\n",
       "      <td>0.134959</td>\n",
       "      <td>-0.010293</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>-0.119516</td>\n",
       "      <td>0.028078</td>\n",
       "      <td>-0.109358</td>\n",
       "      <td>-0.137015</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3376.5</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.458289</td>\n",
       "      <td>0.451478</td>\n",
       "      <td>0.409533</td>\n",
       "      <td>0.373896</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>0.346795</td>\n",
       "      <td>0.339217</td>\n",
       "      <td>0.292869</td>\n",
       "      <td>0.253918</td>\n",
       "      <td>0.270575</td>\n",
       "      <td>0.262597</td>\n",
       "      <td>0.214029</td>\n",
       "      <td>0.173512</td>\n",
       "      <td>-0.008588</td>\n",
       "      <td>-0.060022</td>\n",
       "      <td>-0.101844</td>\n",
       "      <td>-0.051460</td>\n",
       "      <td>-0.093338</td>\n",
       "      <td>-0.042080</td>\n",
       "      <td>1566.5</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3644.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.092016</td>\n",
       "      <td>0.184433</td>\n",
       "      <td>0.373588</td>\n",
       "      <td>0.398714</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.437169</td>\n",
       "      <td>0.094013</td>\n",
       "      <td>0.291596</td>\n",
       "      <td>0.318379</td>\n",
       "      <td>0.236165</td>\n",
       "      <td>0.359619</td>\n",
       "      <td>0.203152</td>\n",
       "      <td>0.231289</td>\n",
       "      <td>0.145379</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>-0.059531</td>\n",
       "      <td>0.075992</td>\n",
       "      <td>-0.088899</td>\n",
       "      <td>0.046572</td>\n",
       "      <td>0.134913</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>3566.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>4610.0</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>0.289226</td>\n",
       "      <td>0.364474</td>\n",
       "      <td>0.486013</td>\n",
       "      <td>0.226593</td>\n",
       "      <td>0.402068</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>0.206345</td>\n",
       "      <td>0.343576</td>\n",
       "      <td>0.057846</td>\n",
       "      <td>0.248139</td>\n",
       "      <td>0.084115</td>\n",
       "      <td>0.228973</td>\n",
       "      <td>-0.067026</td>\n",
       "      <td>0.127691</td>\n",
       "      <td>0.147703</td>\n",
       "      <td>-0.150293</td>\n",
       "      <td>0.044049</td>\n",
       "      <td>-0.291525</td>\n",
       "      <td>-0.104333</td>\n",
       "      <td>0.193064</td>\n",
       "      <td>2177.5</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>6460.5</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>5562.5</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>0.26776</td>\n",
       "      <td>0.35904</td>\n",
       "      <td>0.495832</td>\n",
       "      <td>0.181775</td>\n",
       "      <td>0.437339</td>\n",
       "      <td>0.119193</td>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.370565</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.304297</td>\n",
       "      <td>0.10099</td>\n",
       "      <td>0.262988</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.189642</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>-0.345167</td>\n",
       "      <td>-0.07469</td>\n",
       "      <td>0.277634</td>\n",
       "      <td>2.170639</td>\n",
       "      <td>0.293476</td>\n",
       "      <td>2.725424</td>\n",
       "      <td>0.407873</td>\n",
       "      <td>3.562234</td>\n",
       "      <td>0.587596</td>\n",
       "      <td>2.951366</td>\n",
       "      <td>0.357374</td>\n",
       "      <td>1.865132</td>\n",
       "      <td>0.219127</td>\n",
       "      <td>4.138187</td>\n",
       "      <td>0.889063</td>\n",
       "      <td>8.700871</td>\n",
       "      <td>1.975251</td>\n",
       "      <td>14.672931</td>\n",
       "      <td>4.762204</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>0.192531</td>\n",
       "      <td>0.599399</td>\n",
       "      <td>0.161676</td>\n",
       "      <td>0.517853</td>\n",
       "      <td>0.166289</td>\n",
       "      <td>0.353151</td>\n",
       "      <td>0.126836</td>\n",
       "      <td>0.150885</td>\n",
       "      <td>0.144672</td>\n",
       "      <td>1.293571</td>\n",
       "      <td>0.361910</td>\n",
       "      <td>2.348795</td>\n",
       "      <td>0.650181</td>\n",
       "      <td>3.455724</td>\n",
       "      <td>1.000364</td>\n",
       "      <td>3.266350</td>\n",
       "      <td>0.793944</td>\n",
       "      <td>2.408488</td>\n",
       "      <td>0.564808</td>\n",
       "      <td>835.158410</td>\n",
       "      <td>941.645909</td>\n",
       "      <td>436.039478</td>\n",
       "      <td>404.926017</td>\n",
       "      <td>4264.388544</td>\n",
       "      <td>198.401495</td>\n",
       "      <td>2137.754112</td>\n",
       "      <td>5746.224836</td>\n",
       "      <td>525.904380</td>\n",
       "      <td>21718</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>16463</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3696</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>True</td>\n",
       "      <td>198.401495</td>\n",
       "      <td>0.198401</td>\n",
       "      <td>0.436039</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101101</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.450001</td>\n",
       "      <td>2014</td>\n",
       "      <td>751.090909</td>\n",
       "      <td>1025.681818</td>\n",
       "      <td>1064.590909</td>\n",
       "      <td>2898.772727</td>\n",
       "      <td>2367.969697</td>\n",
       "      <td>2978.878788</td>\n",
       "      <td>1628.833333</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.172662</td>\n",
       "      <td>0.588428</td>\n",
       "      <td>0.518386</td>\n",
       "      <td>0.597267</td>\n",
       "      <td>0.368811</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.477287</td>\n",
       "      <td>0.395529</td>\n",
       "      <td>0.487743</td>\n",
       "      <td>0.227217</td>\n",
       "      <td>0.462784</td>\n",
       "      <td>0.379710</td>\n",
       "      <td>0.473427</td>\n",
       "      <td>0.209489</td>\n",
       "      <td>-0.100784</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>-0.280488</td>\n",
       "      <td>0.114256</td>\n",
       "      <td>-0.184932</td>\n",
       "      <td>-0.292997</td>\n",
       "      <td>882.953271</td>\n",
       "      <td>1196.292640</td>\n",
       "      <td>1307.509346</td>\n",
       "      <td>2696.830607</td>\n",
       "      <td>2430.264019</td>\n",
       "      <td>2975.974299</td>\n",
       "      <td>1802.994743</td>\n",
       "      <td>0.150699</td>\n",
       "      <td>0.193820</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>0.467012</td>\n",
       "      <td>0.542384</td>\n",
       "      <td>0.342539</td>\n",
       "      <td>0.044419</td>\n",
       "      <td>0.385433</td>\n",
       "      <td>0.340260</td>\n",
       "      <td>0.426550</td>\n",
       "      <td>0.202282</td>\n",
       "      <td>0.346954</td>\n",
       "      <td>0.300381</td>\n",
       "      <td>0.389511</td>\n",
       "      <td>0.159294</td>\n",
       "      <td>-0.051992</td>\n",
       "      <td>0.049207</td>\n",
       "      <td>-0.198638</td>\n",
       "      <td>0.100941</td>\n",
       "      <td>-0.148176</td>\n",
       "      <td>-0.245446</td>\n",
       "      <td>852.426201</td>\n",
       "      <td>1155.833333</td>\n",
       "      <td>1253.487045</td>\n",
       "      <td>2645.558079</td>\n",
       "      <td>2363.480204</td>\n",
       "      <td>2973.651383</td>\n",
       "      <td>1721.327365</td>\n",
       "      <td>0.151080</td>\n",
       "      <td>0.190445</td>\n",
       "      <td>0.512619</td>\n",
       "      <td>0.469869</td>\n",
       "      <td>0.554412</td>\n",
       "      <td>0.337601</td>\n",
       "      <td>0.040532</td>\n",
       "      <td>0.391889</td>\n",
       "      <td>0.343148</td>\n",
       "      <td>0.440205</td>\n",
       "      <td>0.196546</td>\n",
       "      <td>0.357029</td>\n",
       "      <td>0.306885</td>\n",
       "      <td>0.406934</td>\n",
       "      <td>0.157267</td>\n",
       "      <td>-0.056314</td>\n",
       "      <td>0.058388</td>\n",
       "      <td>-0.211645</td>\n",
       "      <td>0.114326</td>\n",
       "      <td>-0.157205</td>\n",
       "      <td>-0.266737</td>\n",
       "      <td>900.669719</td>\n",
       "      <td>1231.398246</td>\n",
       "      <td>1361.753160</td>\n",
       "      <td>2698.222208</td>\n",
       "      <td>2521.649149</td>\n",
       "      <td>2976.173781</td>\n",
       "      <td>1873.206152</td>\n",
       "      <td>0.155121</td>\n",
       "      <td>0.203801</td>\n",
       "      <td>0.499474</td>\n",
       "      <td>0.473649</td>\n",
       "      <td>0.535359</td>\n",
       "      <td>0.350606</td>\n",
       "      <td>0.050269</td>\n",
       "      <td>0.373274</td>\n",
       "      <td>0.343788</td>\n",
       "      <td>0.414675</td>\n",
       "      <td>0.206728</td>\n",
       "      <td>0.329182</td>\n",
       "      <td>0.298680</td>\n",
       "      <td>0.372164</td>\n",
       "      <td>0.158102</td>\n",
       "      <td>-0.033827</td>\n",
       "      <td>0.048983</td>\n",
       "      <td>-0.180472</td>\n",
       "      <td>0.082674</td>\n",
       "      <td>-0.147546</td>\n",
       "      <td>-0.227445</td>\n",
       "      <td>935.339006</td>\n",
       "      <td>1282.908128</td>\n",
       "      <td>1434.059869</td>\n",
       "      <td>2749.621335</td>\n",
       "      <td>2610.562772</td>\n",
       "      <td>2978.939478</td>\n",
       "      <td>1973.581567</td>\n",
       "      <td>0.156686</td>\n",
       "      <td>0.210484</td>\n",
       "      <td>0.492348</td>\n",
       "      <td>0.472439</td>\n",
       "      <td>0.522089</td>\n",
       "      <td>0.356917</td>\n",
       "      <td>0.055633</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.340995</td>\n",
       "      <td>0.397957</td>\n",
       "      <td>0.212091</td>\n",
       "      <td>0.314451</td>\n",
       "      <td>0.290881</td>\n",
       "      <td>0.350075</td>\n",
       "      <td>0.158327</td>\n",
       "      <td>-0.025943</td>\n",
       "      <td>0.040031</td>\n",
       "      <td>-0.164304</td>\n",
       "      <td>0.065905</td>\n",
       "      <td>-0.138953</td>\n",
       "      <td>-0.202999</td>\n",
       "      <td>605.5</td>\n",
       "      <td>852.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2518.5</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>2945.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>0.169125</td>\n",
       "      <td>0.101965</td>\n",
       "      <td>0.612356</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.658921</td>\n",
       "      <td>0.286598</td>\n",
       "      <td>-0.068339</td>\n",
       "      <td>0.494437</td>\n",
       "      <td>0.398517</td>\n",
       "      <td>0.551225</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>0.454479</td>\n",
       "      <td>0.597072</td>\n",
       "      <td>0.190191</td>\n",
       "      <td>-0.119458</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>-0.395098</td>\n",
       "      <td>0.195696</td>\n",
       "      <td>-0.289294</td>\n",
       "      <td>-0.459004</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.575687</td>\n",
       "      <td>0.419184</td>\n",
       "      <td>0.68569</td>\n",
       "      <td>0.177794</td>\n",
       "      <td>-0.05007</td>\n",
       "      <td>0.458781</td>\n",
       "      <td>0.278892</td>\n",
       "      <td>0.591229</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.497425</td>\n",
       "      <td>0.324431</td>\n",
       "      <td>0.622860</td>\n",
       "      <td>0.069482</td>\n",
       "      <td>-0.206283</td>\n",
       "      <td>0.181745</td>\n",
       "      <td>-0.443262</td>\n",
       "      <td>0.374007</td>\n",
       "      <td>-0.260829</td>\n",
       "      <td>-0.57841</td>\n",
       "      <td>548.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1056.5</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>0.152359</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.43766</td>\n",
       "      <td>0.316921</td>\n",
       "      <td>0.684059</td>\n",
       "      <td>0.075885</td>\n",
       "      <td>-0.044149</td>\n",
       "      <td>0.305685</td>\n",
       "      <td>0.172911</td>\n",
       "      <td>0.593562</td>\n",
       "      <td>-0.077368</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>0.215416</td>\n",
       "      <td>0.621427</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.140183</td>\n",
       "      <td>0.351689</td>\n",
       "      <td>-0.374203</td>\n",
       "      <td>0.468762</td>\n",
       "      <td>-0.246976</td>\n",
       "      <td>-0.641472</td>\n",
       "      <td>528.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>967.5</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>580.5</td>\n",
       "      <td>0.130148</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.293882</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.047361</td>\n",
       "      <td>-0.066874</td>\n",
       "      <td>0.318599</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.619365</td>\n",
       "      <td>-0.0833</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.23445</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.391509</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.668191</td>\n",
       "      <td>528.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.125104</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.305720</td>\n",
       "      <td>0.217198</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.061767</td>\n",
       "      <td>0.187799</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.622516</td>\n",
       "      <td>-0.190184</td>\n",
       "      <td>0.246704</td>\n",
       "      <td>0.155524</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.129944</td>\n",
       "      <td>-0.094818</td>\n",
       "      <td>0.492266</td>\n",
       "      <td>-0.364948</td>\n",
       "      <td>0.560904</td>\n",
       "      <td>-0.279813</td>\n",
       "      <td>-0.726668</td>\n",
       "      <td>1120.5</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>1626.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.184052</td>\n",
       "      <td>0.508067</td>\n",
       "      <td>0.415264</td>\n",
       "      <td>0.459675</td>\n",
       "      <td>0.360901</td>\n",
       "      <td>0.053450</td>\n",
       "      <td>0.403186</td>\n",
       "      <td>0.299784</td>\n",
       "      <td>0.348930</td>\n",
       "      <td>0.240447</td>\n",
       "      <td>0.357439</td>\n",
       "      <td>0.250346</td>\n",
       "      <td>0.301096</td>\n",
       "      <td>0.189432</td>\n",
       "      <td>-0.117618</td>\n",
       "      <td>-0.063138</td>\n",
       "      <td>-0.180210</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>-0.063947</td>\n",
       "      <td>-0.118419</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.458289</td>\n",
       "      <td>0.464765</td>\n",
       "      <td>0.409942</td>\n",
       "      <td>0.377105</td>\n",
       "      <td>0.097019</td>\n",
       "      <td>0.346795</td>\n",
       "      <td>0.354013</td>\n",
       "      <td>0.293319</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.258472</td>\n",
       "      <td>0.266135</td>\n",
       "      <td>0.202050</td>\n",
       "      <td>0.164499</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>-0.059531</td>\n",
       "      <td>-0.098146</td>\n",
       "      <td>-0.067727</td>\n",
       "      <td>-0.106289</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>1566.5</td>\n",
       "      <td>2042.5</td>\n",
       "      <td>2759.5</td>\n",
       "      <td>3538.0</td>\n",
       "      <td>4717.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>4020.5</td>\n",
       "      <td>0.131892</td>\n",
       "      <td>0.275774</td>\n",
       "      <td>0.386228</td>\n",
       "      <td>0.501393</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.439234</td>\n",
       "      <td>0.149313</td>\n",
       "      <td>0.267987</td>\n",
       "      <td>0.395665</td>\n",
       "      <td>0.197682</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>0.123620</td>\n",
       "      <td>0.261820</td>\n",
       "      <td>0.049841</td>\n",
       "      <td>0.185988</td>\n",
       "      <td>0.142823</td>\n",
       "      <td>-0.074237</td>\n",
       "      <td>0.063835</td>\n",
       "      <td>-0.214782</td>\n",
       "      <td>-0.079714</td>\n",
       "      <td>0.137421</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>3566.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>4610.0</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>0.289226</td>\n",
       "      <td>0.364474</td>\n",
       "      <td>0.486013</td>\n",
       "      <td>0.226593</td>\n",
       "      <td>0.402068</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>0.206345</td>\n",
       "      <td>0.343576</td>\n",
       "      <td>0.057846</td>\n",
       "      <td>0.248139</td>\n",
       "      <td>0.084115</td>\n",
       "      <td>0.228973</td>\n",
       "      <td>-0.067026</td>\n",
       "      <td>0.127691</td>\n",
       "      <td>0.147703</td>\n",
       "      <td>-0.150293</td>\n",
       "      <td>0.044049</td>\n",
       "      <td>-0.291525</td>\n",
       "      <td>-0.104333</td>\n",
       "      <td>0.193064</td>\n",
       "      <td>2177.5</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>6460.5</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>5562.5</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>0.26776</td>\n",
       "      <td>0.35904</td>\n",
       "      <td>0.495832</td>\n",
       "      <td>0.181775</td>\n",
       "      <td>0.437339</td>\n",
       "      <td>0.119193</td>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.370565</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.304297</td>\n",
       "      <td>0.10099</td>\n",
       "      <td>0.262988</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.189642</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>-0.345167</td>\n",
       "      <td>-0.07469</td>\n",
       "      <td>0.277634</td>\n",
       "      <td>2.117678</td>\n",
       "      <td>0.201614</td>\n",
       "      <td>2.842941</td>\n",
       "      <td>0.437466</td>\n",
       "      <td>3.841434</td>\n",
       "      <td>0.654410</td>\n",
       "      <td>3.015690</td>\n",
       "      <td>0.360669</td>\n",
       "      <td>1.917362</td>\n",
       "      <td>0.231283</td>\n",
       "      <td>4.138187</td>\n",
       "      <td>0.889063</td>\n",
       "      <td>8.700871</td>\n",
       "      <td>1.975251</td>\n",
       "      <td>14.672931</td>\n",
       "      <td>4.762204</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>0.192531</td>\n",
       "      <td>0.676076</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.526063</td>\n",
       "      <td>0.164093</td>\n",
       "      <td>0.353151</td>\n",
       "      <td>0.126836</td>\n",
       "      <td>0.153663</td>\n",
       "      <td>0.146517</td>\n",
       "      <td>1.114580</td>\n",
       "      <td>0.318461</td>\n",
       "      <td>2.305804</td>\n",
       "      <td>0.647746</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>1.005897</td>\n",
       "      <td>3.257961</td>\n",
       "      <td>0.780742</td>\n",
       "      <td>2.435950</td>\n",
       "      <td>0.603529</td>\n",
       "      <td>935.281177</td>\n",
       "      <td>810.825640</td>\n",
       "      <td>172.826623</td>\n",
       "      <td>143.811329</td>\n",
       "      <td>4021.808418</td>\n",
       "      <td>65.477003</td>\n",
       "      <td>1995.596901</td>\n",
       "      <td>5570.187783</td>\n",
       "      <td>262.127174</td>\n",
       "      <td>21718</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>16463</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3696</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>65.477003</td>\n",
       "      <td>0.065477</td>\n",
       "      <td>0.172827</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101236</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>2014</td>\n",
       "      <td>1021.914286</td>\n",
       "      <td>1332.514286</td>\n",
       "      <td>1486.414286</td>\n",
       "      <td>2578.542857</td>\n",
       "      <td>2433.100000</td>\n",
       "      <td>2968.657143</td>\n",
       "      <td>2051.771429</td>\n",
       "      <td>0.131922</td>\n",
       "      <td>0.185183</td>\n",
       "      <td>0.432342</td>\n",
       "      <td>0.408446</td>\n",
       "      <td>0.487836</td>\n",
       "      <td>0.335056</td>\n",
       "      <td>0.054595</td>\n",
       "      <td>0.318591</td>\n",
       "      <td>0.292273</td>\n",
       "      <td>0.380395</td>\n",
       "      <td>0.212528</td>\n",
       "      <td>0.268669</td>\n",
       "      <td>0.241531</td>\n",
       "      <td>0.332709</td>\n",
       "      <td>0.159787</td>\n",
       "      <td>-0.029021</td>\n",
       "      <td>0.070326</td>\n",
       "      <td>-0.113766</td>\n",
       "      <td>0.099145</td>\n",
       "      <td>-0.085026</td>\n",
       "      <td>-0.182631</td>\n",
       "      <td>893.079651</td>\n",
       "      <td>1200.573837</td>\n",
       "      <td>1309.695349</td>\n",
       "      <td>2710.627326</td>\n",
       "      <td>2416.260465</td>\n",
       "      <td>2976.404070</td>\n",
       "      <td>1805.411628</td>\n",
       "      <td>0.146870</td>\n",
       "      <td>0.189132</td>\n",
       "      <td>0.504355</td>\n",
       "      <td>0.460267</td>\n",
       "      <td>0.538399</td>\n",
       "      <td>0.338090</td>\n",
       "      <td>0.043470</td>\n",
       "      <td>0.386084</td>\n",
       "      <td>0.336119</td>\n",
       "      <td>0.425147</td>\n",
       "      <td>0.201211</td>\n",
       "      <td>0.348463</td>\n",
       "      <td>0.296988</td>\n",
       "      <td>0.388864</td>\n",
       "      <td>0.159133</td>\n",
       "      <td>-0.057416</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>-0.200445</td>\n",
       "      <td>0.103871</td>\n",
       "      <td>-0.144694</td>\n",
       "      <td>-0.244884</td>\n",
       "      <td>855.633217</td>\n",
       "      <td>1159.430350</td>\n",
       "      <td>1255.376195</td>\n",
       "      <td>2666.390096</td>\n",
       "      <td>2358.199537</td>\n",
       "      <td>2974.874747</td>\n",
       "      <td>1718.730959</td>\n",
       "      <td>0.150763</td>\n",
       "      <td>0.189361</td>\n",
       "      <td>0.514124</td>\n",
       "      <td>0.467531</td>\n",
       "      <td>0.553253</td>\n",
       "      <td>0.335266</td>\n",
       "      <td>0.039732</td>\n",
       "      <td>0.393892</td>\n",
       "      <td>0.340789</td>\n",
       "      <td>0.439117</td>\n",
       "      <td>0.194326</td>\n",
       "      <td>0.359790</td>\n",
       "      <td>0.305189</td>\n",
       "      <td>0.406477</td>\n",
       "      <td>0.155796</td>\n",
       "      <td>-0.061336</td>\n",
       "      <td>0.054684</td>\n",
       "      <td>-0.216108</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>-0.156850</td>\n",
       "      <td>-0.267629</td>\n",
       "      <td>899.990914</td>\n",
       "      <td>1230.224449</td>\n",
       "      <td>1360.067663</td>\n",
       "      <td>2686.084160</td>\n",
       "      <td>2499.598209</td>\n",
       "      <td>2976.756799</td>\n",
       "      <td>1868.145895</td>\n",
       "      <td>0.155024</td>\n",
       "      <td>0.203569</td>\n",
       "      <td>0.498064</td>\n",
       "      <td>0.470530</td>\n",
       "      <td>0.535698</td>\n",
       "      <td>0.349750</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.371743</td>\n",
       "      <td>0.340331</td>\n",
       "      <td>0.415151</td>\n",
       "      <td>0.205889</td>\n",
       "      <td>0.327723</td>\n",
       "      <td>0.295241</td>\n",
       "      <td>0.372782</td>\n",
       "      <td>0.157387</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>-0.179600</td>\n",
       "      <td>0.087131</td>\n",
       "      <td>-0.144572</td>\n",
       "      <td>-0.228820</td>\n",
       "      <td>936.519885</td>\n",
       "      <td>1283.836889</td>\n",
       "      <td>1433.614776</td>\n",
       "      <td>2744.706764</td>\n",
       "      <td>2603.883918</td>\n",
       "      <td>2979.217904</td>\n",
       "      <td>1971.223420</td>\n",
       "      <td>0.156424</td>\n",
       "      <td>0.209733</td>\n",
       "      <td>0.491191</td>\n",
       "      <td>0.470953</td>\n",
       "      <td>0.521664</td>\n",
       "      <td>0.355844</td>\n",
       "      <td>0.055117</td>\n",
       "      <td>0.362630</td>\n",
       "      <td>0.339543</td>\n",
       "      <td>0.397692</td>\n",
       "      <td>0.211175</td>\n",
       "      <td>0.313784</td>\n",
       "      <td>0.289850</td>\n",
       "      <td>0.350252</td>\n",
       "      <td>0.157896</td>\n",
       "      <td>-0.026329</td>\n",
       "      <td>0.040970</td>\n",
       "      <td>-0.164015</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>-0.138283</td>\n",
       "      <td>-0.203617</td>\n",
       "      <td>652.5</td>\n",
       "      <td>905.5</td>\n",
       "      <td>859.5</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>2072.5</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>1185.5</td>\n",
       "      <td>0.162388</td>\n",
       "      <td>0.136905</td>\n",
       "      <td>0.555745</td>\n",
       "      <td>0.521101</td>\n",
       "      <td>0.637752</td>\n",
       "      <td>0.289989</td>\n",
       "      <td>-0.026062</td>\n",
       "      <td>0.432377</td>\n",
       "      <td>0.391874</td>\n",
       "      <td>0.530281</td>\n",
       "      <td>0.133907</td>\n",
       "      <td>0.453331</td>\n",
       "      <td>0.413711</td>\n",
       "      <td>0.548760</td>\n",
       "      <td>0.159413</td>\n",
       "      <td>-0.048766</td>\n",
       "      <td>0.127030</td>\n",
       "      <td>-0.316813</td>\n",
       "      <td>0.174714</td>\n",
       "      <td>-0.272253</td>\n",
       "      <td>-0.426672</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.595423</td>\n",
       "      <td>0.419184</td>\n",
       "      <td>0.68569</td>\n",
       "      <td>0.177794</td>\n",
       "      <td>-0.05007</td>\n",
       "      <td>0.482167</td>\n",
       "      <td>0.278892</td>\n",
       "      <td>0.591229</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.519691</td>\n",
       "      <td>0.324431</td>\n",
       "      <td>0.622860</td>\n",
       "      <td>0.069482</td>\n",
       "      <td>-0.234857</td>\n",
       "      <td>0.152549</td>\n",
       "      <td>-0.467074</td>\n",
       "      <td>0.374007</td>\n",
       "      <td>-0.260829</td>\n",
       "      <td>-0.57841</td>\n",
       "      <td>548.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2934.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>0.158864</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.43766</td>\n",
       "      <td>0.337364</td>\n",
       "      <td>0.685238</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>-0.050800</td>\n",
       "      <td>0.299629</td>\n",
       "      <td>0.188608</td>\n",
       "      <td>0.590675</td>\n",
       "      <td>-0.047157</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>0.237136</td>\n",
       "      <td>0.622788</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>-0.117671</td>\n",
       "      <td>0.353633</td>\n",
       "      <td>-0.341954</td>\n",
       "      <td>0.452475</td>\n",
       "      <td>-0.233687</td>\n",
       "      <td>-0.620547</td>\n",
       "      <td>528.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>967.5</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>580.5</td>\n",
       "      <td>0.130148</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.293882</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.047361</td>\n",
       "      <td>-0.066874</td>\n",
       "      <td>0.318599</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.619365</td>\n",
       "      <td>-0.0833</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.23445</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.391509</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.668191</td>\n",
       "      <td>528.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>821.0</td>\n",
       "      <td>2918.5</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.125104</td>\n",
       "      <td>0.06383</td>\n",
       "      <td>0.430881</td>\n",
       "      <td>0.217198</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.061767</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.622516</td>\n",
       "      <td>-0.190184</td>\n",
       "      <td>0.377432</td>\n",
       "      <td>0.155524</td>\n",
       "      <td>0.658946</td>\n",
       "      <td>-0.129944</td>\n",
       "      <td>-0.235746</td>\n",
       "      <td>0.374706</td>\n",
       "      <td>-0.483655</td>\n",
       "      <td>0.560904</td>\n",
       "      <td>-0.279813</td>\n",
       "      <td>-0.726668</td>\n",
       "      <td>1193.5</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>2735.5</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>0.132788</td>\n",
       "      <td>0.183792</td>\n",
       "      <td>0.438815</td>\n",
       "      <td>0.392466</td>\n",
       "      <td>0.434159</td>\n",
       "      <td>0.348793</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>0.273955</td>\n",
       "      <td>0.319808</td>\n",
       "      <td>0.226495</td>\n",
       "      <td>0.277395</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.272077</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.055992</td>\n",
       "      <td>-0.005752</td>\n",
       "      <td>-0.106291</td>\n",
       "      <td>0.050256</td>\n",
       "      <td>-0.050600</td>\n",
       "      <td>-0.100600</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>0.423539</td>\n",
       "      <td>0.430268</td>\n",
       "      <td>0.373423</td>\n",
       "      <td>0.339506</td>\n",
       "      <td>0.061861</td>\n",
       "      <td>0.326511</td>\n",
       "      <td>0.333843</td>\n",
       "      <td>0.272272</td>\n",
       "      <td>0.235926</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.277717</td>\n",
       "      <td>0.214016</td>\n",
       "      <td>0.176642</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>-0.059531</td>\n",
       "      <td>-0.098146</td>\n",
       "      <td>-0.067727</td>\n",
       "      <td>-0.106289</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>1566.5</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>4114.0</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.108550</td>\n",
       "      <td>0.184433</td>\n",
       "      <td>0.373588</td>\n",
       "      <td>0.448464</td>\n",
       "      <td>0.327322</td>\n",
       "      <td>0.437169</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>0.276240</td>\n",
       "      <td>0.357308</td>\n",
       "      <td>0.226831</td>\n",
       "      <td>0.344990</td>\n",
       "      <td>0.203152</td>\n",
       "      <td>0.287838</td>\n",
       "      <td>0.152069</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.089946</td>\n",
       "      <td>-0.052712</td>\n",
       "      <td>0.075992</td>\n",
       "      <td>-0.141985</td>\n",
       "      <td>-0.014050</td>\n",
       "      <td>0.128191</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>3566.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>5684.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>4610.0</td>\n",
       "      <td>0.170989</td>\n",
       "      <td>0.289226</td>\n",
       "      <td>0.364474</td>\n",
       "      <td>0.486013</td>\n",
       "      <td>0.226593</td>\n",
       "      <td>0.402068</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>0.206345</td>\n",
       "      <td>0.343576</td>\n",
       "      <td>0.057846</td>\n",
       "      <td>0.248139</td>\n",
       "      <td>0.084115</td>\n",
       "      <td>0.228973</td>\n",
       "      <td>-0.067026</td>\n",
       "      <td>0.127691</td>\n",
       "      <td>0.147703</td>\n",
       "      <td>-0.150293</td>\n",
       "      <td>0.044049</td>\n",
       "      <td>-0.291525</td>\n",
       "      <td>-0.104333</td>\n",
       "      <td>0.193064</td>\n",
       "      <td>2177.5</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>6460.5</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>5562.5</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>0.26776</td>\n",
       "      <td>0.35904</td>\n",
       "      <td>0.495832</td>\n",
       "      <td>0.181775</td>\n",
       "      <td>0.437339</td>\n",
       "      <td>0.119193</td>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.370565</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.304297</td>\n",
       "      <td>0.10099</td>\n",
       "      <td>0.262988</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.189642</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>-0.345167</td>\n",
       "      <td>-0.07469</td>\n",
       "      <td>0.277634</td>\n",
       "      <td>2.058431</td>\n",
       "      <td>0.212049</td>\n",
       "      <td>2.758374</td>\n",
       "      <td>0.453090</td>\n",
       "      <td>3.455073</td>\n",
       "      <td>0.533627</td>\n",
       "      <td>3.016406</td>\n",
       "      <td>0.365598</td>\n",
       "      <td>1.875871</td>\n",
       "      <td>0.223074</td>\n",
       "      <td>4.138187</td>\n",
       "      <td>0.889063</td>\n",
       "      <td>7.454411</td>\n",
       "      <td>2.258553</td>\n",
       "      <td>14.276131</td>\n",
       "      <td>4.574316</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>17.945522</td>\n",
       "      <td>4.504748</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>0.192531</td>\n",
       "      <td>0.599399</td>\n",
       "      <td>0.161676</td>\n",
       "      <td>0.517853</td>\n",
       "      <td>0.166289</td>\n",
       "      <td>0.353151</td>\n",
       "      <td>0.126836</td>\n",
       "      <td>0.151178</td>\n",
       "      <td>0.144790</td>\n",
       "      <td>1.199479</td>\n",
       "      <td>0.357367</td>\n",
       "      <td>2.082428</td>\n",
       "      <td>0.658928</td>\n",
       "      <td>3.127103</td>\n",
       "      <td>0.814121</td>\n",
       "      <td>3.290289</td>\n",
       "      <td>0.789950</td>\n",
       "      <td>2.409227</td>\n",
       "      <td>0.565287</td>\n",
       "      <td>794.660657</td>\n",
       "      <td>748.261101</td>\n",
       "      <td>256.930948</td>\n",
       "      <td>256.773891</td>\n",
       "      <td>4151.273547</td>\n",
       "      <td>35.532442</td>\n",
       "      <td>1958.231310</td>\n",
       "      <td>5542.517836</td>\n",
       "      <td>386.386906</td>\n",
       "      <td>21718</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>16463</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3696</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.532442</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>0.256931</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  survey_round  province  psu  locality  period  treatment  panel  \\\n",
       "0  100389  3             1         1    1         2       0.0        0       \n",
       "1  100401  3             1         1    1         2       0.0        0       \n",
       "2  100581  3             1         1    1         2       0.0        0       \n",
       "3  101101  3             1         1    1         2       0.0        1       \n",
       "4  101236  3             1         1    1         2       0.0        0       \n",
       "\n",
       "   present11  present13  present16  hh_size  income_last_month_N_NAs  \\\n",
       "0  1          1          0          5        5                         \n",
       "1  1          1          0          9        9                         \n",
       "2  1          1          0          9        9                         \n",
       "3  1          1          1          5        5                         \n",
       "4  1          0          0          5        5                         \n",
       "\n",
       "   income_last_month  income_last_year_N_NAs  income_last_year    pscores  \\\n",
       "0  0                  5                       0.0               26.920000   \n",
       "1  0                  9                       0.0               11.150000   \n",
       "2  0                  9                       0.0               5.750000    \n",
       "3  0                  5                       0.0               21.450001   \n",
       "4  0                  5                       0.0               41.500000   \n",
       "\n",
       "   year  b1_buff_0.1km_mean  b2_buff_0.1km_mean  b3_buff_0.1km_mean  \\\n",
       "0  2014  1056.785714         1373.214286         1540.428571          \n",
       "1  2014  743.375000          1016.652778         1042.680556          \n",
       "2  2014  871.454545          1210.090909         1327.393939          \n",
       "3  2014  751.090909          1025.681818         1064.590909          \n",
       "4  2014  1021.914286         1332.514286         1486.414286          \n",
       "\n",
       "   b4_buff_0.1km_mean  b5_buff_0.1km_mean  b6_buff_0.1km_mean  \\\n",
       "0  2611.642857         2525.228571         2972.257143          \n",
       "1  2921.305556         2363.236111         2977.208333          \n",
       "2  2671.969697         2431.469697         2966.969697          \n",
       "3  2898.772727         2367.969697         2978.878788          \n",
       "4  2578.542857         2433.100000         2968.657143          \n",
       "\n",
       "   b7_buff_0.1km_mean  b12_buff_0.1km_mean  b13_buff_0.1km_mean  \\\n",
       "0  2108.014286         0.130218             0.186216              \n",
       "1  1601.250000         0.155269             0.167579              \n",
       "2  1777.166667         0.162685             0.207354              \n",
       "3  1628.833333         0.154545             0.172662              \n",
       "4  2051.771429         0.131922             0.185183              \n",
       "\n",
       "   b14_buff_0.1km_mean  b15_buff_0.1km_mean  b16_buff_0.1km_mean  \\\n",
       "0  0.423848             0.409949             0.475416              \n",
       "1  0.594303             0.521424             0.600399              \n",
       "2  0.508129             0.472313             0.545931              \n",
       "3  0.588428             0.518386             0.597267              \n",
       "4  0.432342             0.408446             0.487836              \n",
       "\n",
       "   b17_buff_0.1km_mean  b23_buff_0.1km_mean  b24_buff_0.1km_mean  \\\n",
       "0  0.332163             0.057390             0.310784              \n",
       "1  0.365890             0.012639             0.483665              \n",
       "2  0.341956             0.046228             0.376573              \n",
       "3  0.368811             0.018614             0.477287              \n",
       "4  0.335056             0.054595             0.318591              \n",
       "\n",
       "   b25_buff_0.1km_mean  b26_buff_0.1km_mean  b27_buff_0.1km_mean  \\\n",
       "0  0.295506             0.367979             0.211075              \n",
       "1  0.398411             0.490892             0.223307              \n",
       "2  0.335400             0.420602             0.189832              \n",
       "3  0.395529             0.487743             0.227217              \n",
       "4  0.292273             0.380395             0.212528              \n",
       "\n",
       "   b34_buff_0.1km_mean  b35_buff_0.1km_mean  b36_buff_0.1km_mean  \\\n",
       "0  0.257995             0.242224             0.317290              \n",
       "1  0.473923             0.387724             0.481239              \n",
       "2  0.336197             0.293726             0.381797              \n",
       "3  0.462784             0.379710             0.473427              \n",
       "4  0.268669             0.241531             0.332709              \n",
       "\n",
       "   b37_buff_0.1km_mean  b45_buff_0.1km_mean  b46_buff_0.1km_mean  \\\n",
       "0  0.155569            -0.016822             0.064581              \n",
       "1  0.211265            -0.105604             0.009477              \n",
       "2  0.144875            -0.047125             0.052315              \n",
       "3  0.209489            -0.100784             0.013629              \n",
       "4  0.159787            -0.029021             0.070326              \n",
       "\n",
       "   b47_buff_0.1km_mean  b56_buff_0.1km_mean  b57_buff_0.1km_mean  \\\n",
       "0 -0.106709             0.081315            -0.090048              \n",
       "1 -0.291883             0.114967            -0.192203              \n",
       "2 -0.201118             0.099195            -0.155467              \n",
       "3 -0.280488             0.114256            -0.184932              \n",
       "4 -0.113766             0.099145            -0.085026              \n",
       "\n",
       "   b67_buff_0.1km_mean  b1_buff_0.5km_mean  b2_buff_0.5km_mean  \\\n",
       "0 -0.170117             891.881366          1193.380208          \n",
       "1 -0.300529             878.931634          1192.610081          \n",
       "2 -0.250794             844.847725          1150.935239          \n",
       "3 -0.292997             882.953271          1196.292640          \n",
       "4 -0.182631             893.079651          1200.573837          \n",
       "\n",
       "   b3_buff_0.5km_mean  b4_buff_0.5km_mean  b5_buff_0.5km_mean  \\\n",
       "0  1297.281250         2676.481481         2382.572338          \n",
       "1  1304.334878         2695.401506         2430.099073          \n",
       "2  1252.122520         2744.125438         2381.855893          \n",
       "3  1307.509346         2696.830607         2430.264019          \n",
       "4  1309.695349         2710.627326         2416.260465          \n",
       "\n",
       "   b6_buff_0.5km_mean  b7_buff_0.5km_mean  b12_buff_0.5km_mean  \\\n",
       "0  2977.039931         1781.468750         0.144586              \n",
       "1  2975.713789         1801.095017         0.151423              \n",
       "2  2974.625438         1747.780630         0.153367              \n",
       "3  2975.974299         1802.994743         0.150699              \n",
       "4  2976.404070         1805.411628         0.146870              \n",
       "\n",
       "   b13_buff_0.5km_mean  b14_buff_0.5km_mean  b15_buff_0.5km_mean  \\\n",
       "0  0.185185             0.500117             0.455249              \n",
       "1  0.194847             0.508198             0.468768              \n",
       "2  0.194221             0.529198             0.476340              \n",
       "3  0.193820             0.506700             0.467012              \n",
       "4  0.189132             0.504355             0.460267              \n",
       "\n",
       "   b16_buff_0.5km_mean  b17_buff_0.5km_mean  b23_buff_0.5km_mean  \\\n",
       "0  0.538951             0.332761             0.041716              \n",
       "1  0.543962             0.344087             0.044745              \n",
       "2  0.557610             0.348269             0.042108              \n",
       "3  0.542384             0.342539             0.044419              \n",
       "4  0.538399             0.338090             0.043470              \n",
       "\n",
       "   b24_buff_0.5km_mean  b25_buff_0.5km_mean  b26_buff_0.5km_mean  \\\n",
       "0  0.383244             0.332553             0.427693              \n",
       "1  0.386519             0.341592             0.427775              \n",
       "2  0.409028             0.348427             0.442047              \n",
       "3  0.385433             0.340260             0.426550              \n",
       "4  0.386084             0.336119             0.425147              \n",
       "\n",
       "   b27_buff_0.5km_mean  b34_buff_0.5km_mean  b35_buff_0.5km_mean  \\\n",
       "0  0.197687             0.347077             0.294928              \n",
       "1  0.203255             0.347790             0.301455              \n",
       "2  0.205900             0.373351             0.310881              \n",
       "3  0.202282             0.346954             0.300381              \n",
       "4  0.201211             0.348463             0.296988              \n",
       "\n",
       "   b36_buff_0.5km_mean  b37_buff_0.5km_mean  b45_buff_0.5km_mean  \\\n",
       "0  0.392988             0.157268            -0.058096              \n",
       "1  0.390505             0.159965            -0.051761              \n",
       "2  0.407524             0.165225            -0.070673              \n",
       "3  0.389511             0.159294            -0.051992              \n",
       "4  0.388864             0.159133            -0.057416              \n",
       "\n",
       "   b46_buff_0.5km_mean  b47_buff_0.5km_mean  b56_buff_0.5km_mean  \\\n",
       "0  0.053163            -0.200768             0.110916              \n",
       "1  0.049428            -0.198890             0.100931              \n",
       "2  0.040306            -0.221809             0.110664              \n",
       "3  0.049207            -0.198638             0.100941              \n",
       "4  0.046734            -0.200445             0.103871              \n",
       "\n",
       "   b57_buff_0.5km_mean  b67_buff_0.5km_mean  b1_buff_1km_mean  \\\n",
       "0 -0.144356            -0.251249             864.196688         \n",
       "1 -0.148659            -0.245900             852.733208         \n",
       "2 -0.153543            -0.259792             853.438755         \n",
       "3 -0.148176            -0.245446             852.426201         \n",
       "4 -0.144694            -0.244884             855.633217         \n",
       "\n",
       "   b2_buff_1km_mean  b3_buff_1km_mean  b4_buff_1km_mean  b5_buff_1km_mean  \\\n",
       "0  1170.219059       1269.005375       2682.513655       2375.380593        \n",
       "1  1156.635061       1255.240012       2644.950926       2367.389548        \n",
       "2  1166.697992       1275.906314       2675.079430       2387.659878        \n",
       "3  1155.833333       1253.487045       2645.558079       2363.480204        \n",
       "4  1159.430350       1255.376195       2666.390096       2358.199537        \n",
       "\n",
       "   b6_buff_1km_mean  b7_buff_1km_mean  b12_buff_1km_mean  b13_buff_1km_mean  \\\n",
       "0  2975.853428       1738.178385       0.150423           0.189766            \n",
       "1  2973.689346       1724.653445       0.151242           0.190945            \n",
       "2  2975.803317       1760.362671       0.155068           0.198403            \n",
       "3  2973.651383       1721.327365       0.151080           0.190445            \n",
       "4  2974.874747       1718.730959       0.150763           0.189361            \n",
       "\n",
       "   b14_buff_1km_mean  b15_buff_1km_mean  b16_buff_1km_mean  b17_buff_1km_mean  \\\n",
       "0  0.512677           0.466476           0.549903           0.335840            \n",
       "1  0.512401           0.470372           0.554292           0.338296            \n",
       "2  0.516262           0.473365           0.554252           0.346975            \n",
       "3  0.512619           0.469869           0.554412           0.337601            \n",
       "4  0.514124           0.467531           0.553253           0.335266            \n",
       "\n",
       "   b23_buff_1km_mean  b24_buff_1km_mean  b25_buff_1km_mean  b26_buff_1km_mean  \\\n",
       "0  0.040499           0.392525           0.339903           0.435505            \n",
       "1  0.040883           0.391499           0.343572           0.439930            \n",
       "2  0.044710           0.392626           0.343511           0.436718            \n",
       "3  0.040532           0.391889           0.343148           0.440205            \n",
       "4  0.039732           0.393892           0.340789           0.439117            \n",
       "\n",
       "   b27_buff_1km_mean  b34_buff_1km_mean  b35_buff_1km_mean  b36_buff_1km_mean  \\\n",
       "0  0.195283           0.357713           0.303583           0.402098            \n",
       "1  0.197140           0.356319           0.307001           0.406356            \n",
       "2  0.202819           0.354133           0.303462           0.399815            \n",
       "3  0.196546           0.357029           0.306885           0.406934            \n",
       "4  0.194326           0.359790           0.305189           0.406477            \n",
       "\n",
       "   b37_buff_1km_mean  b45_buff_1km_mean  b46_buff_1km_mean  b47_buff_1km_mean  \\\n",
       "0  0.156017          -0.060724           0.051842          -0.213617            \n",
       "1  0.157527          -0.055376           0.058509          -0.210613            \n",
       "2  0.159556          -0.056772           0.053217          -0.206229            \n",
       "3  0.157267          -0.056314           0.058388          -0.211645            \n",
       "4  0.155796          -0.061336           0.054684          -0.216108            \n",
       "\n",
       "   b56_buff_1km_mean  b57_buff_1km_mean  b67_buff_1km_mean  \\\n",
       "0  0.112212          -0.154903          -0.262551            \n",
       "1  0.113516          -0.157070          -0.265846            \n",
       "2  0.109657          -0.151228          -0.256630            \n",
       "3  0.114326          -0.157205          -0.266737            \n",
       "4  0.115632          -0.156850          -0.267629            \n",
       "\n",
       "   b1_buff_1.5km_mean  b2_buff_1.5km_mean  b3_buff_1.5km_mean  \\\n",
       "0  896.841959          1224.147199         1349.684047          \n",
       "1  900.591837          1231.457892         1361.784293          \n",
       "2  886.069310          1217.299871         1349.368150          \n",
       "3  900.669719          1231.398246         1361.753160          \n",
       "4  899.990914          1230.224449         1360.067663          \n",
       "\n",
       "   b4_buff_1.5km_mean  b5_buff_1.5km_mean  b6_buff_1.5km_mean  \\\n",
       "0  2677.504646         2473.518715         2977.033880          \n",
       "1  2699.590287         2523.612439         2976.143245          \n",
       "2  2682.571631         2485.190135         2976.657834          \n",
       "3  2698.222208         2521.649149         2976.173781          \n",
       "4  2686.084160         2499.598209         2976.756799          \n",
       "\n",
       "   b7_buff_1.5km_mean  b12_buff_1.5km_mean  b13_buff_1.5km_mean  \\\n",
       "0  1849.332279         0.154317             0.201574              \n",
       "1  1873.686321         0.155187             0.203853              \n",
       "2  1857.821019         0.157476             0.207252              \n",
       "3  1873.206152         0.155121             0.203801              \n",
       "4  1868.145895         0.155024             0.203569              \n",
       "\n",
       "   b14_buff_1.5km_mean  b15_buff_1.5km_mean  b16_buff_1.5km_mean  \\\n",
       "0  0.498179             0.467807             0.536980              \n",
       "1  0.499697             0.473985             0.535386              \n",
       "2  0.503414             0.474339             0.541221              \n",
       "3  0.499474             0.473649             0.535359              \n",
       "4  0.498064             0.470530             0.535698              \n",
       "\n",
       "   b17_buff_1.5km_mean  b23_buff_1.5km_mean  b24_buff_1.5km_mean  \\\n",
       "0  0.346843             0.048774             0.372498              \n",
       "1  0.350756             0.050256             0.373471              \n",
       "2  0.354151             0.051455             0.375723              \n",
       "3  0.350606             0.050269             0.373274              \n",
       "4  0.349750             0.050127             0.371743              \n",
       "\n",
       "   b25_buff_1.5km_mean  b26_buff_1.5km_mean  b27_buff_1.5km_mean  \\\n",
       "0  0.337881             0.417237             0.203413              \n",
       "1  0.344109             0.414651             0.206827              \n",
       "2  0.342443             0.419498             0.208291              \n",
       "3  0.343788             0.414675             0.206728              \n",
       "4  0.340331             0.415151             0.205889              \n",
       "\n",
       "   b34_buff_1.5km_mean  b35_buff_1.5km_mean  b36_buff_1.5km_mean  \\\n",
       "0  0.329714             0.293951             0.376116              \n",
       "1  0.329397             0.299024             0.372150              \n",
       "2  0.330661             0.296207             0.376163              \n",
       "3  0.329182             0.298680             0.372164              \n",
       "4  0.327723             0.295241             0.372782              \n",
       "\n",
       "   b37_buff_1.5km_mean  b45_buff_1.5km_mean  b46_buff_1.5km_mean  \\\n",
       "0  0.156188            -0.039601             0.052971              \n",
       "1  0.158216            -0.033692             0.048726              \n",
       "2  0.158535            -0.038195             0.051966              \n",
       "3  0.158102            -0.033827             0.048983              \n",
       "4  0.157387            -0.035962             0.051330              \n",
       "\n",
       "   b47_buff_1.5km_mean  b56_buff_1.5km_mean  b57_buff_1.5km_mean  \\\n",
       "0 -0.182947             0.092379            -0.144392              \n",
       "1 -0.180593             0.082282            -0.147801              \n",
       "2 -0.181647             0.089982            -0.144455              \n",
       "3 -0.180472             0.082674            -0.147546              \n",
       "4 -0.179600             0.087131            -0.144572              \n",
       "\n",
       "   b67_buff_1.5km_mean  b1_buff_2km_mean  b2_buff_2km_mean  b3_buff_2km_mean  \\\n",
       "0 -0.233654             936.888325        1283.219033       1430.618932        \n",
       "1 -0.227319             935.139042        1282.843795       1434.237337        \n",
       "2 -0.231429             920.696670        1265.622987       1411.402917        \n",
       "3 -0.227445             935.339006        1282.908128       1434.059869        \n",
       "4 -0.228820             936.519885        1283.836889       1433.614776        \n",
       "\n",
       "   b4_buff_2km_mean  b5_buff_2km_mean  b6_buff_2km_mean  b7_buff_2km_mean  \\\n",
       "0  2740.887780       2596.078695       2979.461795       1965.636674        \n",
       "1  2749.286865       2610.672206       2978.904935       1973.593795        \n",
       "2  2734.977180       2576.445799       2978.413655       1940.046220        \n",
       "3  2749.621335       2610.562772       2978.939478       1973.581567        \n",
       "4  2744.706764       2603.883918       2979.217904       1971.223420        \n",
       "\n",
       "   b12_buff_2km_mean  b13_buff_2km_mean  b14_buff_2km_mean  b15_buff_2km_mean  \\\n",
       "0  0.155997           0.208544           0.490514           0.469631            \n",
       "1  0.156766           0.210645           0.492383           0.472539            \n",
       "2  0.157766           0.210414           0.496292           0.473458            \n",
       "3  0.156686           0.210484           0.492348           0.472439            \n",
       "4  0.156424           0.209733           0.491191           0.470953            \n",
       "\n",
       "   b16_buff_2km_mean  b17_buff_2km_mean  b23_buff_2km_mean  b24_buff_2km_mean  \\\n",
       "0  0.521550           0.354432           0.054314           0.362234            \n",
       "1  0.522162           0.357013           0.055719           0.363689            \n",
       "2  0.527740           0.356323           0.054456           0.367283            \n",
       "3  0.522089           0.356917           0.055633           0.363720            \n",
       "4  0.521664           0.355844           0.055117           0.362630            \n",
       "\n",
       "   b25_buff_2km_mean  b26_buff_2km_mean  b27_buff_2km_mean  b34_buff_2km_mean  \\\n",
       "0  0.338427           0.397929           0.210049           0.314100            \n",
       "1  0.341036           0.397973           0.212118           0.314340            \n",
       "2  0.341176           0.403576           0.210385           0.319212            \n",
       "3  0.340995           0.397957           0.212091           0.314451            \n",
       "4  0.339543           0.397692           0.211175           0.313784            \n",
       "\n",
       "   b35_buff_2km_mean  b36_buff_2km_mean  b37_buff_2km_mean  b45_buff_2km_mean  \\\n",
       "0  0.289433           0.351205           0.157532          -0.027133            \n",
       "1  0.290843           0.350015           0.158270          -0.025861            \n",
       "2  0.292148           0.356965           0.157736          -0.029847            \n",
       "3  0.290881           0.350075           0.158327          -0.025943            \n",
       "4  0.289850           0.350252           0.157896          -0.026329            \n",
       "\n",
       "   b46_buff_2km_mean  b47_buff_2km_mean  b56_buff_2km_mean  b57_buff_2km_mean  \\\n",
       "0  0.041706          -0.164718           0.068762          -0.138203            \n",
       "1  0.040086          -0.164242           0.065878          -0.138971            \n",
       "2  0.042608          -0.170038           0.072363          -0.140906            \n",
       "3  0.040031          -0.164304           0.065905          -0.138953            \n",
       "4  0.040970          -0.164015           0.067227          -0.138283            \n",
       "\n",
       "   b67_buff_2km_mean  b1_buff_0.1km_min  b2_buff_0.1km_min  b3_buff_0.1km_min  \\\n",
       "0 -0.205016           817.0              1121.0             1339.0              \n",
       "1 -0.202991           604.5              852.0              692.0               \n",
       "2 -0.211116           690.5              995.0              982.0               \n",
       "3 -0.202999           605.5              852.0              743.0               \n",
       "4 -0.203617           652.5              905.5              859.5               \n",
       "\n",
       "   b4_buff_0.1km_min  b5_buff_0.1km_min  b6_buff_0.1km_min  b7_buff_0.1km_min  \\\n",
       "0  2327.5             2285.0             2950.0             1827.0              \n",
       "1  2518.5             1981.0             2945.0             1092.0              \n",
       "2  2413.5             1966.0             2960.0             1220.0              \n",
       "3  2518.5             1981.0             2945.0             1092.0              \n",
       "4  2285.0             2072.5             2950.0             1185.5              \n",
       "\n",
       "   b12_buff_0.1km_min  b13_buff_0.1km_min  b14_buff_0.1km_min  \\\n",
       "0  0.156863            0.242115            0.480363             \n",
       "1  0.169928            0.067489            0.612872             \n",
       "2  0.180659            0.174290            0.555090             \n",
       "3  0.169125            0.101965            0.612356             \n",
       "4  0.162388            0.136905            0.555745             \n",
       "\n",
       "   b15_buff_0.1km_min  b16_buff_0.1km_min  b17_buff_0.1km_min  \\\n",
       "0  0.473243            0.566233            0.381997             \n",
       "1  0.532392            0.659389            0.287356             \n",
       "2  0.480143            0.621696            0.277153             \n",
       "3  0.531800            0.658921            0.286598             \n",
       "4  0.521101            0.637752            0.289989             \n",
       "\n",
       "   b23_buff_0.1km_min  b24_buff_0.1km_min  b25_buff_0.1km_min  \\\n",
       "0  0.088618            0.349862            0.341750             \n",
       "1 -0.103627            0.494437            0.398517             \n",
       "2 -0.006576            0.416165            0.327930             \n",
       "3 -0.068339            0.494437            0.398517             \n",
       "4 -0.026062            0.432377            0.391874             \n",
       "\n",
       "   b26_buff_0.1km_min  b27_buff_0.1km_min  b34_buff_0.1km_min  \\\n",
       "0  0.449275            0.239484            0.269603             \n",
       "1  0.551225            0.123457            0.568914             \n",
       "2  0.496839            0.101580            0.421587             \n",
       "3  0.551225            0.123457            0.544381             \n",
       "4  0.530281            0.133907            0.453331             \n",
       "\n",
       "   b35_buff_0.1km_min  b36_buff_0.1km_min  b37_buff_0.1km_min  \\\n",
       "0  0.261038            0.375612            0.154138             \n",
       "1  0.482230            0.619467            0.224215             \n",
       "2  0.333786            0.501776            0.108084             \n",
       "3  0.454479            0.597072            0.190191             \n",
       "4  0.413711            0.548760            0.159413             \n",
       "\n",
       "   b45_buff_0.1km_min  b46_buff_0.1km_min  b47_buff_0.1km_min  \\\n",
       "0 -0.009214            0.117954           -0.120472             \n",
       "1 -0.119458            0.078064           -0.395098             \n",
       "2 -0.102181            0.101703           -0.328471             \n",
       "3 -0.119458            0.078064           -0.395098             \n",
       "4 -0.048766            0.127030           -0.316813             \n",
       "\n",
       "   b56_buff_0.1km_min  b57_buff_0.1km_min  b67_buff_0.1km_min  \\\n",
       "0  0.127030           -0.111381           -0.235085             \n",
       "1  0.195696           -0.289294           -0.459004             \n",
       "2  0.201786           -0.234149           -0.416268             \n",
       "3  0.195696           -0.289294           -0.459004             \n",
       "4  0.174714           -0.272253           -0.426672             \n",
       "\n",
       "   b1_buff_0.5km_min  b2_buff_0.5km_min  b3_buff_0.5km_min  b4_buff_0.5km_min  \\\n",
       "0  548.0              755.0              683.0              1484.0              \n",
       "1  548.0              755.0              682.0              2035.0              \n",
       "2  548.0              755.0              683.0              2285.0              \n",
       "3  548.0              755.0              683.0              2035.0              \n",
       "4  548.0              755.0              683.0              2161.0              \n",
       "\n",
       "   b5_buff_0.5km_min  b6_buff_0.5km_min  b7_buff_0.5km_min  \\\n",
       "0  1339.0             2939.0             785.0               \n",
       "1  1339.0             2939.0             785.0               \n",
       "2  1339.0             2939.0             785.0               \n",
       "3  1339.0             2939.0             785.0               \n",
       "4  1339.0             2939.0             785.0               \n",
       "\n",
       "   b12_buff_0.5km_min  b13_buff_0.5km_min  b14_buff_0.5km_min  \\\n",
       "0  0.158864            0.109667            0.460630             \n",
       "1  0.158864            0.108943            0.575687             \n",
       "2  0.158864            0.109667            0.613131             \n",
       "3  0.158864            0.109667            0.575687             \n",
       "4  0.158864            0.109667            0.595423             \n",
       "\n",
       "   b15_buff_0.5km_min  b16_buff_0.5km_min  b17_buff_0.5km_min  \\\n",
       "0  0.419184            0.68569             0.177794             \n",
       "1  0.419184            0.68569             0.177794             \n",
       "2  0.419184            0.68569             0.177794             \n",
       "3  0.419184            0.68569             0.177794             \n",
       "4  0.419184            0.68569             0.177794             \n",
       "\n",
       "   b23_buff_0.5km_min  b24_buff_0.5km_min  b25_buff_0.5km_min  \\\n",
       "0 -0.05007             0.325592            0.278892             \n",
       "1 -0.05080             0.458781            0.278892             \n",
       "2 -0.05007             0.503289            0.278892             \n",
       "3 -0.05007             0.458781            0.278892             \n",
       "4 -0.05007             0.482167            0.278892             \n",
       "\n",
       "   b26_buff_0.5km_min  b27_buff_0.5km_min  b34_buff_0.5km_min  \\\n",
       "0  0.591229            0.019481            0.369635             \n",
       "1  0.591229            0.019481            0.497976             \n",
       "2  0.591229            0.019481            0.539757             \n",
       "3  0.591229            0.019481            0.497425             \n",
       "4  0.591229            0.019481            0.519691             \n",
       "\n",
       "   b35_buff_0.5km_min  b36_buff_0.5km_min  b37_buff_0.5km_min  \\\n",
       "0  0.324431            0.622860            0.069482             \n",
       "1  0.325087            0.623308            0.070211             \n",
       "2  0.324431            0.622860            0.069482             \n",
       "3  0.324431            0.622860            0.069482             \n",
       "4  0.324431            0.622860            0.069482             \n",
       "\n",
       "   b45_buff_0.5km_min  b46_buff_0.5km_min  b47_buff_0.5km_min  \\\n",
       "0 -0.051364            0.328962           -0.308065             \n",
       "1 -0.206283            0.181745           -0.443262             \n",
       "2 -0.261038            0.125191           -0.488599             \n",
       "3 -0.206283            0.181745           -0.443262             \n",
       "4 -0.234857            0.152549           -0.467074             \n",
       "\n",
       "   b56_buff_0.5km_min  b57_buff_0.5km_min  b67_buff_0.5km_min  \\\n",
       "0  0.374007           -0.260829           -0.57841              \n",
       "1  0.374007           -0.260829           -0.57841              \n",
       "2  0.374007           -0.260829           -0.57841              \n",
       "3  0.374007           -0.260829           -0.57841              \n",
       "4  0.374007           -0.260829           -0.57841              \n",
       "\n",
       "   b1_buff_1km_min  b2_buff_1km_min  b3_buff_1km_min  b4_buff_1km_min  \\\n",
       "0  548.0            755.0            682.0            1401.0            \n",
       "1  548.0            745.0            682.0            1401.0            \n",
       "2  548.0            755.0            682.0            1401.0            \n",
       "3  548.0            745.0            682.0            1401.0            \n",
       "4  548.0            755.0            682.0            1401.0            \n",
       "\n",
       "   b5_buff_1km_min  b6_buff_1km_min  b7_buff_1km_min  b12_buff_1km_min  \\\n",
       "0  1106.0           2934.0           687.0            0.158864           \n",
       "1  1056.5           2921.0           638.0            0.152359           \n",
       "2  1106.0           2934.0           687.0            0.158864           \n",
       "3  1056.5           2921.0           638.0            0.152359           \n",
       "4  1106.0           2934.0           687.0            0.158864           \n",
       "\n",
       "   b13_buff_1km_min  b14_buff_1km_min  b15_buff_1km_min  b16_buff_1km_min  \\\n",
       "0  0.108943          0.43766           0.337364          0.685238           \n",
       "1  0.108943          0.43766           0.316921          0.684059           \n",
       "2  0.108943          0.43766           0.337364          0.685238           \n",
       "3  0.108943          0.43766           0.316921          0.684059           \n",
       "4  0.108943          0.43766           0.337364          0.685238           \n",
       "\n",
       "   b17_buff_1km_min  b23_buff_1km_min  b24_buff_1km_min  b25_buff_1km_min  \\\n",
       "0  0.112551         -0.050800          0.299629          0.188608           \n",
       "1  0.075885         -0.044149          0.305685          0.172911           \n",
       "2  0.112551         -0.050800          0.299629          0.188608           \n",
       "3  0.075885         -0.044149          0.305685          0.172911           \n",
       "4  0.112551         -0.050800          0.299629          0.188608           \n",
       "\n",
       "   b26_buff_1km_min  b27_buff_1km_min  b34_buff_1km_min  b35_buff_1km_min  \\\n",
       "0  0.590675         -0.047157          0.345175          0.237136           \n",
       "1  0.593562         -0.077368          0.345175          0.215416           \n",
       "2  0.590675         -0.047157          0.345175          0.237136           \n",
       "3  0.593562         -0.077368          0.345175          0.215416           \n",
       "4  0.590675         -0.047157          0.345175          0.237136           \n",
       "\n",
       "   b36_buff_1km_min  b37_buff_1km_min  b45_buff_1km_min  b46_buff_1km_min  \\\n",
       "0  0.622788          0.003652         -0.117671          0.353633           \n",
       "1  0.621427         -0.033333         -0.140183          0.351689           \n",
       "2  0.622788          0.003652         -0.117671          0.353633           \n",
       "3  0.621427         -0.033333         -0.140183          0.351689           \n",
       "4  0.622788          0.003652         -0.117671          0.353633           \n",
       "\n",
       "   b47_buff_1km_min  b56_buff_1km_min  b57_buff_1km_min  b67_buff_1km_min  \\\n",
       "0 -0.341954          0.452475         -0.233687         -0.620547           \n",
       "1 -0.374203          0.468762         -0.246976         -0.641472           \n",
       "2 -0.341954          0.452475         -0.233687         -0.620547           \n",
       "3 -0.374203          0.468762         -0.246976         -0.641472           \n",
       "4 -0.341954          0.452475         -0.233687         -0.620547           \n",
       "\n",
       "   b1_buff_1.5km_min  b2_buff_1.5km_min  b3_buff_1.5km_min  b4_buff_1.5km_min  \\\n",
       "0  528.0              686.0              600.0              1327.5              \n",
       "1  528.0              686.0              600.0              1327.5              \n",
       "2  528.0              686.0              600.0              1327.5              \n",
       "3  528.0              686.0              600.0              1327.5              \n",
       "4  528.0              686.0              600.0              1327.5              \n",
       "\n",
       "   b5_buff_1.5km_min  b6_buff_1.5km_min  b7_buff_1.5km_min  \\\n",
       "0  967.5              2918.5             580.5               \n",
       "1  967.5              2918.5             580.5               \n",
       "2  967.5              2918.5             580.5               \n",
       "3  967.5              2918.5             580.5               \n",
       "4  967.5              2918.5             580.5               \n",
       "\n",
       "   b12_buff_1.5km_min  b13_buff_1.5km_min  b14_buff_1.5km_min  \\\n",
       "0  0.130148            0.06383             0.430881             \n",
       "1  0.130148            0.06383             0.430881             \n",
       "2  0.130148            0.06383             0.430881             \n",
       "3  0.130148            0.06383             0.430881             \n",
       "4  0.130148            0.06383             0.430881             \n",
       "\n",
       "   b15_buff_1.5km_min  b16_buff_1.5km_min  b17_buff_1.5km_min  \\\n",
       "0  0.293882            0.693602            0.047361             \n",
       "1  0.293882            0.693602            0.047361             \n",
       "2  0.293882            0.693602            0.047361             \n",
       "3  0.293882            0.693602            0.047361             \n",
       "4  0.293882            0.693602            0.047361             \n",
       "\n",
       "   b23_buff_1.5km_min  b24_buff_1.5km_min  b25_buff_1.5km_min  \\\n",
       "0 -0.066874            0.318599            0.170245             \n",
       "1 -0.066874            0.318599            0.170245             \n",
       "2 -0.066874            0.318599            0.170245             \n",
       "3 -0.066874            0.318599            0.170245             \n",
       "4 -0.066874            0.318599            0.170245             \n",
       "\n",
       "   b26_buff_1.5km_min  b27_buff_1.5km_min  b34_buff_1.5km_min  \\\n",
       "0  0.619365           -0.0833              0.377432             \n",
       "1  0.619365           -0.0833              0.377432             \n",
       "2  0.619365           -0.0833              0.377432             \n",
       "3  0.619365           -0.0833              0.377432             \n",
       "4  0.619365           -0.0833              0.377432             \n",
       "\n",
       "   b35_buff_1.5km_min  b36_buff_1.5km_min  b37_buff_1.5km_min  \\\n",
       "0  0.23445             0.658946           -0.016518             \n",
       "1  0.23445             0.658946           -0.016518             \n",
       "2  0.23445             0.658946           -0.016518             \n",
       "3  0.23445             0.658946           -0.016518             \n",
       "4  0.23445             0.658946           -0.016518             \n",
       "\n",
       "   b45_buff_1.5km_min  b46_buff_1.5km_min  b47_buff_1.5km_min  \\\n",
       "0 -0.156863            0.374706           -0.391509             \n",
       "1 -0.156863            0.374706           -0.391509             \n",
       "2 -0.156863            0.374706           -0.391509             \n",
       "3 -0.156863            0.374706           -0.391509             \n",
       "4 -0.156863            0.374706           -0.391509             \n",
       "\n",
       "   b56_buff_1.5km_min  b57_buff_1.5km_min  b67_buff_1.5km_min  \\\n",
       "0  0.502059           -0.25               -0.668191             \n",
       "1  0.502059           -0.25               -0.668191             \n",
       "2  0.502059           -0.25               -0.668191             \n",
       "3  0.502059           -0.25               -0.668191             \n",
       "4  0.502059           -0.25               -0.668191             \n",
       "\n",
       "   b1_buff_2km_min  b2_buff_2km_min  b3_buff_2km_min  b4_buff_2km_min  \\\n",
       "0  528.0            686.0            600.0            1327.5            \n",
       "1  528.0            679.0            600.0            993.0             \n",
       "2  528.0            679.0            600.0            1327.5            \n",
       "3  528.0            679.0            600.0            993.0             \n",
       "4  528.0            679.0            600.0            1327.5            \n",
       "\n",
       "   b5_buff_2km_min  b6_buff_2km_min  b7_buff_2km_min  b12_buff_2km_min  \\\n",
       "0  967.5            2918.5           579.5            0.130148           \n",
       "1  821.0            2918.5           462.0            0.125104           \n",
       "2  821.0            2918.5           462.0            0.125104           \n",
       "3  821.0            2918.5           462.0            0.125104           \n",
       "4  821.0            2918.5           462.0            0.125104           \n",
       "\n",
       "   b13_buff_2km_min  b14_buff_2km_min  b15_buff_2km_min  b16_buff_2km_min  \\\n",
       "0  0.06383           0.430881          0.293882          0.693602           \n",
       "1  0.06383           0.305720          0.217198          0.693602           \n",
       "2  0.06383           0.430881          0.217198          0.693602           \n",
       "3  0.06383           0.305720          0.217198          0.693602           \n",
       "4  0.06383           0.430881          0.217198          0.693602           \n",
       "\n",
       "   b17_buff_2km_min  b23_buff_2km_min  b24_buff_2km_min  b25_buff_2km_min  \\\n",
       "0  0.046501         -0.066874          0.318599          0.170245           \n",
       "1 -0.066667         -0.061767          0.187799          0.094667           \n",
       "2 -0.066667         -0.061767          0.323200          0.094667           \n",
       "3 -0.066667         -0.061767          0.187799          0.094667           \n",
       "4 -0.066667         -0.061767          0.323200          0.094667           \n",
       "\n",
       "   b26_buff_2km_min  b27_buff_2km_min  b34_buff_2km_min  b35_buff_2km_min  \\\n",
       "0  0.619365         -0.084156          0.377432          0.234450           \n",
       "1  0.622516         -0.190184          0.246704          0.155524           \n",
       "2  0.622516         -0.190184          0.377432          0.155524           \n",
       "3  0.622516         -0.190184          0.246704          0.155524           \n",
       "4  0.622516         -0.190184          0.377432          0.155524           \n",
       "\n",
       "   b36_buff_2km_min  b37_buff_2km_min  b45_buff_2km_min  b46_buff_2km_min  \\\n",
       "0  0.658946         -0.017380         -0.156863          0.374706           \n",
       "1  0.658946         -0.129944         -0.094818          0.492266           \n",
       "2  0.658946         -0.129944         -0.235746          0.374706           \n",
       "3  0.658946         -0.129944         -0.094818          0.492266           \n",
       "4  0.658946         -0.129944         -0.235746          0.374706           \n",
       "\n",
       "   b47_buff_2km_min  b56_buff_2km_min  b57_buff_2km_min  b67_buff_2km_min  \\\n",
       "0 -0.392239          0.502059         -0.250808         -0.668668           \n",
       "1 -0.364948          0.560904         -0.279813         -0.726668           \n",
       "2 -0.483655          0.560904         -0.279813         -0.726668           \n",
       "3 -0.364948          0.560904         -0.279813         -0.726668           \n",
       "4 -0.483655          0.560904         -0.279813         -0.726668           \n",
       "\n",
       "   b1_buff_0.1km_max  b2_buff_0.1km_max  b3_buff_0.1km_max  b4_buff_0.1km_max  \\\n",
       "0  1205.0             1572.5             1703.0             2874.0              \n",
       "1  1120.5             1461.0             1626.0             3435.0              \n",
       "2  1006.5             1410.0             1721.0             2871.0              \n",
       "3  1120.5             1461.0             1626.0             3435.0              \n",
       "4  1193.5             1559.0             1731.0             3060.0              \n",
       "\n",
       "   b5_buff_0.1km_max  b6_buff_0.1km_max  b7_buff_0.1km_max  \\\n",
       "0  2779.5             3041.5             2472.0              \n",
       "1  2712.0             3027.0             2386.0              \n",
       "2  2812.5             2975.0             2258.0              \n",
       "3  2712.0             3027.0             2386.0              \n",
       "4  2735.5             3025.0             2472.0              \n",
       "\n",
       "   b12_buff_0.1km_max  b13_buff_0.1km_max  b14_buff_0.1km_max  \\\n",
       "0  0.132313            0.171252            0.409169             \n",
       "1  0.131900            0.184052            0.508067             \n",
       "2  0.166977            0.261962            0.480851             \n",
       "3  0.131900            0.184052            0.508067             \n",
       "4  0.132788            0.183792            0.438815             \n",
       "\n",
       "   b15_buff_0.1km_max  b16_buff_0.1km_max  b17_buff_0.1km_max  \\\n",
       "0  0.395156            0.432474            0.344574             \n",
       "1  0.415264            0.459675            0.360901             \n",
       "2  0.472899            0.494412            0.383367             \n",
       "3  0.415264            0.459675            0.360901             \n",
       "4  0.392466            0.434159            0.348793             \n",
       "\n",
       "   b23_buff_0.1km_max  b24_buff_0.1km_max  b25_buff_0.1km_max  \\\n",
       "0  0.039841            0.292702            0.277344             \n",
       "1  0.053450            0.403186            0.299784             \n",
       "2  0.099329            0.341275            0.332149             \n",
       "3  0.053450            0.403186            0.299784             \n",
       "4  0.052280            0.324962            0.273955             \n",
       "\n",
       "   b26_buff_0.1km_max  b27_buff_0.1km_max  b34_buff_0.1km_max  \\\n",
       "0  0.318379            0.222401            0.255844             \n",
       "1  0.348930            0.240447            0.357439             \n",
       "2  0.356899            0.231189            0.250436             \n",
       "3  0.348930            0.240447            0.357439             \n",
       "4  0.319808            0.226495            0.277395             \n",
       "\n",
       "   b35_buff_0.1km_max  b36_buff_0.1km_max  b37_buff_0.1km_max  \\\n",
       "0  0.240156            0.282116            0.184192             \n",
       "1  0.250346            0.301096            0.189432             \n",
       "2  0.240763            0.267036            0.134959             \n",
       "3  0.250346            0.301096            0.189432             \n",
       "4  0.224896            0.272077            0.176303             \n",
       "\n",
       "   b45_buff_0.1km_max  b46_buff_0.1km_max  b47_buff_0.1km_max  \\\n",
       "0 -0.016715            0.028315           -0.075196             \n",
       "1 -0.117618           -0.063138           -0.180210             \n",
       "2 -0.010293            0.017790           -0.119516             \n",
       "3 -0.117618           -0.063138           -0.180210             \n",
       "4 -0.055992           -0.005752           -0.106291             \n",
       "\n",
       "   b56_buff_0.1km_max  b57_buff_0.1km_max  b67_buff_0.1km_max  \\\n",
       "0  0.045009           -0.058555           -0.103292             \n",
       "1  0.054888           -0.063947           -0.118419             \n",
       "2  0.028078           -0.109358           -0.137015             \n",
       "3  0.054888           -0.063947           -0.118419             \n",
       "4  0.050256           -0.050600           -0.100600             \n",
       "\n",
       "   b1_buff_0.5km_max  b2_buff_0.5km_max  b3_buff_0.5km_max  b4_buff_0.5km_max  \\\n",
       "0  1391.0             1744.0             1972.0             3435.0              \n",
       "1  1276.0             1666.5             2024.0             3435.0              \n",
       "2  1276.0             1666.0             1972.0             3435.0              \n",
       "3  1276.0             1666.0             2024.0             3435.0              \n",
       "4  1391.0             1744.0             1974.0             3435.0              \n",
       "\n",
       "   b5_buff_0.5km_max  b6_buff_0.5km_max  b7_buff_0.5km_max  \\\n",
       "0  3492.0             3049.0             2793.0              \n",
       "1  3492.0             3048.5             2821.0              \n",
       "2  3376.5             3046.0             2800.0              \n",
       "3  3492.0             3049.0             2821.0              \n",
       "4  3492.0             3049.0             2821.0              \n",
       "\n",
       "   b12_buff_0.5km_max  b13_buff_0.5km_max  b14_buff_0.5km_max  \\\n",
       "0  0.112600            0.172762            0.423539             \n",
       "1  0.132710            0.226667            0.458289             \n",
       "2  0.132563            0.214286            0.458289             \n",
       "3  0.132563            0.226667            0.458289             \n",
       "4  0.112600            0.173254            0.423539             \n",
       "\n",
       "   b15_buff_0.5km_max  b16_buff_0.5km_max  b17_buff_0.5km_max  \\\n",
       "0  0.430268            0.373423            0.335086             \n",
       "1  0.464765            0.409874            0.377105             \n",
       "2  0.451478            0.409533            0.373896             \n",
       "3  0.464765            0.409942            0.377105             \n",
       "4  0.430268            0.373423            0.339506             \n",
       "\n",
       "   b23_buff_0.5km_max  b24_buff_0.5km_max  b25_buff_0.5km_max  \\\n",
       "0  0.061356            0.326511            0.333843             \n",
       "1  0.096870            0.346663            0.353882             \n",
       "2  0.084112            0.346795            0.339217             \n",
       "3  0.097019            0.346795            0.354013             \n",
       "4  0.061861            0.326511            0.333843             \n",
       "\n",
       "   b26_buff_0.5km_max  b27_buff_0.5km_max  b34_buff_0.5km_max  \\\n",
       "0  0.272272            0.231210            0.270575             \n",
       "1  0.293107            0.257270            0.258472             \n",
       "2  0.292869            0.253918            0.270575             \n",
       "3  0.293319            0.257410            0.258472             \n",
       "4  0.272272            0.235926            0.270105             \n",
       "\n",
       "   b35_buff_0.5km_max  b36_buff_0.5km_max  b37_buff_0.5km_max  \\\n",
       "0  0.278184            0.214499            0.172298             \n",
       "1  0.266135            0.201971            0.164499             \n",
       "2  0.262597            0.214029            0.173512             \n",
       "3  0.266135            0.202050            0.164499             \n",
       "4  0.277717            0.214016            0.176642             \n",
       "\n",
       "   b45_buff_0.5km_max  b46_buff_0.5km_max  b47_buff_0.5km_max  \\\n",
       "0  0.008229           -0.059531           -0.103083             \n",
       "1  0.008229           -0.059613           -0.098146             \n",
       "2 -0.008588           -0.060022           -0.101844             \n",
       "3  0.008229           -0.059531           -0.098146             \n",
       "4  0.008229           -0.059531           -0.098146             \n",
       "\n",
       "   b56_buff_0.5km_max  b57_buff_0.5km_max  b67_buff_0.5km_max  \\\n",
       "0 -0.067727           -0.111217           -0.043821             \n",
       "1 -0.067808           -0.106289           -0.038760             \n",
       "2 -0.051460           -0.093338           -0.042080             \n",
       "3 -0.067727           -0.106289           -0.038842             \n",
       "4 -0.067727           -0.106289           -0.038842             \n",
       "\n",
       "   b1_buff_1km_max  b2_buff_1km_max  b3_buff_1km_max  b4_buff_1km_max  \\\n",
       "0  1566.5           1948.0           2275.0           3435.0            \n",
       "1  1566.5           2042.5           2759.5           3538.0            \n",
       "2  1566.5           1884.0           2275.0           3435.0            \n",
       "3  1566.5           2042.5           2759.5           3538.0            \n",
       "4  1566.5           1948.0           2275.0           3435.0            \n",
       "\n",
       "   b5_buff_1km_max  b6_buff_1km_max  b7_buff_1km_max  b12_buff_1km_max  \\\n",
       "0  3644.0           3114.0           4000.0           0.108550           \n",
       "1  4762.0           3049.0           4023.0           0.131892           \n",
       "2  3644.0           3049.0           4000.0           0.092016           \n",
       "3  4717.0           3049.0           4020.5           0.131892           \n",
       "4  4114.0           3091.0           4000.0           0.108550           \n",
       "\n",
       "   b13_buff_1km_max  b14_buff_1km_max  b15_buff_1km_max  b16_buff_1km_max  \\\n",
       "0  0.184433          0.373588          0.398714          0.330627           \n",
       "1  0.275774          0.386228          0.504938          0.321200           \n",
       "2  0.184433          0.373588          0.398714          0.321200           \n",
       "3  0.275774          0.386228          0.501393          0.321200           \n",
       "4  0.184433          0.373588          0.448464          0.327322           \n",
       "\n",
       "   b17_buff_1km_max  b23_buff_1km_max  b24_buff_1km_max  b25_buff_1km_max  \\\n",
       "0  0.437169          0.077433          0.276240          0.303290           \n",
       "1  0.439485          0.149313          0.267987          0.399662           \n",
       "2  0.437169          0.094013          0.291596          0.318379           \n",
       "3  0.439234          0.149313          0.267987          0.395665           \n",
       "4  0.437169          0.077433          0.276240          0.357308           \n",
       "\n",
       "   b26_buff_1km_max  b27_buff_1km_max  b34_buff_1km_max  b35_buff_1km_max  \\\n",
       "0  0.230344          0.344990          0.203152          0.231289           \n",
       "1  0.197682          0.326519          0.123620          0.266237           \n",
       "2  0.236165          0.359619          0.203152          0.231289           \n",
       "3  0.197682          0.326241          0.123620          0.261820           \n",
       "4  0.226831          0.344990          0.203152          0.287838           \n",
       "\n",
       "   b36_buff_1km_max  b37_buff_1km_max  b45_buff_1km_max  b46_buff_1km_max  \\\n",
       "0  0.155688          0.274900          0.029524         -0.049015           \n",
       "1  0.049841          0.186288          0.147470         -0.074237           \n",
       "2  0.145379          0.274900          0.029524         -0.059531           \n",
       "3  0.049841          0.185988          0.142823         -0.074237           \n",
       "4  0.152069          0.274900          0.089946         -0.052712           \n",
       "\n",
       "   b47_buff_1km_max  b56_buff_1km_max  b57_buff_1km_max  b67_buff_1km_max  \\\n",
       "0  0.075992         -0.078426          0.046572          0.124543           \n",
       "1  0.064145         -0.219306         -0.084121          0.137726           \n",
       "2  0.075992         -0.088899          0.046572          0.134913           \n",
       "3  0.063835         -0.214782         -0.079714          0.137421           \n",
       "4  0.075992         -0.141985         -0.014050          0.128191           \n",
       "\n",
       "   b1_buff_1.5km_max  b2_buff_1.5km_max  b3_buff_1.5km_max  b4_buff_1.5km_max  \\\n",
       "0  1966.0             2742.0             3447.0             4166.0              \n",
       "1  1966.0             2777.0             3566.0             4221.0              \n",
       "2  1966.0             2777.0             3566.0             4221.0              \n",
       "3  1966.0             2777.0             3566.0             4221.0              \n",
       "4  1966.0             2777.0             3566.0             4221.0              \n",
       "\n",
       "   b5_buff_1.5km_max  b6_buff_1.5km_max  b7_buff_1.5km_max  \\\n",
       "0  5684.0             3118.0             4572.0              \n",
       "1  5684.0             3114.0             4610.0              \n",
       "2  5684.0             3118.0             4610.0              \n",
       "3  5684.0             3118.0             4610.0              \n",
       "4  5684.0             3118.0             4610.0              \n",
       "\n",
       "   b12_buff_1.5km_max  b13_buff_1.5km_max  b14_buff_1.5km_max  \\\n",
       "0  0.164826            0.273601            0.358774             \n",
       "1  0.170989            0.289226            0.364474             \n",
       "2  0.170989            0.289226            0.364474             \n",
       "3  0.170989            0.289226            0.364474             \n",
       "4  0.170989            0.289226            0.364474             \n",
       "\n",
       "   b15_buff_1.5km_max  b16_buff_1.5km_max  b17_buff_1.5km_max  \\\n",
       "0  0.486013            0.226593            0.398593             \n",
       "1  0.486013            0.225984            0.402068             \n",
       "2  0.486013            0.226593            0.402068             \n",
       "3  0.486013            0.226593            0.402068             \n",
       "4  0.486013            0.226593            0.402068             \n",
       "\n",
       "   b23_buff_1.5km_max  b24_buff_1.5km_max  b25_buff_1.5km_max  \\\n",
       "0  0.113912            0.206138            0.349157             \n",
       "1  0.124389            0.206345            0.343576             \n",
       "2  0.124389            0.206345            0.343576             \n",
       "3  0.124389            0.206345            0.343576             \n",
       "4  0.124389            0.206345            0.343576             \n",
       "\n",
       "   b26_buff_1.5km_max  b27_buff_1.5km_max  b34_buff_1.5km_max  \\\n",
       "0  0.064164            0.250205            0.094444             \n",
       "1  0.057206            0.248139            0.084115             \n",
       "2  0.057846            0.248139            0.084115             \n",
       "3  0.057846            0.248139            0.084115             \n",
       "4  0.057846            0.248139            0.084115             \n",
       "\n",
       "   b35_buff_1.5km_max  b36_buff_1.5km_max  b37_buff_1.5km_max  \\\n",
       "0  0.244990           -0.050114            0.140292             \n",
       "1  0.228973           -0.067665            0.127691             \n",
       "2  0.228973           -0.067026            0.127691             \n",
       "3  0.228973           -0.067026            0.127691             \n",
       "4  0.228973           -0.067026            0.127691             \n",
       "\n",
       "   b45_buff_1.5km_max  b46_buff_1.5km_max  b47_buff_1.5km_max  \\\n",
       "0  0.154112           -0.143877            0.046464             \n",
       "1  0.147703           -0.150920            0.044049             \n",
       "2  0.147703           -0.150293            0.044049             \n",
       "3  0.147703           -0.150293            0.044049             \n",
       "4  0.147703           -0.150293            0.044049             \n",
       "\n",
       "   b56_buff_1.5km_max  b57_buff_1.5km_max  b67_buff_1.5km_max  \\\n",
       "0 -0.291525           -0.108424            0.189077             \n",
       "1 -0.292112           -0.104333            0.193682             \n",
       "2 -0.291525           -0.104333            0.193064             \n",
       "3 -0.291525           -0.104333            0.193064             \n",
       "4 -0.291525           -0.104333            0.193064             \n",
       "\n",
       "   b1_buff_2km_max  b2_buff_2km_max  b3_buff_2km_max  b4_buff_2km_max  \\\n",
       "0  2177.5           2967.0           3770.0           4617.0            \n",
       "1  2177.5           2967.0           3770.0           4617.0            \n",
       "2  2177.5           2967.0           3770.0           4617.0            \n",
       "3  2177.5           2967.0           3770.0           4617.0            \n",
       "4  2177.5           2967.0           3770.0           4617.0            \n",
       "\n",
       "   b5_buff_2km_max  b6_buff_2km_max  b7_buff_2km_max  b12_buff_2km_max  \\\n",
       "0  6460.5           3145.0           5562.5           0.153465           \n",
       "1  6460.5           3145.0           5562.5           0.153465           \n",
       "2  6460.5           3145.0           5562.5           0.153465           \n",
       "3  6460.5           3145.0           5562.5           0.153465           \n",
       "4  6460.5           3145.0           5562.5           0.153465           \n",
       "\n",
       "   b13_buff_2km_max  b14_buff_2km_max  b15_buff_2km_max  b16_buff_2km_max  \\\n",
       "0  0.26776           0.35904           0.495832          0.181775           \n",
       "1  0.26776           0.35904           0.495832          0.181775           \n",
       "2  0.26776           0.35904           0.495832          0.181775           \n",
       "3  0.26776           0.35904           0.495832          0.181775           \n",
       "4  0.26776           0.35904           0.495832          0.181775           \n",
       "\n",
       "   b17_buff_2km_max  b23_buff_2km_max  b24_buff_2km_max  b25_buff_2km_max  \\\n",
       "0  0.437339          0.119193          0.217563          0.370565           \n",
       "1  0.437339          0.119193          0.217563          0.370565           \n",
       "2  0.437339          0.119193          0.217563          0.370565           \n",
       "3  0.437339          0.119193          0.217563          0.370565           \n",
       "4  0.437339          0.119193          0.217563          0.370565           \n",
       "\n",
       "   b26_buff_2km_max  b27_buff_2km_max  b34_buff_2km_max  b35_buff_2km_max  \\\n",
       "0  0.029123          0.304297          0.10099           0.262988           \n",
       "1  0.029123          0.304297          0.10099           0.262988           \n",
       "2  0.029123          0.304297          0.10099           0.262988           \n",
       "3  0.029123          0.304297          0.10099           0.262988           \n",
       "4  0.029123          0.304297          0.10099           0.262988           \n",
       "\n",
       "   b36_buff_2km_max  b37_buff_2km_max  b45_buff_2km_max  b46_buff_2km_max  \\\n",
       "0 -0.090383          0.192071          0.166418         -0.189642           \n",
       "1 -0.090383          0.192071          0.166418         -0.189642           \n",
       "2 -0.090383          0.192071          0.166418         -0.189642           \n",
       "3 -0.090383          0.192071          0.166418         -0.189642           \n",
       "4 -0.090383          0.192071          0.166418         -0.189642           \n",
       "\n",
       "   b47_buff_2km_max  b56_buff_2km_max  b57_buff_2km_max  b67_buff_2km_max  \\\n",
       "0  0.092883         -0.345167         -0.07469           0.277634           \n",
       "1  0.092883         -0.345167         -0.07469           0.277634           \n",
       "2  0.092883         -0.345167         -0.07469           0.277634           \n",
       "3  0.092883         -0.345167         -0.07469           0.277634           \n",
       "4  0.092883         -0.345167         -0.07469           0.277634           \n",
       "\n",
       "   viirs_spatialmean_monthlymean_buff_1km  \\\n",
       "0  2.058431                                 \n",
       "1  2.117678                                 \n",
       "2  2.170639                                 \n",
       "3  2.117678                                 \n",
       "4  2.058431                                 \n",
       "\n",
       "   viirs_spatialmean_monthlysd_buff_1km  \\\n",
       "0  0.212049                               \n",
       "1  0.201614                               \n",
       "2  0.293476                               \n",
       "3  0.201614                               \n",
       "4  0.212049                               \n",
       "\n",
       "   viirs_spatialmean_monthlymean_buff_2km  \\\n",
       "0  2.703993                                 \n",
       "1  2.842941                                 \n",
       "2  2.725424                                 \n",
       "3  2.842941                                 \n",
       "4  2.758374                                 \n",
       "\n",
       "   viirs_spatialmean_monthlysd_buff_2km  \\\n",
       "0  0.442176                               \n",
       "1  0.437466                               \n",
       "2  0.407873                               \n",
       "3  0.437466                               \n",
       "4  0.453090                               \n",
       "\n",
       "   viirs_spatialmean_monthlymean_buff_3km  \\\n",
       "0  3.183021                                 \n",
       "1  3.841434                                 \n",
       "2  3.562234                                 \n",
       "3  3.841434                                 \n",
       "4  3.455073                                 \n",
       "\n",
       "   viirs_spatialmean_monthlysd_buff_3km  \\\n",
       "0  0.458820                               \n",
       "1  0.654410                               \n",
       "2  0.587596                               \n",
       "3  0.654410                               \n",
       "4  0.533627                               \n",
       "\n",
       "   viirs_spatialmean_monthlymean_buff_5km  \\\n",
       "0  2.959563                                 \n",
       "1  3.031431                                 \n",
       "2  2.951366                                 \n",
       "3  3.015690                                 \n",
       "4  3.016406                                 \n",
       "\n",
       "   viirs_spatialmean_monthlysd_buff_5km  \\\n",
       "0  0.357889                               \n",
       "1  0.364188                               \n",
       "2  0.357374                               \n",
       "3  0.360669                               \n",
       "4  0.365598                               \n",
       "\n",
       "   viirs_spatialmean_monthlymean_buff_10km  \\\n",
       "0  1.835716                                  \n",
       "1  1.919555                                  \n",
       "2  1.865132                                  \n",
       "3  1.917362                                  \n",
       "4  1.875871                                  \n",
       "\n",
       "   viirs_spatialmean_monthlysd_buff_10km  \\\n",
       "0  0.216637                                \n",
       "1  0.231518                                \n",
       "2  0.219127                                \n",
       "3  0.231283                                \n",
       "4  0.223074                                \n",
       "\n",
       "   viirs_spatialmax_monthlymean_buff_1km  viirs_spatialmax_monthlysd_buff_1km  \\\n",
       "0  4.138187                               0.889063                              \n",
       "1  4.138187                               0.889063                              \n",
       "2  4.138187                               0.889063                              \n",
       "3  4.138187                               0.889063                              \n",
       "4  4.138187                               0.889063                              \n",
       "\n",
       "   viirs_spatialmax_monthlymean_buff_2km  viirs_spatialmax_monthlysd_buff_2km  \\\n",
       "0  7.454411                               2.258553                              \n",
       "1  8.700871                               1.975251                              \n",
       "2  8.700871                               1.975251                              \n",
       "3  8.700871                               1.975251                              \n",
       "4  7.454411                               2.258553                              \n",
       "\n",
       "   viirs_spatialmax_monthlymean_buff_3km  viirs_spatialmax_monthlysd_buff_3km  \\\n",
       "0  11.129500                              2.579266                              \n",
       "1  14.672931                              4.762204                              \n",
       "2  14.672931                              4.762204                              \n",
       "3  14.672931                              4.762204                              \n",
       "4  14.276131                              4.574316                              \n",
       "\n",
       "   viirs_spatialmax_monthlymean_buff_5km  viirs_spatialmax_monthlysd_buff_5km  \\\n",
       "0  17.945522                              4.504748                              \n",
       "1  17.945522                              4.504748                              \n",
       "2  17.945522                              4.504748                              \n",
       "3  17.945522                              4.504748                              \n",
       "4  17.945522                              4.504748                              \n",
       "\n",
       "   viirs_spatialmax_monthlymean_buff_10km  \\\n",
       "0  17.945522                                \n",
       "1  17.945522                                \n",
       "2  17.945522                                \n",
       "3  17.945522                                \n",
       "4  17.945522                                \n",
       "\n",
       "   viirs_spatialmax_monthlysd_buff_10km  \\\n",
       "0  4.504748                               \n",
       "1  4.504748                               \n",
       "2  4.504748                               \n",
       "3  4.504748                               \n",
       "4  4.504748                               \n",
       "\n",
       "   viirs_spatialmin_monthlymean_buff_1km  viirs_spatialmin_monthlysd_buff_1km  \\\n",
       "0  0.85135                                0.192531                              \n",
       "1  0.85135                                0.192531                              \n",
       "2  0.85135                                0.192531                              \n",
       "3  0.85135                                0.192531                              \n",
       "4  0.85135                                0.192531                              \n",
       "\n",
       "   viirs_spatialmin_monthlymean_buff_2km  viirs_spatialmin_monthlysd_buff_2km  \\\n",
       "0  0.599399                               0.161676                              \n",
       "1  0.676076                               0.176400                              \n",
       "2  0.599399                               0.161676                              \n",
       "3  0.676076                               0.176400                              \n",
       "4  0.599399                               0.161676                              \n",
       "\n",
       "   viirs_spatialmin_monthlymean_buff_3km  viirs_spatialmin_monthlysd_buff_3km  \\\n",
       "0  0.475024                               0.146881                              \n",
       "1  0.526063                               0.164093                              \n",
       "2  0.517853                               0.166289                              \n",
       "3  0.526063                               0.164093                              \n",
       "4  0.517853                               0.166289                              \n",
       "\n",
       "   viirs_spatialmin_monthlymean_buff_5km  viirs_spatialmin_monthlysd_buff_5km  \\\n",
       "0  0.320060                               0.169679                              \n",
       "1  0.353151                               0.126836                              \n",
       "2  0.353151                               0.126836                              \n",
       "3  0.353151                               0.126836                              \n",
       "4  0.353151                               0.126836                              \n",
       "\n",
       "   viirs_spatialmin_monthlymean_buff_10km  \\\n",
       "0  0.151178                                 \n",
       "1  0.153663                                 \n",
       "2  0.150885                                 \n",
       "3  0.153663                                 \n",
       "4  0.151178                                 \n",
       "\n",
       "   viirs_spatialmin_monthlysd_buff_10km  viirs_spatialsd_monthlymean_buff_1km  \\\n",
       "0  0.144790                              1.199479                               \n",
       "1  0.146517                              1.114580                               \n",
       "2  0.144672                              1.293571                               \n",
       "3  0.146517                              1.114580                               \n",
       "4  0.144790                              1.199479                               \n",
       "\n",
       "   viirs_spatialsd_monthlysd_buff_1km  viirs_spatialsd_monthlymean_buff_2km  \\\n",
       "0  0.357367                            2.054746                               \n",
       "1  0.318461                            2.305804                               \n",
       "2  0.361910                            2.348795                               \n",
       "3  0.318461                            2.305804                               \n",
       "4  0.357367                            2.082428                               \n",
       "\n",
       "   viirs_spatialsd_monthlysd_buff_2km  viirs_spatialsd_monthlymean_buff_3km  \\\n",
       "0  0.646521                            2.763771                               \n",
       "1  0.647746                            3.456623                               \n",
       "2  0.650181                            3.455724                               \n",
       "3  0.647746                            3.456623                               \n",
       "4  0.658928                            3.127103                               \n",
       "\n",
       "   viirs_spatialsd_monthlysd_buff_3km  viirs_spatialsd_monthlymean_buff_5km  \\\n",
       "0  0.654013                            3.277391                               \n",
       "1  1.005897                            3.264376                               \n",
       "2  1.000364                            3.266350                               \n",
       "3  1.005897                            3.257961                               \n",
       "4  0.814121                            3.290289                               \n",
       "\n",
       "   viirs_spatialsd_monthlysd_buff_5km  viirs_spatialsd_monthlymean_buff_10km  \\\n",
       "0  0.772987                            2.362731                                \n",
       "1  0.782375                            2.434603                                \n",
       "2  0.793944                            2.408488                                \n",
       "3  0.780742                            2.435950                                \n",
       "4  0.789950                            2.409227                                \n",
       "\n",
       "   viirs_spatialsd_monthlysd_buff_10km  dist_osm_fclass_tertiary_meters  \\\n",
       "0  0.534068                             707.590360                        \n",
       "1  0.605651                             949.344371                        \n",
       "2  0.564808                             835.158410                        \n",
       "3  0.603529                             935.281177                        \n",
       "4  0.565287                             794.660657                        \n",
       "\n",
       "   dist_osm_fclass_secondary_meters  dist_osm_fclass_residential_meters  \\\n",
       "0  691.084276                        290.853957                           \n",
       "1  821.615637                        173.271184                           \n",
       "2  941.645909                        436.039478                           \n",
       "3  810.825640                        172.826623                           \n",
       "4  748.261101                        256.930948                           \n",
       "\n",
       "   dist_osm_fclass_trunk_meters  dist_osm_fclass_primary_meters  \\\n",
       "0  301.885996                    4213.933117                      \n",
       "1  135.784050                    4011.442510                      \n",
       "2  404.926017                    4264.388544                      \n",
       "3  143.811329                    4021.808418                      \n",
       "4  256.773891                    4151.273547                      \n",
       "\n",
       "   dist_osm_fclass_unclassified_meters  dist_osm_fclass_service_meters  \\\n",
       "0  61.828224                            1892.079096                      \n",
       "1  71.969127                            2002.804245                      \n",
       "2  198.401495                           2137.754112                      \n",
       "3  65.477003                            1995.596901                      \n",
       "4  35.532442                            1958.231310                      \n",
       "\n",
       "   dist_osm_fclass_motorway_meters  dist_osm_fclass_living_street_meters  \\\n",
       "0  5496.035379                      445.707495                             \n",
       "1  5577.352264                      254.089102                             \n",
       "2  5746.224836                      525.904380                             \n",
       "3  5570.187783                      262.127174                             \n",
       "4  5542.517836                      386.386906                             \n",
       "\n",
       "   estimate_dau_all  estimate_mau_all  estimate_dau_male  estimate_mau_male  \\\n",
       "0  21718             37000.0           16463              30000.0             \n",
       "1  21718             37000.0           16463              30000.0             \n",
       "2  21718             37000.0           16463              30000.0             \n",
       "3  21718             37000.0           16463              30000.0             \n",
       "4  21718             37000.0           16463              30000.0             \n",
       "\n",
       "   estimate_dau_female  estimate_mau_female  pscores_poor  \\\n",
       "0  3696                 7300.0               False          \n",
       "1  3696                 7300.0               True           \n",
       "2  3696                 7300.0               True           \n",
       "3  3696                 7300.0               False          \n",
       "4  3696                 7300.0               False          \n",
       "\n",
       "   distance_road_meters  distance_road_kms  dist_osm_fclass_residential_kms  \\\n",
       "0  61.828224             0.061828           0.290854                          \n",
       "1  71.969127             0.071969           0.173271                          \n",
       "2  198.401495            0.198401           0.436039                          \n",
       "3  65.477003             0.065477           0.172827                          \n",
       "4  35.532442             0.035532           0.256931                          \n",
       "\n",
       "   viirs_NA  landsat_NA  pscores_NA  N_uid  keep  \n",
       "0  False     False       False       3      True  \n",
       "1  False     False       False       3      True  \n",
       "2  False     False       False       3      True  \n",
       "3  False     False       False       4      True  \n",
       "4  False     False       False       2      True  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Restrict to Year\n",
    "#df = df[df['year'] == 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1512\n",
       "2    1508\n",
       "1    1508\n",
       "Name: pscores_bin, dtype: int64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Changes\n",
    "#df['pscores_bin'] = df['pscores'] < 0\n",
    "\n",
    "#### Levels\n",
    "#df = df.loc[df['survey_round'] != 1]\n",
    "#df['pscores_bin'] = df['pscores'] <= (df['pscores'].median())\n",
    "#df['pscores_bin'] = df['pscores_poor']\n",
    "\n",
    "# DV as Quantiles\n",
    "df['pscores_bin'] = pd.qcut(df['pscores'], 4, labels=False)\n",
    "#df['pscores_2011'].value_counts()\n",
    "#df['pscores_bin'] = df['pscores'] < 0\n",
    "\n",
    "df.pscores_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['pscores_bin'] != 1]\n",
    "df['pscores_bin'] = (df['pscores_bin'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       True \n",
       "2       True \n",
       "4       False\n",
       "6       False\n",
       "7       True \n",
       "8       True \n",
       "9       True \n",
       "10      True \n",
       "12      True \n",
       "13      False\n",
       "14      True \n",
       "16      True \n",
       "17      True \n",
       "19      True \n",
       "20      False\n",
       "22      False\n",
       "24      False\n",
       "26      False\n",
       "28      False\n",
       "29      False\n",
       "30      False\n",
       "31      False\n",
       "33      True \n",
       "38      False\n",
       "40      True \n",
       "41      False\n",
       "42      False\n",
       "43      False\n",
       "44      True \n",
       "        ...  \n",
       "4494    False\n",
       "4495    False\n",
       "4496    False\n",
       "4497    False\n",
       "4498    False\n",
       "4499    False\n",
       "4500    False\n",
       "4501    True \n",
       "4502    False\n",
       "4503    False\n",
       "4504    False\n",
       "4505    False\n",
       "4506    False\n",
       "4507    False\n",
       "4508    True \n",
       "4509    False\n",
       "4510    True \n",
       "4513    True \n",
       "4514    False\n",
       "4515    True \n",
       "4516    False\n",
       "4518    False\n",
       "4519    False\n",
       "4520    False\n",
       "4521    False\n",
       "4522    False\n",
       "4523    False\n",
       "4524    False\n",
       "4526    False\n",
       "4527    True \n",
       "Name: pscores_bin, Length: 3020, dtype: bool"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep Select Columns\n",
    "df_viirs = df.filter(regex='viirs').filter(regex='_2km')\n",
    "df_landsat = df.filter(regex='^b').filter(regex='_1km')\n",
    "df_osm = df.filter(regex='fclass').filter(regex='meters')\n",
    "df_facebook = df.filter(regex='^estimate_dau')\n",
    "\n",
    "df_y = df.filter(regex='^pscores_bin$')\n",
    "\n",
    "df_all = df_y.join(df_viirs).join(df_landsat).join(df_osm).join(df_facebook)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns where the label is missing\n",
    "#df = df.loc[~pd.isnull(df['hhinc_2011'])]\n",
    "\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'pscores_bin'\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "# Separate feature sets from label sets\n",
    "x_df = df_all.drop(labels=[LABEL], axis=1)\n",
    "y_df = df_all[LABEL]\n",
    "\n",
    "x_df[x_df.columns] = preprocessing.scale(x_df[x_df.columns])\n",
    "#x_df[x_df.columns] = preprocessing.StandardScaler().fit_transform(x_df[x_df.columns])\n",
    "\n",
    "# Split into test and train sets for features and labels\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x_df, y_df, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True     1071\n",
      "False    1043\n",
      "Name: pscores_bin, dtype: int64\n",
      "False    465\n",
      "True     441\n",
      "Name: pscores_bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train.head()\n",
    "x_test.head()\n",
    "\n",
    "# check that lengths match\n",
    "print(len(x_train) == len(y_train))\n",
    "print(len(x_test) == len(y_test))\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_FEATURES = df_all.filter(regex='^b', axis=1).columns.tolist()\n",
    "NIGHT_FEATURES = df_all.filter(regex='viirs', axis=1).columns.tolist()\n",
    "SATELLITE_FEATURES = df_all.filter(regex='^b|viirs').columns.tolist()\n",
    "NONSATELLITE_FEATURES = df_all.filter(regex='dist_osm|estimate_').columns.tolist()\n",
    "ALL_FEATURES = x_df.columns.tolist()\n",
    "\n",
    "MAIN_FEATURES = ['viirs_spatialmean_monthlymean_buff_2km',\n",
    "    'viirs_spatialmean_monthlysd_buff_2km',\n",
    "     'b1_buff_1km_mean',\n",
    " 'b2_buff_1km_mean',\n",
    " 'b3_buff_1km_mean',\n",
    " 'b4_buff_1km_mean',\n",
    " 'b5_buff_1km_mean',\n",
    " 'b6_buff_1km_mean',\n",
    " 'b7_buff_1km_mean',\n",
    " 'b12_buff_1km_mean',\n",
    " 'b13_buff_1km_mean',\n",
    " 'b14_buff_1km_mean',\n",
    " 'b15_buff_1km_mean',\n",
    " 'b16_buff_1km_mean',\n",
    " 'b17_buff_1km_mean',\n",
    " 'b23_buff_1km_mean',\n",
    " 'b24_buff_1km_mean',\n",
    " 'b25_buff_1km_mean',\n",
    " 'b26_buff_1km_mean',\n",
    " 'b27_buff_1km_mean',\n",
    " 'b34_buff_1km_mean',\n",
    " 'b35_buff_1km_mean',\n",
    " 'b36_buff_1km_mean',\n",
    " 'b37_buff_1km_mean',\n",
    " 'b45_buff_1km_mean',\n",
    " 'b46_buff_1km_mean',\n",
    " 'b47_buff_1km_mean',\n",
    " 'b56_buff_1km_mean',\n",
    " 'b57_buff_1km_mean',\n",
    " 'b67_buff_1km_mean',\n",
    "    'dist_osm_fclass_tertiary_meters',\n",
    " 'dist_osm_fclass_secondary_meters',\n",
    " 'dist_osm_fclass_residential_meters',\n",
    " 'dist_osm_fclass_trunk_meters',\n",
    " 'dist_osm_fclass_primary_meters',\n",
    " 'dist_osm_fclass_unclassified_meters',\n",
    " 'dist_osm_fclass_service_meters',\n",
    " 'dist_osm_fclass_motorway_meters',\n",
    " 'dist_osm_fclass_living_street_meters',\n",
    " 'estimate_dau_all',\n",
    " 'estimate_dau_male',\n",
    " 'estimate_dau_female']\n",
    "\n",
    "\n",
    "MAIN_FEATURES_LIM = ['viirs_spatialmean_monthlymean_buff_2km',\n",
    " 'b12_buff_1km_mean',\n",
    " 'b13_buff_1km_mean',\n",
    " 'b14_buff_1km_mean',\n",
    " 'b15_buff_1km_mean',\n",
    " 'b16_buff_1km_mean',\n",
    " 'b17_buff_1km_mean',\n",
    " 'b23_buff_1km_mean',\n",
    " 'b24_buff_1km_mean',\n",
    " 'b25_buff_1km_mean',\n",
    " 'b26_buff_1km_mean',\n",
    " 'b27_buff_1km_mean',\n",
    " 'b34_buff_1km_mean',\n",
    " 'b35_buff_1km_mean',\n",
    " 'b36_buff_1km_mean',\n",
    " 'b37_buff_1km_mean',\n",
    " 'b45_buff_1km_mean',\n",
    " 'b46_buff_1km_mean',\n",
    " 'b47_buff_1km_mean',\n",
    " 'b56_buff_1km_mean',\n",
    " 'b57_buff_1km_mean',\n",
    " 'b67_buff_1km_mean',\n",
    "    'dist_osm_fclass_tertiary_meters',\n",
    " 'dist_osm_fclass_secondary_meters',\n",
    " 'dist_osm_fclass_residential_meters',\n",
    " 'dist_osm_fclass_trunk_meters',\n",
    " 'dist_osm_fclass_primary_meters',\n",
    " 'dist_osm_fclass_unclassified_meters',\n",
    " 'dist_osm_fclass_service_meters',\n",
    " 'dist_osm_fclass_motorway_meters',\n",
    " 'dist_osm_fclass_living_street_meters',\n",
    " 'estimate_dau_all']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Regressors\n",
    "\n",
    "### 5.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = x_test.append(x_train)\n",
    "y_all = y_test.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a TrainedRegressor object to hold key results information\n",
    "class TrainedRegressor:\n",
    "    \n",
    "    def __init__(self, method, params, features, regressor):\n",
    "        self.method = method\n",
    "        self.params = params\n",
    "        self.regressor = regressor\n",
    "        self.features = features\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Trained {self.method} on feature set {self.features} with params {self.params}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "Model 1: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "Model 2: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "Model 3: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "Model 4: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "Model 5: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "Model 6: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "Model 7: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 8: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 9: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 10: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 11: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 12: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 13: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 14: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 15: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 16: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 17: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 18: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 19: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 20: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 21: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "Model 22: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "Model 23: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "Model 24: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "Model 25: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "Model 26: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "Model 27: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "Model 28: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 29: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 30: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 31: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 32: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 33: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 34: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 35: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 36: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 37: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 38: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 39: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 40: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 41: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 42: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "Model 43: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "Model 44: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "Model 45: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "Model 46: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "Model 47: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "Model 48: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "Model 49: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 50: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 51: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 52: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 53: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 54: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 55: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 56: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 57: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 58: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 59: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 60: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 61: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 62: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 63: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "Model 64: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "Model 65: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "Model 66: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "Model 67: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "Model 68: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "Model 69: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "Model 70: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 71: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 72: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 73: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 74: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 75: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 76: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 77: Training AdaBoostClassifier on MAIN_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 78: Training AdaBoostClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 79: Training AdaBoostClassifier on DAY_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 80: Training AdaBoostClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 81: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 82: Training AdaBoostClassifier on SATELLITE_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 83: Training AdaBoostClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'random_state': 0}\n",
      "Model 84: Training KNeighborsClassifier on MAIN_FEATURES with params {'n_neighbors': 2}\n",
      "Model 85: Training KNeighborsClassifier on MAIN_FEATURES_LIM with params {'n_neighbors': 2}\n",
      "Model 86: Training KNeighborsClassifier on DAY_FEATURES with params {'n_neighbors': 2}\n",
      "Model 87: Training KNeighborsClassifier on NIGHT_FEATURES with params {'n_neighbors': 2}\n",
      "Model 88: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 2}\n",
      "Model 89: Training KNeighborsClassifier on SATELLITE_FEATURES with params {'n_neighbors': 2}\n",
      "Model 90: Training KNeighborsClassifier on NONSATELLITE_FEATURES with params {'n_neighbors': 2}\n",
      "Model 91: Training KNeighborsClassifier on MAIN_FEATURES with params {'n_neighbors': 5}\n",
      "Model 92: Training KNeighborsClassifier on MAIN_FEATURES_LIM with params {'n_neighbors': 5}\n",
      "Model 93: Training KNeighborsClassifier on DAY_FEATURES with params {'n_neighbors': 5}\n",
      "Model 94: Training KNeighborsClassifier on NIGHT_FEATURES with params {'n_neighbors': 5}\n",
      "Model 95: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 5}\n",
      "Model 96: Training KNeighborsClassifier on SATELLITE_FEATURES with params {'n_neighbors': 5}\n",
      "Model 97: Training KNeighborsClassifier on NONSATELLITE_FEATURES with params {'n_neighbors': 5}\n",
      "Model 98: Training KNeighborsClassifier on MAIN_FEATURES with params {'n_neighbors': 10}\n",
      "Model 99: Training KNeighborsClassifier on MAIN_FEATURES_LIM with params {'n_neighbors': 10}\n",
      "Model 100: Training KNeighborsClassifier on DAY_FEATURES with params {'n_neighbors': 10}\n",
      "Model 101: Training KNeighborsClassifier on NIGHT_FEATURES with params {'n_neighbors': 10}\n",
      "Model 102: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 10}\n",
      "Model 103: Training KNeighborsClassifier on SATELLITE_FEATURES with params {'n_neighbors': 10}\n",
      "Model 104: Training KNeighborsClassifier on NONSATELLITE_FEATURES with params {'n_neighbors': 10}\n",
      "Model 105: Training KNeighborsClassifier on MAIN_FEATURES with params {'n_neighbors': 15}\n",
      "Model 106: Training KNeighborsClassifier on MAIN_FEATURES_LIM with params {'n_neighbors': 15}\n",
      "Model 107: Training KNeighborsClassifier on DAY_FEATURES with params {'n_neighbors': 15}\n",
      "Model 108: Training KNeighborsClassifier on NIGHT_FEATURES with params {'n_neighbors': 15}\n",
      "Model 109: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 15}\n",
      "Model 110: Training KNeighborsClassifier on SATELLITE_FEATURES with params {'n_neighbors': 15}\n",
      "Model 111: Training KNeighborsClassifier on NONSATELLITE_FEATURES with params {'n_neighbors': 15}\n",
      "Model 112: Training LinearSVC on MAIN_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 113: Training LinearSVC on MAIN_FEATURES_LIM with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 114: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 115: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 116: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 117: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 118: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 119: Training LinearSVC on MAIN_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 120: Training LinearSVC on MAIN_FEATURES_LIM with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 121: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 122: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 123: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 124: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 125: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 126: Training LinearSVC on MAIN_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 127: Training LinearSVC on MAIN_FEATURES_LIM with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 128: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 129: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 130: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 131: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 132: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 133: Training LinearSVC on MAIN_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 134: Training LinearSVC on MAIN_FEATURES_LIM with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 135: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 136: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 137: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 138: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 139: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 140: Training LinearSVC on MAIN_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 141: Training LinearSVC on MAIN_FEATURES_LIM with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 142: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 143: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 144: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 145: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 146: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 147: Training LinearSVC on MAIN_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 148: Training LinearSVC on MAIN_FEATURES_LIM with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 149: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 150: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 151: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 152: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 153: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 154: Training SVC on MAIN_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 155: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'linear', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 156: Training SVC on DAY_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 157: Training SVC on NIGHT_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 158: Training SVC on ALL_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 159: Training SVC on SATELLITE_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 160: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 161: Training SVC on MAIN_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 162: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'poly', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 163: Training SVC on DAY_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 164: Training SVC on NIGHT_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 165: Training SVC on ALL_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 166: Training SVC on SATELLITE_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 167: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 168: Training SVC on MAIN_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 169: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 170: Training SVC on DAY_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 171: Training SVC on NIGHT_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 172: Training SVC on ALL_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 173: Training SVC on SATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 174: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 175: Training SVC on MAIN_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 176: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 177: Training SVC on DAY_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 178: Training SVC on NIGHT_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 179: Training SVC on ALL_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 180: Training SVC on SATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 181: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': None, 'random_state': 0}\n",
      "Model 182: Training SVC on MAIN_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 183: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'linear', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 184: Training SVC on DAY_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 185: Training SVC on NIGHT_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 186: Training SVC on ALL_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 187: Training SVC on SATELLITE_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 188: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 189: Training SVC on MAIN_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 190: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'poly', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 191: Training SVC on DAY_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 192: Training SVC on NIGHT_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 193: Training SVC on ALL_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 194: Training SVC on SATELLITE_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 195: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'poly', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 196: Training SVC on MAIN_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 197: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 198: Training SVC on DAY_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 199: Training SVC on NIGHT_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 200: Training SVC on ALL_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 201: Training SVC on SATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 202: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 203: Training SVC on MAIN_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 204: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 205: Training SVC on DAY_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 206: Training SVC on NIGHT_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 207: Training SVC on ALL_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 208: Training SVC on SATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 209: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 0.01, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 210: Training SVC on MAIN_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 211: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'linear', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 212: Training SVC on DAY_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 213: Training SVC on NIGHT_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 214: Training SVC on ALL_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 215: Training SVC on SATELLITE_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 216: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 217: Training SVC on MAIN_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 218: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'poly', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 219: Training SVC on DAY_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 220: Training SVC on NIGHT_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 221: Training SVC on ALL_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 222: Training SVC on SATELLITE_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 223: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 224: Training SVC on MAIN_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 225: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'rbf', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 226: Training SVC on DAY_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 227: Training SVC on NIGHT_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 228: Training SVC on ALL_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 229: Training SVC on SATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 230: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 231: Training SVC on MAIN_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 232: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 233: Training SVC on DAY_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 234: Training SVC on NIGHT_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 235: Training SVC on ALL_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 236: Training SVC on SATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 237: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': None, 'random_state': 0}\n",
      "Model 238: Training SVC on MAIN_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 239: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'linear', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 240: Training SVC on DAY_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 241: Training SVC on NIGHT_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 242: Training SVC on ALL_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 243: Training SVC on SATELLITE_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 244: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'linear', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 245: Training SVC on MAIN_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 246: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'poly', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 247: Training SVC on DAY_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 248: Training SVC on NIGHT_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 249: Training SVC on ALL_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 250: Training SVC on SATELLITE_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 251: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'poly', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 252: Training SVC on MAIN_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 253: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'rbf', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 254: Training SVC on DAY_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 255: Training SVC on NIGHT_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 256: Training SVC on ALL_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 257: Training SVC on SATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 258: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 259: Training SVC on MAIN_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 260: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 261: Training SVC on DAY_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 262: Training SVC on NIGHT_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 263: Training SVC on ALL_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 264: Training SVC on SATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 265: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 1, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 266: Training SVC on MAIN_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 267: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'linear', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 268: Training SVC on DAY_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 269: Training SVC on NIGHT_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 270: Training SVC on ALL_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 271: Training SVC on SATELLITE_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 272: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 273: Training SVC on MAIN_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 274: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'poly', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 275: Training SVC on DAY_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 276: Training SVC on NIGHT_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 277: Training SVC on ALL_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 278: Training SVC on SATELLITE_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 279: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 280: Training SVC on MAIN_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 281: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'rbf', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 282: Training SVC on DAY_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 283: Training SVC on NIGHT_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 284: Training SVC on ALL_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 285: Training SVC on SATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 286: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 287: Training SVC on MAIN_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 288: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 289: Training SVC on DAY_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 290: Training SVC on NIGHT_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 291: Training SVC on ALL_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 292: Training SVC on SATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 293: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': None, 'random_state': 0}\n",
      "Model 294: Training SVC on MAIN_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 295: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'linear', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 296: Training SVC on DAY_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 297: Training SVC on NIGHT_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 298: Training SVC on ALL_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 299: Training SVC on SATELLITE_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 300: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'linear', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 301: Training SVC on MAIN_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 302: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'poly', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 303: Training SVC on DAY_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 304: Training SVC on NIGHT_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 305: Training SVC on ALL_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 306: Training SVC on SATELLITE_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 307: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'poly', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 308: Training SVC on MAIN_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 309: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'rbf', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 310: Training SVC on DAY_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 311: Training SVC on NIGHT_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 312: Training SVC on ALL_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 313: Training SVC on SATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 314: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'rbf', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 315: Training SVC on MAIN_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 316: Training SVC on MAIN_FEATURES_LIM with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 317: Training SVC on DAY_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 318: Training SVC on NIGHT_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 319: Training SVC on ALL_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 320: Training SVC on SATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 321: Training SVC on NONSATELLITE_FEATURES with params {'kernel': 'sigmoid', 'C': 2, 'class_weight': 'balanced', 'random_state': 0}\n",
      "Model 322: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 323: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 324: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 325: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 326: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 327: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 328: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 329: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 330: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 331: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 332: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 333: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 334: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 335: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 336: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 337: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 338: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 339: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 340: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 341: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 342: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 343: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 344: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 345: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 346: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 347: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 348: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 349: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 350: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 351: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 352: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 353: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 354: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 355: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 356: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 357: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 358: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 359: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 360: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 361: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 362: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 363: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 364: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 365: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 366: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 367: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 368: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 369: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 370: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 371: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 372: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 373: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 374: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 375: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 376: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 377: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 378: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 379: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 380: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 381: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 382: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 383: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 384: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 385: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 386: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 387: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 388: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 389: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 390: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 391: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 392: Training DecisionTreeClassifier on MAIN_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 393: Training DecisionTreeClassifier on MAIN_FEATURES_LIM with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 394: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 395: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 396: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 397: Training DecisionTreeClassifier on SATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 398: Training DecisionTreeClassifier on NONSATELLITE_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 399: Training GradientBoostingClassifier on MAIN_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 400: Training GradientBoostingClassifier on MAIN_FEATURES_LIM with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 401: Training GradientBoostingClassifier on DAY_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 402: Training GradientBoostingClassifier on NIGHT_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 403: Training GradientBoostingClassifier on ALL_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 404: Training GradientBoostingClassifier on SATELLITE_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 405: Training GradientBoostingClassifier on NONSATELLITE_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 406: Training RandomForestClassifier on MAIN_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 407: Training RandomForestClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 408: Training RandomForestClassifier on DAY_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 409: Training RandomForestClassifier on NIGHT_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 410: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 411: Training RandomForestClassifier on SATELLITE_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 412: Training RandomForestClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 413: Training RandomForestClassifier on MAIN_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 414: Training RandomForestClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 415: Training RandomForestClassifier on DAY_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 416: Training RandomForestClassifier on NIGHT_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 417: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 418: Training RandomForestClassifier on SATELLITE_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 419: Training RandomForestClassifier on NONSATELLITE_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 420: Training RandomForestClassifier on MAIN_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "Model 421: Training RandomForestClassifier on MAIN_FEATURES_LIM with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-a896e61b96b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_predict_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m#x_test.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_traineddatamodel_testdatapredict_r13.csv'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/robmarty/Desktop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pov_opm_data_with_predictions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 3020\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         libwriters.write_csv_rows(self.data, ix, self.nlevels,\n\u001b[0;32m--> 315\u001b[0;31m                                   self.cols, self.writer)\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use GRID_MAIN for full grid search\n",
    "# parameters = cf.GRID_TEST_CLASS\n",
    "parameters = GRID_TEST_CLASS\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df_all = pd.DataFrame()\n",
    "results_df_trainedonly_all = pd.DataFrame()\n",
    "\n",
    "x_trainedonly_all = x_all.copy()\n",
    "\n",
    "trained_list = []\n",
    "trained_list_all = []\n",
    "count = 0\n",
    "# print('Training model ', end='')\n",
    "for i in parameters['regressors']:\n",
    "    for j in parameters[i]:\n",
    "        for k in ('MAIN_FEATURES', 'MAIN_FEATURES_LIM', 'DAY_FEATURES', 'NIGHT_FEATURES', 'ALL_FEATURES', 'SATELLITE_FEATURES', 'NONSATELLITE_FEATURES'):\n",
    "        \n",
    "            print(f'Model {count}: Training {i} on {k} with params {str(j)}')\n",
    "\n",
    "            # A. Train Models --------------------------\n",
    "            regressor = eval(i)(**j)\n",
    "            \n",
    "            trained = regressor.fit(x_train[eval(k)], y_train)\n",
    "            trained_list.append(TrainedRegressor(i, str(j), k, trained))\n",
    "            \n",
    "            # B. Results -------------------------------------\n",
    "            pred_labels = trained_list[count].regressor.predict(x_test[eval(k)])\n",
    "\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list[count].method,\n",
    "                'features': trained_list[count].features,\n",
    "                'params': trained_list[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_test, y_pred=pred_labels),\n",
    "                'average_precision_score': average_precision_score(y_test, pred_labels),\n",
    "                'recall_score': recall_score(y_test, pred_labels)\n",
    "            }\n",
    "    \n",
    "            results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score','average_precision_score',\n",
    "                 'recall_score']]\n",
    "        \n",
    "            results_df.to_csv(\"/Users/robmarty/Desktop/pov_results_r13.csv\")\n",
    "            \n",
    "            x_test['y_true'] = y_test\n",
    "            x_test['y_predict_' + str(count)] = pred_labels\n",
    "            #x_test.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_traineddatamodel_testdatapredict_r13.csv'))\n",
    "            x_test.to_csv(os.path.join('/Users/robmarty/Desktop', 'pov_opm_data_with_predictions.csv'))\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "  \n",
    "            # A. Train ------------------------------------\n",
    "            # Initialize regressor, fit data, then append TrainedRegressor object to list\n",
    "            # 1. Train Data\n",
    "            #regressor = eval(i)(**j)\n",
    "            #trained = regressor.fit(x_train[eval(k)], y_train)\n",
    "            #trained_list.append(TrainedRegressor(i, str(j), k, trained))\n",
    "\n",
    "            # 2. All Data\n",
    "            #trained_all = trained\n",
    "            #trained_list_all = trained_list\n",
    "\n",
    "            \n",
    "            #trained_all = regressor.fit(x_all[eval(k)], y_all)\n",
    "            #trained_list_all.append(TrainedRegressor(i, str(j), k, trained_all))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # B. Results -------------------------------------\n",
    "            # 1. Trained Model on Test Data - - - - - - - - - -\n",
    "            #pred_labels = trained_list[count].regressor.predict(x_test[eval(k)])\n",
    "\n",
    "            #pred_dict = {\n",
    "            #    'regressor': trained_list[count].method,\n",
    "            #    'features': trained_list[count].features,\n",
    "            #    'params': trained_list[count].params,\n",
    "            #    'accuracy_score': accuracy_score(y_true=y_test, y_pred=pred_labels)        \n",
    "            #}\n",
    "    \n",
    "            #results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "            #    .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "            #    [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            #results_df.to_csv(\"/Users/robmarty/Desktop/pov_results_r13.csv\")\n",
    "            \n",
    "            #x_test['y_true'] = y_test\n",
    "            #x_test['y_predict_' + str(count)] = pred_labels\n",
    "            #x_test.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_traineddatamodel_testdatapredict_r13.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 2. Trained All Model on All Data - - - - - - - - - -\n",
    "            #pred_labels_all = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            #pred_dict = {\n",
    "            #    'regressor': trained_list_all[count].method,\n",
    "            #    'features': trained_list_all[count].features,\n",
    "            #    'params': trained_list_all[count].params,\n",
    "            #    'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_all)        \n",
    "            #}\n",
    "    \n",
    "            #results_df_all = results_df_all.append(pred_dict, ignore_index=True) \\\n",
    "            #    .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "            #    [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            #results_df_all.to_csv(\"/Users/robmarty/Desktop/pov_results_all_r13.csv\")\n",
    "\n",
    "            # ALL\n",
    "            #x_trainedonly_all['y_true'] = y_all\n",
    "            #x_trainedonly_all['y_predict_' + str(count)] = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "            #x_trainedonly_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_alldatamodel_alldatapredict_r13.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 3. Trained Model on All Data - - - - - - - - - -\n",
    "            #pred_labels_trainedonly_all = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            #pred_dict = {\n",
    "            #    'regressor': trained_list[count].method,\n",
    "            #    'features': trained_list[count].features,\n",
    "            #    'params': trained_list[count].params,\n",
    "            #    'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_trainedonly_all)        \n",
    "            #}\n",
    "    \n",
    "            #results_df_trainedonly_all = results_df_trainedonly_all.append(pred_dict, ignore_index=True) \\\n",
    "            #    .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "            #    [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            #results_df_trainedonly_all.to_csv(\"/Users/robmarty/Desktop/pov_results_trainedonly_all_r13.csv\")\n",
    "\n",
    "            # ALL\n",
    "            #x_all['y_true'] = y_all\n",
    "            #x_all['y_predict_' + str(count)] = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "            #x_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_testdatamodel_alldatapredict_r13.csv'))\n",
    "\n",
    "            ####\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
