{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=vjGBumuoEwObfOyEx3u_EIIoSypBIGVEGp1tPSObl70&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=vjGBumuoEwObfOyEx3u_EIIoSypBIGVEGp1tPSObl70&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AX4XfWi4QM7nyi-0RlXPAgqQB9MAMw1lWGkDUNZH4hIRw6IyFIS5VTh_JuI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geetools\n",
    "from geetools import ui, cloud_mask\n",
    "import os, datetime\n",
    "import config as cf\n",
    "import pandas as pd\n",
    "import eeconvert\n",
    "\n",
    "cloud_mask_landsatSR = cloud_mask.landsatSR()\n",
    "cloud_mask_sentinel2 = cloud_mask.sentinel2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_NAME = 'DHS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survey_to_fc_buffer(survey_df, buffer_size_urban, buffer_size_rural):\n",
    "    '''\n",
    "    Convert pandas dataframe of survey locations to a feature collection. \n",
    "    \n",
    "    Inputs:\n",
    "        survey_df: pandas dataframe of survey locations. Function assumes \n",
    "                   the dataframe contains (1) latitude, (2) longitude and\n",
    "                   (3) uid variables. Assumes coordinates in WGS84.\n",
    "    Returns:\n",
    "        (feature collection)\n",
    "    '''\n",
    "    \n",
    "    survey_fc_list = []\n",
    "    \n",
    "    n_rows = survey_df.shape[0]\n",
    "    for i in range(0, n_rows):\n",
    "        survey_df_i = survey_df.iloc[[i]]\n",
    "        \n",
    "        ur = survey_df_i['urban_rural'].iloc[0]\n",
    "        if ur == 'U':\n",
    "            buffer_size = buffer_size_urban\n",
    "        elif ur == 'R':\n",
    "            buffer_size = buffer_size_rural\n",
    "\n",
    "        f_i = ee.Feature(ee.Geometry.Point([survey_df_i['longitude'].iloc[0], \n",
    "                                            survey_df_i['latitude'].iloc[0]]), \n",
    "                         {'uid': survey_df_i['uid'].iloc[0]})\n",
    "        \n",
    "        f_i = f_i.buffer(buffer_size)\n",
    "\n",
    "        survey_fc_list.append(f_i)\n",
    "        \n",
    "    survey_fc = ee.FeatureCollection(survey_fc_list)\n",
    "    \n",
    "    return survey_fc\n",
    "\n",
    "def extract_sat(survey_df, buffer_size_urban, buffer_size_rural, satellite, year):\n",
    "    '''\n",
    "    Extract satellite imagery to locations \n",
    "    \n",
    "    Inputs:\n",
    "        survey_df: pandas dataframe of survey locations. Function assumes \n",
    "                   the dataframe contains (1) latitude, (2) longitude and\n",
    "                   (3) uid variables. Assumes coordinates in WGS84.\n",
    "    Returns:\n",
    "        (feature collection)\n",
    "    '''\n",
    "    \n",
    "    #print(survey_df.uid)\n",
    "    \n",
    "    # Prep l7 ---------------------------------------------------\n",
    "    if satellite == 'l7':\n",
    "        \n",
    "        # Scale\n",
    "        SCALE = 100 # ok to upscale\n",
    "        \n",
    "        # Year\n",
    "        year_use = year\n",
    "        \n",
    "        year_plus = year_use + 1\n",
    "        year_minus = year_use - 1\n",
    "        \n",
    "        year_minus_str = str(year_minus) + '-01-01'\n",
    "        year_plus_str = str(year_plus) + '-12-31'\n",
    "        \n",
    "        image = ee.ImageCollection('LANDSAT/LC07/C01/T1_SR')\\\n",
    "            .filterDate(year_minus_str, year_plus_str)\\\n",
    "            .map(cloud_mask_landsatSR)\\\n",
    "            .median()\\\n",
    "            .multiply(0.0001)\n",
    "\n",
    "        ndvi = image.normalizedDifference(['B4', 'B3']).rename('NDVI');\n",
    "        image = image.addBands(ndvi)\n",
    "        \n",
    "        BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "        \n",
    "    # Prep l8 ---------------------------------------------------\n",
    "    if satellite == 'l8':\n",
    "        \n",
    "        SCALE = 100 # ok to upscale\n",
    "        #SCALE = 2000\n",
    "        \n",
    "        # Year\n",
    "        # landsat 8 starts in April 2013; if year is less than\n",
    "        # 2014, use 2014 as year (to ensure have year before and after)\n",
    "        if year < 2014:\n",
    "            year_use = 2014\n",
    "        else:\n",
    "            year_use = year\n",
    "                    \n",
    "        year_plus = year_use + 1\n",
    "        year_minus = year_use - 1\n",
    "        \n",
    "        year_minus_str = str(year_minus) + '-01-01'\n",
    "        year_plus_str = str(year_plus) + '-12-31'\n",
    "        \n",
    "        image = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\\\n",
    "            .filterDate(year_minus_str, year_plus_str)\\\n",
    "            .map(cloud_mask_landsatSR)\\\n",
    "            .median()\\\n",
    "            .multiply(0.0001)\n",
    "\n",
    "        # https://www.linkedin.com/pulse/ndvi-ndbi-ndwi-calculation-using-landsat-7-8-tek-bahadur-kshetri\n",
    "        ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI');\n",
    "        ndbi = image.normalizedDifference(['B6', 'B5']).rename('NDBI');\n",
    "        image = image.addBands(ndvi)\n",
    "        image = image.addBands(ndbi)\n",
    "        \n",
    "        bu = image.select('NDBI').subtract(image.select('NDVI')).rename('BU')\n",
    "        image = image.addBands(bu)\n",
    "        \n",
    "        BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11', 'NDVI', 'NDBI', 'BU']\n",
    "        #BANDS = ['NDVI']\n",
    "        \n",
    "    # Prep s2 ---------------------------------------------------\n",
    "    if satellite == 's2':\n",
    "        \n",
    "        SCALE = 100 # ok to upscale\n",
    "        \n",
    "        # Year\n",
    "        # sentinel starts in March 2017; juse use 2018\n",
    "        year_use = 2018\n",
    "                    \n",
    "        year_plus = year_use + 1\n",
    "        year_minus = year_use - 1\n",
    "        \n",
    "        year_minus_str = str(year_minus) + '-12-01'\n",
    "        year_plus_str = str(year_plus) + '-12-31'\n",
    "        \n",
    "        image = ee.ImageCollection('COPERNICUS/S2_SR')\\\n",
    "            .filterDate(year_minus_str, year_plus_str)\\\n",
    "            .map(cloud_mask_sentinel2)\\\n",
    "            .median()\\\n",
    "            .multiply(0.0001)\n",
    "        \n",
    "        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI');\n",
    "        image = image.addBands(ndvi)\n",
    "        \n",
    "        BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'AOT', 'NDVI']\n",
    "\n",
    "        image = image.select(BANDS)    \n",
    "    \n",
    "    # Prep viirs ---------------------------------------------------\n",
    "    if satellite == 'viirs':\n",
    "        \n",
    "        SCALE = 500 \n",
    "        \n",
    "        # Year\n",
    "        # VIIRS starts in April 2012; if year is less than\n",
    "        # 2013, use 2013 as year (to ensure have year before and after)\n",
    "        if year < 2013:\n",
    "            year_use = 2013\n",
    "        else:\n",
    "            year_use = year\n",
    "                    \n",
    "        year_plus = year_use + 1\n",
    "        year_minus = year_use - 1\n",
    "        \n",
    "        year_minus_str = str(year_minus) + '-01-01'\n",
    "        year_plus_str = str(year_plus) + '-12-31'\n",
    "        \n",
    "        image = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG')\\\n",
    "            .filterDate(year_minus_str, year_plus_str)\\\n",
    "            .median()\n",
    "        \n",
    "        BANDS = ['avg_rad']\n",
    "        \n",
    "    # Prep DMSP ---------------------------------------------------\n",
    "    if satellite == 'dmsp':\n",
    "        \n",
    "        SCALE = 1000 \n",
    "        \n",
    "        # Year\n",
    "        # DMSP-OLS starts in 2013; if year is more than\n",
    "        # 2012, use 2012 as year (to ensure have year before and after)\n",
    "        if year > 2012:\n",
    "            year_use = 2012\n",
    "        else:\n",
    "            year_use = year\n",
    "                    \n",
    "        year_plus = year_use + 1\n",
    "        year_minus = year_use - 1\n",
    "        \n",
    "        year_minus_str = str(year_minus) + '-01-01'\n",
    "        year_plus_str = str(year_plus) + '-12-31'\n",
    "        \n",
    "        image = ee.ImageCollection('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS')\\\n",
    "            .filterDate(year_minus_str, year_plus_str)\\\n",
    "            .median()\n",
    "        \n",
    "        BANDS = ['stable_lights', 'avg_lights_x_pct']\n",
    "    \n",
    "    # Prep Survey ---------------------------------------------------\n",
    "    survey_fc = survey_to_fc_buffer(survey_df, buffer_size_urban, buffer_size_rural)\n",
    "    \n",
    "    # Extract Values ---------------------------------------------------\n",
    "    #print(survey_fc.size().getInfo())\n",
    "        \n",
    "    vals = image.reduceRegions(collection = survey_fc,\n",
    "                               reducer = ee.Reducer.mean(),\n",
    "                               scale = SCALE,\n",
    "                               tileScale = 8)\n",
    "\n",
    "    survey_df = survey_df[['uid']]\n",
    "    \n",
    "        \n",
    "    #print(BANDS)\n",
    "    for band_i in BANDS:\n",
    "        #print(band_i)\n",
    "        #a = vals.aggregate_array(band_i).getInfo()\n",
    "        #print(len(a))\n",
    "        survey_df[satellite + '_' + band_i] = vals.aggregate_array(band_i).getInfo()\n",
    "        \n",
    "    return survey_df\n",
    "\n",
    "def extract_satellite_in_chunks(survey_df, buffer_size_urban, buffer_size_rural, satellite, year):\n",
    "    \n",
    "    vals_df_list = []\n",
    "    \n",
    "    for chunk_i in list(np.unique(survey_df.chunk_id)):\n",
    "        print(chunk_i)\n",
    "\n",
    "        survey_df_i = survey_df[survey_df['chunk_id'] == chunk_i]\n",
    "        print(survey_df_i.shape)\n",
    "        vals_i_df = extract_sat(survey_df_i, buffer_size_urban, buffer_size_rural, satellite, year)\n",
    "\n",
    "        vals_df_list.append(vals_i_df)\n",
    "\n",
    "    vals_df = pd.concat(vals_df_list)\n",
    "    \n",
    "    return vals_df\n",
    "\n",
    "def extract_satellite_by_year(survey_df, buffer_size_urban, buffer_size_rural, satellite):\n",
    "    \n",
    "    vals_df_list = []\n",
    "    \n",
    "    for year_i in list(np.unique(survey_df.year)):\n",
    "        print(year_i)\n",
    "\n",
    "        survey_df_i = survey_df[survey_df['year'] == year_i]\n",
    "        vals_i_df = extract_satellite_in_chunks(survey_df_i, buffer_size_urban, buffer_size_rural, satellite, year_i)\n",
    "\n",
    "        vals_df_list.append(vals_i_df)\n",
    "\n",
    "    vals_df = pd.concat(vals_df_list)\n",
    "    \n",
    "    return vals_df\n",
    "\n",
    "def chunk_ids(total_length, chunk_size):\n",
    "    n_numbers = np.ceil(total_length / chunk_size)\n",
    "    n_numbers = int(n_numbers)\n",
    "    \n",
    "    chunk_ids = list(range(0,n_numbers)) * chunk_size\n",
    "    chunk_ids.sort()\n",
    "    chunk_ids = chunk_ids[:total_length]\n",
    "    \n",
    "    return chunk_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Prep Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = pd.read_csv(os.path.join(cf.SECURE_DATA_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData - PII', 'GPS_uid_crosswalk.csv'))\n",
    "\n",
    "survey_df = survey_df[survey_df.uid != 'IA201400180012']\n",
    "\n",
    "#survey_df = survey_df[survey_df.most_recent_survey == True]\n",
    "#survey_df = survey_df.head(3000)\n",
    "CHUNK_SIZE = 1000\n",
    "\n",
    "survey_years = list(survey_df.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33406, 7)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df['chunk_id'] = chunk_ids(survey_df.shape[0], CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey_df = survey_df[(survey_df['chunk_id'] == 11) & (survey_df['year'] == 2015)]\n",
    "#survey_df['longitude'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "Feature.select: Parameter 'input' is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"Feature.select: Parameter 'input' is required.\". Details: \"Feature.select: Parameter 'input' is required.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-5a2e3bbbb449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#a = vals.aggregate_array(band_i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    676\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'expression'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_cloud_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m           \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m           prettyPrint=False))['result']\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEEException\u001b[0m: Feature.select: Parameter 'input' is required."
     ]
    }
   ],
   "source": [
    "# DEBUGGING!!!\n",
    "buffer_size_urban = 2000\n",
    "buffer_size_rural = 2000\n",
    "\n",
    "survey_df_i = survey_df[survey_df['chunk_id'] == 1]\n",
    "survey_df_i.shape\n",
    "SCALE = 100 # ok to upscale\n",
    "\n",
    "# Year\n",
    "# sentinel starts in March 2017; juse use 2018\n",
    "year_use = 2018\n",
    "\n",
    "year_plus = year_use + 1\n",
    "year_minus = year_use - 1\n",
    "\n",
    "year_minus_str = str(year_minus) + '-01-01'\n",
    "year_plus_str = str(year_plus) + '-12-31'\n",
    "\n",
    "image = ee.ImageCollection('COPERNICUS/S2_SR')\\\n",
    "    .filterDate(year_minus_str, year_plus_str)\\\n",
    "    .map(cloud_mask_sentinel2)\\\n",
    "    .median()\\\n",
    "    .multiply(0.0001)\n",
    "\n",
    "ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI');\n",
    "image = image.addBands(ndvi)\n",
    "\n",
    "BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'AOT', 'NDVI']\n",
    "\n",
    "image = image.select(BANDS)  \n",
    "\n",
    "# Prep Survey ---------------------------------------------------\n",
    "survey_fc = survey_to_fc_buffer(survey_df_i, buffer_size_urban, buffer_size_rural)\n",
    "\n",
    "# Extract Values ---------------------------------------------------\n",
    "vals = image.reduceRegions(collection = survey_fc,\n",
    "                           reducer = ee.Reducer.mean(),\n",
    "                           scale = SCALE,\n",
    "                           tileScale = 8)\n",
    "\n",
    "a = eeconvert.fcToDf(vals)\n",
    "#band_i = 'B1'\n",
    "#a = vals.aggregate_array(band_i)\n",
    "a = ee.Feature(vals.first()).select(['B1'])\n",
    "print(a.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_s2_df = extract_satellite_by_year(survey_df, 2000, 2000, 's2')\n",
    "\n",
    "val_s2_df.to_csv(os.path.join(cf.DROPBOX_DIRECTORY, \n",
    "                            'Data', \n",
    "                            SURVEY_NAME, \n",
    "                            'FinalData', \n",
    "                            'Individual Datasets',\n",
    "                           'survey_s2.csv'),\n",
    "              index = False)\n",
    "\n",
    "val_s2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Landsat 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey_df['chunk_id'] = range(0, survey_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "29\n",
      "(314, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robmarty/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "29\n",
      "(611, 8)\n",
      "2015\n",
      "0\n",
      "(328, 8)\n",
      "1\n",
      "(1000, 8)\n",
      "2\n",
      "(1000, 8)\n",
      "3\n",
      "(1000, 8)\n",
      "4\n",
      "(1000, 8)\n",
      "5\n",
      "(1000, 8)\n",
      "6\n",
      "(1000, 8)\n",
      "7\n",
      "(1000, 8)\n",
      "8\n",
      "(1000, 8)\n",
      "9\n",
      "(1000, 8)\n",
      "10\n",
      "(1000, 8)\n",
      "11\n",
      "(1000, 8)\n",
      "12\n",
      "(1000, 8)\n",
      "13\n",
      "(1000, 8)\n",
      "14\n",
      "(1000, 8)\n",
      "15\n",
      "(1000, 8)\n",
      "16\n",
      "(1000, 8)\n",
      "17\n",
      "(1000, 8)\n",
      "18\n",
      "(1000, 8)\n",
      "19\n",
      "(1000, 8)\n",
      "20\n",
      "(1000, 8)\n",
      "21\n",
      "(1000, 8)\n",
      "22\n",
      "(1000, 8)\n",
      "23\n",
      "(1000, 8)\n",
      "24\n",
      "(1000, 8)\n",
      "25\n",
      "(1000, 8)\n",
      "26\n",
      "(1000, 8)\n",
      "27\n",
      "(1000, 8)\n",
      "28\n",
      "(1000, 8)\n",
      "29\n",
      "(75, 8)\n",
      "30\n",
      "(430, 8)\n",
      "2016\n",
      "30\n",
      "(383, 8)\n",
      "32\n",
      "(49, 8)\n",
      "33\n",
      "(406, 8)\n",
      "2017\n",
      "0\n",
      "(672, 8)\n",
      "30\n",
      "(187, 8)\n",
      "31\n",
      "(1000, 8)\n",
      "32\n",
      "(951, 8)\n"
     ]
    }
   ],
   "source": [
    "val_l8_df = extract_satellite_by_year(survey_df, 3000, 3000, 'l8')\n",
    "\n",
    "val_l8_df.to_csv(os.path.join(cf.DROPBOX_DIRECTORY, \n",
    "                            'Data', \n",
    "                            SURVEY_NAME, \n",
    "                            'FinalData', \n",
    "                            'Individual Datasets',\n",
    "                           'survey_l8.csv'),\n",
    "              index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Landsat 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_l7_df = extract_satellite_by_year(survey_df, 2000, 5000, 'l7')\n",
    "\n",
    "val_l7_df.to_csv(os.path.join(cf.DROPBOX_DIRECTORY, \n",
    "                            'Data', \n",
    "                            SURVEY_NAME, \n",
    "                            'FinalData', \n",
    "                            'Individual Datasets',\n",
    "                           'survey_l7.csv'),\n",
    "              index = False)\n",
    "\n",
    "val_l7_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract VIIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robmarty/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 8)\n",
      "(328, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(1000, 8)\n",
      "(75, 8)\n",
      "(431, 8)\n",
      "(383, 8)\n",
      "(48, 8)\n",
      "(407, 8)\n",
      "(672, 8)\n",
      "(186, 8)\n",
      "(1000, 8)\n",
      "(952, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>viirs_avg_rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>KY201200000105</td>\n",
       "      <td>0.374646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29677</th>\n",
       "      <td>KY201200000106</td>\n",
       "      <td>0.725092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29678</th>\n",
       "      <td>KY201200000107</td>\n",
       "      <td>0.169814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29679</th>\n",
       "      <td>KY201200000108</td>\n",
       "      <td>0.772588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29680</th>\n",
       "      <td>KY201200000109</td>\n",
       "      <td>0.873666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uid  viirs_avg_rad\n",
       "29676  KY201200000105       0.374646\n",
       "29677  KY201200000106       0.725092\n",
       "29678  KY201200000107       0.169814\n",
       "29679  KY201200000108       0.772588\n",
       "29680  KY201200000109       0.873666"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_viirs_df = extract_satellite_by_year(survey_df, 2000, 2000, 'viirs')\n",
    "\n",
    "val_viirs_df.to_csv(os.path.join(cf.DROPBOX_DIRECTORY, \n",
    "                            'Data', \n",
    "                            SURVEY_NAME, \n",
    "                            'FinalData', \n",
    "                            'Individual Datasets',\n",
    "                           'survey_viirs.csv'),\n",
    "              index = False)\n",
    "\n",
    "val_viirs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract DMSP-OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dmsp_df = extract_satellite_by_year(survey_df, 2000, 5000, 'dmsp')\n",
    "\n",
    "val_dmsp_df.to_csv(os.path.join(cf.DROPBOX_DIRECTORY, \n",
    "                            'Data', \n",
    "                            SURVEY_NAME, \n",
    "                            'FinalData', \n",
    "                            'Individual Datasets',\n",
    "                           'survey_dmsp.csv'),\n",
    "              index = False)\n",
    "\n",
    "val_dmsp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import folium\n",
    "#from folium import plugins\n",
    "\n",
    "#mapid = survey_i_fc.getMapId()\n",
    "\n",
    "#map = folium.Map(location=[80.773137, 7.873592])\n",
    "#folium.TileLayer(\n",
    "#    tiles=mapid['tile_fetcher'].url_format,\n",
    "#    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "#    overlay=True,\n",
    "#    name='border',\n",
    "#  ).add_to(map)\n",
    "\n",
    "#map.add_child(folium.LayerControl())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
