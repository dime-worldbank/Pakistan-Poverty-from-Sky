{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DA6XKs-DESD"
   },
   "source": [
    "# Estimate CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vOjYjPI4iy0H"
   },
   "outputs": [],
   "source": [
    "#TODO:\n",
    "#* Lets have forcnn be training and nocnn be validation. No need for separate test set. Hmmmm no., wont have all classes.\n",
    "#*In prepping, may want to ensure balance within (a) train and (b) validation\n",
    "\n",
    "# Functions up top, then parameters / for loop below (some stuff doesn't need to be repeated for the for loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2bzIvfOYrVP"
   },
   "source": [
    "Adapted from:\n",
    "\n",
    "https://codelabs.developers.google.com/codelabs/keras-flowers-transfer-learning#0\n",
    "\n",
    "https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/04_Keras_Flowers_transfer_learning_solution.ipynb#scrollTo=M3G-2aUBQJ-H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JJTMmXsEf8n"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2Tdoud0HJNx1"
   },
   "outputs": [],
   "source": [
    "## Satellite and survey params\n",
    "SURVEY_NAME = 'LAGOS_POINTS'\n",
    "\n",
    "# Parameters ------------------------------\n",
    "VERSION = 2\n",
    "\n",
    "if VERSION == 1:\n",
    "\n",
    "    SATELLITE         = 's2' \n",
    "    OUTCOME_VAR       = \"viirs\" \n",
    "    UNDERSAMPLE_INDIA = True\n",
    "    \n",
    "if VERSION == 2:\n",
    "\n",
    "    SATELLITE         = 'landsat' \n",
    "    OUTCOME_VAR       = \"ntlharmon\" \n",
    "    UNDERSAMPLE_INDIA = True\n",
    "\n",
    "# Objects based on parameters ------------\n",
    "OUT_NAME_SUFFIX   = SATELLITE + '_' + OUTCOME_VAR + '_underia' + str(UNDERSAMPLE_INDIA)\n",
    "\n",
    "## CNN params\n",
    "if SATELLITE == 's2':\n",
    "    IMAGE_SIZE = [224, 224]\n",
    "elif SATELLITE == 'landsat':\n",
    "    IMAGE_SIZE = [224, 224]\n",
    "\n",
    "if OUTCOME_VAR == 'viirs':\n",
    "    NUM_GROUPS = 5\n",
    "elif OUTCOME_VAR == 'ntlharmon':\n",
    "    NUM_GROUPS = 5\n",
    "\n",
    "EPOCHS           = 200\n",
    "BATCH_SIZE       = 16 #16, 32\n",
    "PATIENCE         = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aixnvSxAEfc0",
    "outputId": "c7c23065-d656-4686-a2a4-563ab8096963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage import exposure\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import config as cf\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBdsPW_tEkN9",
    "outputId": "1536ddbe-5437-4b4b-af79-c95a9d4ee306"
   },
   "outputs": [],
   "source": [
    "# Authenticate Google Drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "d67D5MGjEkQi"
   },
   "outputs": [],
   "source": [
    "# Authenticate Google Cloud\n",
    "#from google.colab import auth\n",
    "#auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "T4dgVWXFEm9L"
   },
   "outputs": [],
   "source": [
    "#GOOGLEDRIVE_DIRECTORY = os.path.join('/Volumes/GoogleDrive/My Drive/World Bank/IEs/Pakistan Poverty Estimation')\n",
    "#GOOGLEDRIVE_DIRECTORY = os.path.join('/content/gdrive/My Drive/World Bank/IEs/Pakistan Poverty Estimation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "083GuGrVFw_d"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSigR3d-EpvJ"
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IhRluY8pErdJ"
   },
   "outputs": [],
   "source": [
    "# Get actual values function\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset\n",
    "\n",
    "#### NTL Group\n",
    "def decode_fn_ntl_group(record_bytes):\n",
    "    return tf.io.parse_single_example(\n",
    "        # Data\n",
    "        record_bytes,\n",
    "\n",
    "        # Schema\n",
    "        {\"viirs_ntl_group\": tf.io.FixedLenFeature([], dtype=tf.int64)}\n",
    "    )\n",
    "\n",
    "def extract_ntl_group(TF_FILES):\n",
    "    actual_values = []\n",
    "    for batch in tf.data.TFRecordDataset([TF_FILES]).map(decode_fn_ntl_group):\n",
    "        value = batch['viirs_ntl_group'].numpy()\n",
    "        actual_values.append(value)\n",
    "\n",
    "    return actual_values\n",
    "\n",
    "#### UID\n",
    "def decode_fn_uid(record_bytes):\n",
    "    return tf.io.parse_single_example(\n",
    "        # Data\n",
    "        record_bytes,\n",
    "\n",
    "        # Schema\n",
    "        {\"uid\": tf.io.FixedLenFeature([], dtype=tf.string)}\n",
    "    )\n",
    "\n",
    "def extract_uid(TF_FILES):\n",
    "    actual_values = []\n",
    "    for batch in tf.data.TFRecordDataset([TF_FILES]).map(decode_fn_uid):\n",
    "        value = batch['uid'].numpy()\n",
    "        actual_values.append(value)\n",
    "\n",
    "    return actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_ZIHgcH7ErgF"
   },
   "outputs": [],
   "source": [
    "def dataset_to_numpy_util(dataset, N, process_image = True):\n",
    "    dataset = dataset.batch(N)\n",
    "    \n",
    "    for images, labels in dataset:\n",
    "        numpy_images = images.numpy()\n",
    "        numpy_labels = labels.numpy()\n",
    "\n",
    "        if process_image:\n",
    "            p2, p98 = np.percentile(numpy_images, (2,98))\n",
    "            numpy_images = exposure.rescale_intensity(numpy_images, in_range=(p2, p98)) \n",
    "        break;\n",
    "\n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "def display_one_image(image, title, subplot, red=False):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16, color='red' if red else 'black')\n",
    "    return subplot+1\n",
    "\n",
    "def display_9_images_from_dataset(dataset):\n",
    "    subplot=331\n",
    "    plt.figure(figsize=(13,13))\n",
    "    images, labels = dataset_to_numpy_util(dataset, 9)\n",
    "    for i, image in enumerate(images):\n",
    "        title = labels[i] # CLASSES[labels[i]]\n",
    "        subplot = display_one_image(image, title, subplot)\n",
    "        if i >= 8:\n",
    "            break;\n",
    "              \n",
    "    #plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def display_training_curves(training, validation, title, subplot):\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        #plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6FdImv2lG6sa"
   },
   "outputs": [],
   "source": [
    "## To extract uid & ntl_group\n",
    "def dataset_to_numpy_util_single_val(dataset, N):\n",
    "    dataset = dataset.batch(N)\n",
    "    \n",
    "    for val in dataset:\n",
    "        val = val.numpy()\n",
    "        break;\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "niVFllCzY-d6"
   },
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/break-list-chunks-size-n-python/\n",
    "def divide_chunks(l, n):\n",
    "        \n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjWMxaUZE6ll"
   },
   "source": [
    "### Functions for reading images and labels from TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "QMtjiV7TEriI"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames, sat_var, exp_det, train):\n",
    "    # read from TFRecords. For optimal performance, read from multiple\n",
    "    # TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    #### Define read_tfrcord\n",
    "    # Define here. Later map over this function, and not sure how to\n",
    "    # enter sat_var into the mapping\n",
    "    def read_tfrecord(example, sat_var = sat_var):\n",
    "        features = {'viirs_ntl_group': tf.io.FixedLenFeature([], tf.int64),\n",
    "                    sat_var: tf.io.FixedLenFeature([], tf.string)}\n",
    "        parsed_features = tf.io.parse_single_example(example, features)\n",
    "\n",
    "        image = tf.io.decode_png(parsed_features[sat_var], dtype=tf.dtypes.uint16)\n",
    "        image = image / 10000 # within 0 and 1\n",
    "\n",
    "        if sat_var != 'b_rgb':\n",
    "            image = tf.repeat(image, repeats = 3, axis=2)\n",
    "\n",
    "        # If training sample, augment the data\n",
    "        if train:\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_flip_up_down(image)\n",
    "            image = tf.image.random_brightness(image, 0.025)\n",
    "\n",
    "            if sat_var == 'b_rgb':\n",
    "                image = tf.image.random_contrast(image, 0.5, 1.5)\n",
    "\n",
    "        label = tf.one_hot(parsed_features[\"viirs_ntl_group\"], NUM_GROUPS)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    #### load_dataset function\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = exp_det\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5XqDCjwuE_zt"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord_uid(example):\n",
    "    features = {'uid': tf.io.FixedLenFeature([], tf.string)}\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(example, features)\n",
    "\n",
    "    return parsed_features['uid']\n",
    "\n",
    "def load_dataset_uid(filenames, exp_det):\n",
    "    # read from TFRecords. For optimal performance, read from multiple\n",
    "    # TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = exp_det\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.map(read_tfrecord_uid, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nPym-f4fE_31"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord_ntl_group(example):\n",
    "    features = {'viirs_ntl_group': tf.io.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.io.parse_single_example(example, features)\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"viirs_ntl_group\"], NUM_GROUPS)\n",
    "\n",
    "    return label\n",
    "\n",
    "def load_dataset_ntl_group(filenames, exp_det):\n",
    "    # read from TFRecords. For optimal performance, read from multiple\n",
    "    # TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = exp_det\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.map(read_tfrecord_ntl_group, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8RQkl4MFsLk"
   },
   "source": [
    "### Functions to create batched datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wspCMcDKFrjd"
   },
   "outputs": [],
   "source": [
    "def get_batched_dataset(filenames, sat_var, exp_det, train=False):\n",
    "    dataset = load_dataset(filenames, sat_var, exp_det = exp_det, train = train)\n",
    "    dataset = dataset.cache() # This dataset fits in RAM\n",
    "    if train:\n",
    "        # Best practices for Keras:\n",
    "        # Training dataset: repeat then batch\n",
    "        # Evaluation dataset: do not repeat\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    # should shuffle too but this dataset was well shuffled on disk already\n",
    "    return dataset\n",
    "    # source: Dataset performance guide: https://www.tensorflow.org/guide/performance/datasets\n",
    "\n",
    "def get_batched_dataset_uid(filenames, exp_det, train=False):\n",
    "    dataset = load_dataset_uid(filenames, exp_det = exp_det)\n",
    "    dataset = dataset.cache() # This dataset fits in RAM\n",
    "    if train:\n",
    "        # Best practices for Keras:\n",
    "        # Training dataset: repeat then batch\n",
    "        # Evaluation dataset: do not repeat\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    # should shuffle too but this dataset was well shuffled on disk already\n",
    "    return dataset\n",
    "    # source: Dataset performance guide: https://www.tensorflow.org/guide/performance/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nmao2iZFMo6"
   },
   "source": [
    "## Load TFRecords and divide into train/test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaTeXk4rFRiM",
    "outputId": "6a0e34b9-f42d-4779-da1c-81fa0085bd02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_PATH = os.path.join(cf.DROPBOX_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData', 'Individual Datasets',\n",
    "                       'cnn_' + OUT_NAME_SUFFIX, 'tfrecords')\n",
    "GCS_PATTERN = os.path.join(TF_PATH, '*.tfrecord')\n",
    "\n",
    "#GCS_PATTERN = 'gs://ieconnectpovest/cnn_' + OUT_NAME_SUFFIX + '/tfrecords/*.tfrecord'\n",
    "all_filenames = tf.io.gfile.glob(GCS_PATTERN)\n",
    "len(all_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/LAGOS_POINTS/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_test_fold1_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/LAGOS_POINTS/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_fold1_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/LAGOS_POINTS/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_test_NA_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/LAGOS_POINTS/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_train_fold1_1_all.tfrecord']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "WK1cNuLWFRkW"
   },
   "outputs": [],
   "source": [
    "#forcnn_filenames = [x for x in all_filenames if 'forcnn_' in x]\n",
    "#split = int(len(forcnn_filenames) * VALIDATION_SPLIT)\n",
    "#training_filenames = forcnn_filenames[split:]\n",
    "#validation_filenames = forcnn_filenames[:split]\n",
    "\n",
    "# forcnn_filenames = [x for x in all_filenames if 'forcnn_' in x] # TODO: Not sure need?\n",
    "\n",
    "training_filenames = [x for x in all_filenames if 'forcnn_train_' in x]\n",
    "validation_filenames = [x for x in all_filenames if 'forcnn_test_' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVv4_7GhFRmm",
    "outputId": "281c9975-6df3-4ef9-faaf-e5c059a5915f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:11:57.298708: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 14:11:57.357100: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "#TOTAL_OBS = len(extract_uid(all_filenames))\n",
    "#print(TOTAL_OBS)\n",
    "\n",
    "TOTAL_OBS_VALIDATION = len(extract_uid(validation_filenames))\n",
    "print(TOTAL_OBS_VALIDATION)\n",
    "\n",
    "TOTAL_OBS_TRAINING = len(extract_uid(training_filenames))\n",
    "print(TOTAL_OBS_TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "k9kEz9YRFiAO"
   },
   "outputs": [],
   "source": [
    "validation_steps = TOTAL_OBS_VALIDATION // BATCH_SIZE\n",
    "steps_per_epoch  = TOTAL_OBS_TRAINING   // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYgQff2pF8pX"
   },
   "source": [
    "## Example Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Fsbsj6FdF44c"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'numpy_images' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sat_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb_rgb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdisplay_9_images_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_filenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msat_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_det\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mdisplay_9_images_from_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     23\u001b[0m subplot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m331\u001b[39m\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m13\u001b[39m))\n\u001b[0;32m---> 25\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_to_numpy_util\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[1;32m     27\u001b[0m     title \u001b[38;5;241m=\u001b[39m labels[i] \u001b[38;5;66;03m# CLASSES[labels[i]]\u001b[39;00m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mdataset_to_numpy_util\u001b[0;34m(dataset, N, process_image)\u001b[0m\n\u001b[1;32m     10\u001b[0m         numpy_images \u001b[38;5;241m=\u001b[39m exposure\u001b[38;5;241m.\u001b[39mrescale_intensity(numpy_images, in_range\u001b[38;5;241m=\u001b[39m(p2, p98)) \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m;\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy_images\u001b[49m, numpy_labels\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'numpy_images' referenced before assignment"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 936x936 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sat_var = \"b_rgb\"\n",
    "display_9_images_from_dataset(load_dataset(training_filenames, sat_var, exp_det = False, train = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DzIjMTeGLMF"
   },
   "source": [
    "## Run CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSYuNyEDF49U",
    "outputId": "1fc0b661-45f3-4084-80bc-37af737c32ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_rgb ----------------------------------------------------------\n",
      "Extract features\n",
      "0\n",
      "166/166 [==============================] - 14s 84ms/step\n",
      "1\n",
      "255/255 [==============================] - 23s 89ms/step\n",
      "2\n",
      "201/201 [==============================] - 17s 87ms/step\n",
      "3\n",
      "270/270 [==============================] - 24s 88ms/step\n",
      "4\n",
      "155/155 [==============================] - 13s 85ms/step\n",
      "5\n",
      "279/279 [==============================] - 25s 89ms/step\n",
      "6\n",
      "200/200 [==============================] - 17s 87ms/step\n",
      "7\n",
      "162/162 [==============================] - 14s 85ms/step\n",
      "8\n",
      "232/232 [==============================] - 21s 89ms/step\n",
      "9\n",
      "182/182 [==============================] - 16s 86ms/step\n",
      "10\n",
      "205/205 [==============================] - 18s 88ms/step\n",
      "11\n",
      "195/195 [==============================] - 17s 87ms/step\n",
      "12\n",
      "222/222 [==============================] - 19s 87ms/step\n",
      "13\n",
      "206/206 [==============================] - 18s 86ms/step\n",
      "14\n",
      "212/212 [==============================] - 19s 88ms/step\n",
      "15\n",
      "214/214 [==============================] - 18s 86ms/step\n",
      "16\n",
      "240/240 [==============================] - 21s 88ms/step\n",
      "17\n",
      "210/210 [==============================] - 18s 85ms/step\n",
      "18\n",
      "233/233 [==============================] - 20s 87ms/step\n",
      "19\n",
      "181/181 [==============================] - 16s 86ms/step\n",
      "20\n",
      "196/196 [==============================] - 17s 85ms/step\n",
      "21\n",
      "175/175 [==============================] - 15s 88ms/step\n",
      "22\n",
      "249/249 [==============================] - 23s 93ms/step\n",
      "23\n",
      "194/194 [==============================] - 17s 88ms/step\n",
      "24\n",
      "91/91 [==============================] - 9s 94ms/step\n",
      "Grab predicted value\n",
      "641/641 [==============================] - 60s 94ms/step\n",
      "Check predicted values\n",
      "0.3779404587603709\n",
      "b_ndvi ----------------------------------------------------------\n",
      "Extract features\n",
      "0\n",
      "166/166 [==============================] - 15s 88ms/step\n",
      "1\n",
      "255/255 [==============================] - 22s 86ms/step\n",
      "2\n",
      "201/201 [==============================] - 17s 84ms/step\n",
      "3\n",
      "270/270 [==============================] - 23s 87ms/step\n",
      "4\n",
      "155/155 [==============================] - 13s 83ms/step\n",
      "5\n",
      "279/279 [==============================] - 24s 86ms/step\n",
      "6\n",
      "200/200 [==============================] - 17s 87ms/step\n",
      "7\n",
      "162/162 [==============================] - 14s 87ms/step\n",
      "8\n",
      "232/232 [==============================] - 21s 91ms/step\n",
      "9\n",
      "182/182 [==============================] - 17s 93ms/step\n",
      "10\n",
      "205/205 [==============================] - 20s 100ms/step\n",
      "11\n",
      "195/195 [==============================] - 18s 95ms/step\n",
      "12\n",
      "222/222 [==============================] - 21s 94ms/step\n",
      "13\n",
      "206/206 [==============================] - 19s 95ms/step\n",
      "14\n",
      "212/212 [==============================] - 20s 96ms/step\n",
      "15\n",
      "214/214 [==============================] - 20s 96ms/step\n",
      "16\n",
      "240/240 [==============================] - 23s 95ms/step\n",
      "17\n",
      "210/210 [==============================] - 20s 94ms/step\n",
      "18\n",
      "233/233 [==============================] - 22s 96ms/step\n",
      "19\n",
      "181/181 [==============================] - 17s 96ms/step\n",
      "20\n",
      "196/196 [==============================] - 18s 92ms/step\n",
      "21\n",
      "175/175 [==============================] - 16s 93ms/step\n",
      "22\n",
      "249/249 [==============================] - 23s 94ms/step\n",
      "23\n",
      "194/194 [==============================] - 18s 91ms/step\n",
      "24\n",
      "91/91 [==============================] - 8s 89ms/step\n",
      "Grab predicted value\n",
      "641/641 [==============================] - 60s 93ms/step\n",
      "Check predicted values\n",
      "0.44333821376281113\n",
      "b_bu ----------------------------------------------------------\n",
      "Extract features\n",
      "0\n",
      "166/166 [==============================] - 15s 89ms/step\n",
      "1\n",
      "255/255 [==============================] - 24s 93ms/step\n",
      "2\n",
      "201/201 [==============================] - 18s 92ms/step\n",
      "3\n",
      "270/270 [==============================] - 25s 93ms/step\n",
      "4\n",
      "155/155 [==============================] - 14s 89ms/step\n",
      "5\n",
      "279/279 [==============================] - 26s 94ms/step\n",
      "6\n",
      "200/200 [==============================] - 18s 91ms/step\n",
      "7\n",
      "162/162 [==============================] - 15s 92ms/step\n",
      "8\n",
      "232/232 [==============================] - 22s 93ms/step\n",
      "9\n",
      "182/182 [==============================] - 18s 99ms/step\n",
      "10\n",
      "205/205 [==============================] - 20s 100ms/step\n",
      "11\n",
      "195/195 [==============================] - 19s 97ms/step\n",
      "12\n",
      "222/222 [==============================] - 21s 93ms/step\n",
      "13\n",
      "206/206 [==============================] - 19s 92ms/step\n",
      "14\n",
      "212/212 [==============================] - 21s 98ms/step\n",
      "15\n",
      "214/214 [==============================] - 20s 92ms/step\n",
      "16\n",
      "240/240 [==============================] - 22s 93ms/step\n",
      "17\n",
      "210/210 [==============================] - 19s 93ms/step\n",
      "18\n",
      "233/233 [==============================] - 23s 97ms/step\n",
      "19\n",
      "181/181 [==============================] - 18s 99ms/step\n",
      "20\n",
      "196/196 [==============================] - 18s 92ms/step\n",
      "21\n",
      "175/175 [==============================] - 16s 91ms/step\n",
      "22\n",
      "249/249 [==============================] - 23s 93ms/step\n",
      "23\n",
      "194/194 [==============================] - 18s 92ms/step\n",
      "24\n",
      "91/91 [==============================] - 8s 89ms/step\n",
      "Grab predicted value\n",
      "641/641 [==============================] - 59s 92ms/step\n",
      "Check predicted values\n",
      "0.39199609565641774\n"
     ]
    }
   ],
   "source": [
    "# If False, loads previously processed model and creates (a) features and (b)\n",
    "# predictions datasets \n",
    "RUN_MODEL = False\n",
    "MAKE_DATASETS = True\n",
    "\n",
    "overwrite_model = False # Whether to overwrite model if already exists\n",
    "\n",
    "for sat_var in ['b_rgb', 'b_ndvi', 'b_bu']: # 'b_rgb', 'b_ndvi', 'b_bu'\n",
    "  \n",
    "    print(sat_var + ' ----------------------------------------------------------')\n",
    "\n",
    "    # 1. PREP AND RUN MODEL ========================================================\n",
    "\n",
    "    # Instantiate the datasets -----------------------------------------------------\n",
    "    training_dataset = get_batched_dataset(training_filenames, sat_var, exp_det = False, train=True)\n",
    "    validation_dataset = get_batched_dataset(validation_filenames, sat_var, exp_det = False, train=False)\n",
    "\n",
    "    validation_dataset_exdtT = get_batched_dataset(validation_filenames, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_exdtT = get_batched_dataset(all_filenames, sat_var, exp_det = True, train=False)\n",
    "\n",
    "    # Split all_dataset into chunks ----------------------------------------------\n",
    "    # We max out RAM when trying to get full dataset of all features, so break into chunks\n",
    "    n_group = math.ceil(len(all_filenames)/25)\n",
    "\n",
    "    all_filenames_list = list(divide_chunks(all_filenames, n_group))\n",
    "\n",
    "    all_filenames_0 = all_filenames_list[0]\n",
    "    all_filenames_1 = all_filenames_list[1]\n",
    "    all_filenames_2 = all_filenames_list[2]\n",
    "    all_filenames_3 = all_filenames_list[3]\n",
    "    all_filenames_4 = all_filenames_list[4]\n",
    "    all_filenames_5 = all_filenames_list[5]\n",
    "    all_filenames_6 = all_filenames_list[6]\n",
    "    all_filenames_7 = all_filenames_list[7]\n",
    "    all_filenames_8 = all_filenames_list[8]\n",
    "    all_filenames_9 = all_filenames_list[9]\n",
    "    all_filenames_10 = all_filenames_list[10]\n",
    "    all_filenames_11 = all_filenames_list[11]\n",
    "    all_filenames_12 = all_filenames_list[12]\n",
    "    all_filenames_13 = all_filenames_list[13]\n",
    "    all_filenames_14 = all_filenames_list[14]\n",
    "    all_filenames_15 = all_filenames_list[15]\n",
    "    all_filenames_16 = all_filenames_list[16]\n",
    "    all_filenames_17 = all_filenames_list[17]\n",
    "    all_filenames_18 = all_filenames_list[18]\n",
    "    all_filenames_19 = all_filenames_list[19]\n",
    "    all_filenames_20 = all_filenames_list[20]\n",
    "    all_filenames_21 = all_filenames_list[21]\n",
    "    all_filenames_22 = all_filenames_list[22]\n",
    "    all_filenames_23 = all_filenames_list[23]\n",
    "    all_filenames_24 = all_filenames_list[24]\n",
    "\n",
    "    all_dataset_0_exdtT = get_batched_dataset(all_filenames_0, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_1_exdtT = get_batched_dataset(all_filenames_1, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_2_exdtT = get_batched_dataset(all_filenames_2, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_3_exdtT = get_batched_dataset(all_filenames_3, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_4_exdtT = get_batched_dataset(all_filenames_4, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_5_exdtT = get_batched_dataset(all_filenames_5, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_6_exdtT = get_batched_dataset(all_filenames_6, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_7_exdtT = get_batched_dataset(all_filenames_7, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_8_exdtT = get_batched_dataset(all_filenames_8, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_9_exdtT = get_batched_dataset(all_filenames_9, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_10_exdtT = get_batched_dataset(all_filenames_10, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_11_exdtT = get_batched_dataset(all_filenames_11, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_12_exdtT = get_batched_dataset(all_filenames_12, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_13_exdtT = get_batched_dataset(all_filenames_13, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_14_exdtT = get_batched_dataset(all_filenames_14, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_15_exdtT = get_batched_dataset(all_filenames_15, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_16_exdtT = get_batched_dataset(all_filenames_16, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_17_exdtT = get_batched_dataset(all_filenames_17, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_18_exdtT = get_batched_dataset(all_filenames_18, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_19_exdtT = get_batched_dataset(all_filenames_19, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_20_exdtT = get_batched_dataset(all_filenames_20, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_21_exdtT = get_batched_dataset(all_filenames_21, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_22_exdtT = get_batched_dataset(all_filenames_22, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_23_exdtT = get_batched_dataset(all_filenames_23, sat_var, exp_det = True, train=False)\n",
    "    all_dataset_24_exdtT = get_batched_dataset(all_filenames_24, sat_var, exp_det = True, train=False)\n",
    "\n",
    "    # Output names -----------------------------------------------------------------\n",
    "    # Paths for saving model, predictions (on test) and featurs (on training)\n",
    "    name_suffix = OUT_NAME_SUFFIX + \"_\" + sat_var\n",
    "\n",
    "    CNN_MODEL_PATH = os.path.join(cf.DROPBOX_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData', \"Individual Datasets\",\n",
    "                                    'cnn_models', \n",
    "                                    'model_' + name_suffix + '.h5')\n",
    "\n",
    "    PREDICTIONS_PATH = os.path.join(cf.DROPBOX_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData', \"Individual Datasets\",\n",
    "                                    'cnn_predictions',\n",
    "                                    'predictions_' + name_suffix + '.csv')\n",
    "\n",
    "    FEATURES_PATH = os.path.join(cf.DROPBOX_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData', \"Individual Datasets\",\n",
    "                                    'cnn_features', \"split_into_data_subsets\",\n",
    "                                    'features_' + name_suffix)\n",
    "\n",
    "    # Define model ---------------------------------------------------------------\n",
    "    if (RUN_MODEL & ((os.path.exists(CNN_MODEL_PATH) == False | overwrite_model))): \n",
    "        ### Setup Pre-Trained Network\n",
    "        #pretrained_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n",
    "        pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "        #pretrained_model = tf.keras.applications.ResNet18(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
    "        #pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
    "        pretrained_model.trainable = False\n",
    "\n",
    "        ### Setup Model\n",
    "        model = tf.keras.Sequential([\n",
    "            pretrained_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(4096, activation='relu', name = 'fc1'), # 512, 4096\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(NUM_GROUPS, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='rmsprop', # adam\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        # Run model --------------------------------------------------------------------\n",
    "        ### Setup Early Stopping\n",
    "        # Use early stopping to help with overfitting\n",
    "        monitor = 'val_accuracy'\n",
    "        mode = 'max'\n",
    "        es = EarlyStopping(monitor=monitor, mode=mode, patience=PATIENCE, verbose=False)\n",
    "\n",
    "        mc = ModelCheckpoint(CNN_MODEL_PATH, monitor=monitor, mode=mode, \n",
    "                            verbose=True, save_best_only=True)\n",
    "\n",
    "        ### Fit Model\n",
    "        history = model.fit(training_dataset, \n",
    "                            steps_per_epoch=steps_per_epoch, \n",
    "                            epochs=EPOCHS,\n",
    "                            callbacks=[es, mc],\n",
    "                            validation_data=validation_dataset, \n",
    "                            validation_steps=validation_steps)\n",
    "\n",
    "        # Show history -----------------------------------------------------------------\n",
    "        print(history.history.keys())\n",
    "        display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
    "        display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)\n",
    "\n",
    "    # 2. EXTRACT FEATURES AND PREDICTIONS ==========================================\n",
    "    if MAKE_DATASETS:\n",
    "\n",
    "        ## Load model ------------------------------------------------------------------\n",
    "        model = load_model(CNN_MODEL_PATH)\n",
    "\n",
    "        ## Double check evaluation -----------------------------------------------------\n",
    "        if False:\n",
    "            print(\"Check validation accuracy\")\n",
    "            model.evaluate(validation_dataset_exdtT) \n",
    "\n",
    "        ## Grab features ---------------------------------------------------------------\n",
    "        print(\"Extract features\")\n",
    "        feature_extractor = Model(inputs=model.inputs,\n",
    "                        outputs=model.get_layer(name='fc1').output,)\n",
    "\n",
    "        def extract_features(all_dataset_i_exdtT, all_filenames_i, i, FEATURES_PATH):\n",
    "            print(i)\n",
    "\n",
    "            features_i = feature_extractor.predict(all_dataset_i_exdtT)\n",
    "            features_i_df = pd.DataFrame(features_i).add_prefix('cnn_feat_')\n",
    "            features_i_df['uid'] = dataset_to_numpy_util_single_val(load_dataset_uid(all_filenames_i, exp_det = True),features_i_df.shape[0])\n",
    "            features_i_df.to_csv(FEATURES_PATH + '_' + str(i) + '.csv', index=False)\n",
    "\n",
    "        extract_features(all_dataset_0_exdtT, all_filenames_0, 0, FEATURES_PATH)\n",
    "        extract_features(all_dataset_1_exdtT, all_filenames_1, 1, FEATURES_PATH)\n",
    "        extract_features(all_dataset_2_exdtT, all_filenames_2, 2, FEATURES_PATH)\n",
    "        extract_features(all_dataset_3_exdtT, all_filenames_3, 3, FEATURES_PATH)\n",
    "        extract_features(all_dataset_4_exdtT, all_filenames_4, 4, FEATURES_PATH)\n",
    "        extract_features(all_dataset_5_exdtT, all_filenames_5, 5, FEATURES_PATH)\n",
    "        extract_features(all_dataset_6_exdtT, all_filenames_6, 6, FEATURES_PATH)\n",
    "        extract_features(all_dataset_7_exdtT, all_filenames_7, 7, FEATURES_PATH)\n",
    "        extract_features(all_dataset_8_exdtT, all_filenames_8, 8, FEATURES_PATH)\n",
    "        extract_features(all_dataset_9_exdtT, all_filenames_9, 9, FEATURES_PATH)\n",
    "        extract_features(all_dataset_10_exdtT, all_filenames_10, 10, FEATURES_PATH)\n",
    "        extract_features(all_dataset_11_exdtT, all_filenames_11, 11, FEATURES_PATH)\n",
    "        extract_features(all_dataset_12_exdtT, all_filenames_12, 12, FEATURES_PATH)\n",
    "        extract_features(all_dataset_13_exdtT, all_filenames_13, 13, FEATURES_PATH)\n",
    "        extract_features(all_dataset_14_exdtT, all_filenames_14, 14, FEATURES_PATH)\n",
    "        extract_features(all_dataset_15_exdtT, all_filenames_15, 15, FEATURES_PATH)\n",
    "        extract_features(all_dataset_16_exdtT, all_filenames_16, 16, FEATURES_PATH)\n",
    "        extract_features(all_dataset_17_exdtT, all_filenames_17, 17, FEATURES_PATH)\n",
    "        extract_features(all_dataset_18_exdtT, all_filenames_18, 18, FEATURES_PATH)\n",
    "        extract_features(all_dataset_19_exdtT, all_filenames_19, 19, FEATURES_PATH)\n",
    "        extract_features(all_dataset_20_exdtT, all_filenames_20, 20, FEATURES_PATH)\n",
    "        extract_features(all_dataset_21_exdtT, all_filenames_21, 21, FEATURES_PATH)\n",
    "        extract_features(all_dataset_22_exdtT, all_filenames_22, 22, FEATURES_PATH)\n",
    "        extract_features(all_dataset_23_exdtT, all_filenames_23, 23, FEATURES_PATH)\n",
    "        extract_features(all_dataset_24_exdtT, all_filenames_24, 24, FEATURES_PATH)\n",
    "\n",
    "        #feature_extractor = Model(inputs=model.inputs,\n",
    "        #                  outputs=model.get_layer(name='fc1').output,)\n",
    "\n",
    "        #features = feature_extractor.predict(all_dataset_exdtT)\n",
    "        #features_df = pd.DataFrame(features).add_prefix('cnn_feat_')\n",
    "\n",
    "        #features_df['uid'] = dataset_to_numpy_util_single_val(load_dataset_uid(all_filenames, exp_det = True),features_df.shape[0])\n",
    "\n",
    "        #features_df.to_csv(FEATURES_PATH, index=False)\n",
    "\n",
    "        ## Grab predicted value --------------------------------------------------------\n",
    "        print(\"Grab predicted value\")\n",
    "        predictions = model.predict(validation_dataset_exdtT)\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "        true_values = dataset_to_numpy_util_single_val(load_dataset_ntl_group(validation_filenames, exp_det = True),predictions.shape[0])\n",
    "        true_values = true_values.argmax(axis=-1)\n",
    "\n",
    "        pred_df = pd.DataFrame({'predictions':predictions, 'true_values':true_values})\n",
    "        pred_df['uid'] = dataset_to_numpy_util_single_val(load_dataset_uid(validation_filenames, exp_det = True),predictions.shape[0])\n",
    "\n",
    "        pred_df.to_csv(PREDICTIONS_PATH, index=False)\n",
    "\n",
    "        # Check predicted values -------------------------------------------------------\n",
    "        print(\"Check predicted values\")\n",
    "        print(np.mean(pred_df['predictions'] == pred_df['true_values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUt4mQwwF-p8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgzW_FeNkOBg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijdyyze7LLwC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "02_cnn_CLEAN_LOOP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
