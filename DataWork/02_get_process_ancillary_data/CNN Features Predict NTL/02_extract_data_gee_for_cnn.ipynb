{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0MV-G1dXVY2"
   },
   "source": [
    "# Prepare CNN Data\n",
    "\n",
    "__IMPORTANT:__\n",
    "1. In `config.py`, change `DROPBOX_DIRECTORY` to point to the appropriate folder on your computer.\n",
    "2. The script needs to be separately run when `SURVEY_NAME` equals `DHS`, `DHS_nga_policy_experiment`, and `LSMS`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "# Datasets -------------------------------------\n",
    "SURVEY_NAME = 'DHS' # \"DHS\", \"DHS_nga_policy_experiment\", \"LSMS\"\n",
    "\n",
    "VERSION = 2\n",
    "if VERSION == 1:\n",
    "\n",
    "    SATELLITE         = 's2' \n",
    "    OUTCOME_VAR       = \"viirs\" \n",
    "    UNDERSAMPLE_INDIA = True\n",
    "    \n",
    "if VERSION == 2:\n",
    "\n",
    "    SATELLITE         = 'landsat' \n",
    "    OUTCOME_VAR       = \"ntlharmon\" \n",
    "    UNDERSAMPLE_INDIA = True\n",
    "\n",
    "# Processing data ------------------------------\n",
    "SKIP_IF_SCRAPED = True ## Skip if filename has already been created\n",
    "CHECK_IF_UID_SCRAPED = False ## Load data already scraped and skip if scraped; add date to filename\n",
    "IGNORE_ERRORS = False ## Load dataset of errors and remove from ones to scrape\n",
    "\n",
    "CHUNK_SIZE = 1 # Number of observtaions to scrape in GEE at any given time\n",
    "\n",
    "# Parameters based on dataset ---------------------\n",
    "if SATELLITE == 's2':\n",
    "    KERNEL_SIZE = 224\n",
    "elif SATELLITE == 'landsat':\n",
    "    KERNEL_SIZE = 224 #167\n",
    "elif SATELLITE == 'landsat_7':\n",
    "    KERNEL_SIZE = 224 #167\n",
    "\n",
    "print(KERNEL_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuOZpPbiXVY5"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "#ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, datetime\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import config as cf\n",
    "import ee_utils as utils\n",
    "import eeconvert\n",
    "import time\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "DROPBOX_DIR = cf.DROPBOX_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_fn_uid(record_bytes):\n",
    "    return tf.io.parse_single_example(\n",
    "        # Data\n",
    "        record_bytes,\n",
    "\n",
    "        # Schema\n",
    "        {\"uid\": tf.io.FixedLenFeature([], dtype=tf.string)}\n",
    "    )\n",
    "\n",
    "def extract_uid(TF_FILES):\n",
    "    actual_values = []\n",
    "    for batch in tf.data.TFRecordDataset([TF_FILES]).map(decode_fn_uid):\n",
    "        value = batch['uid'].numpy()\n",
    "        actual_values.append(value)\n",
    "\n",
    "    return actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwPA7XTCYmjh",
    "outputId": "74e611ba-5c81-44ca-e2ce-c595399753a0"
   },
   "outputs": [],
   "source": [
    "# Directory to store tfrecords\n",
    "out_path = os.path.join(DROPBOX_DIR, \n",
    "            'Data', \n",
    "            SURVEY_NAME, \n",
    "            'FinalData',\n",
    "            'Individual Datasets',\n",
    "            'cnn_' + SATELLITE + '_' + OUTCOME_VAR + '_underia' + str(UNDERSAMPLE_INDIA),\n",
    "            'tfrecords')\n",
    "\n",
    "out_path_errors = os.path.join(DROPBOX_DIR, \n",
    "            'Data', \n",
    "            SURVEY_NAME, \n",
    "            'FinalData',\n",
    "            'Individual Datasets',\n",
    "            'cnn_' + SATELLITE + '_' + OUTCOME_VAR + '_underia' + str(UNDERSAMPLE_INDIA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phzXq49zXVY5",
    "outputId": "0b60e419-0e3f-44e2-e927-0895afb316cc"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3517, 9)\n",
      "0    1140\n",
      "1    1038\n",
      "3     527\n",
      "2     418\n",
      "4     394\n",
      "Name: ntl_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "if UNDERSAMPLE_INDIA == True:\n",
    "    UNDERSAMPLE_INDIA_str = \"TRUE\"\n",
    "else:\n",
    "    UNDERSAMPLE_INDIA_str = \"FALSE\"\n",
    "    \n",
    "survey_df = pd.read_csv(os.path.join(DROPBOX_DIR, 'Data', SURVEY_NAME, 'FinalData', 'Individual Datasets', \n",
    "                                     'data_for_cnn_' + OUTCOME_VAR + '_iaunder' + UNDERSAMPLE_INDIA_str + '_' + SATELLITE + '.csv'))\n",
    "\n",
    "### If sentinel, only use most recent\n",
    "if SATELLITE == 's2':\n",
    "    survey_df = survey_df[survey_df.most_recent_survey == True]\n",
    "        \n",
    "### N Observations      \n",
    "print(survey_df.shape)\n",
    "print(survey_df.ntl_group.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if UID Already Scraped\n",
    "\n",
    "(1) Filter surveys to those that have been scraped, and (2) add date/time to filename (so process of checking if file has been scraped doesnt skip it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IGNORE_ERRORS:\n",
    "    error_files = glob.glob(out_path_errors + '/*.csv')\n",
    "    error_df = pd.concat([pd.read_csv(f) for f in error_files])\n",
    "\n",
    "    survey_df = survey_df[~survey_df['uid'].isin(error_df['uid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if everything processed, ignoring errors\n",
    "if False:\n",
    "    tf_paths = glob.glob(out_path + '/*.tfrecord')\n",
    "    processed_uids = extract_uid(tf_paths)\n",
    "\n",
    "    ## List of IDs already processed\n",
    "    processed_uids = [x.decode('utf-8') for x in processed_uids]\n",
    "\n",
    "    ## Subset survey to uids not scraped\n",
    "    survey_df = survey_df[~survey_df['uid'].isin(processed_uids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECK_IF_UID_SCRAPED:\n",
    "\n",
    "    tf_paths = glob.glob(out_path + '/*.tfrecord')\n",
    "    processed_uids = extract_uid(tf_paths)\n",
    "    \n",
    "    ## List of IDs already processed\n",
    "    processed_uids = [x.decode('utf-8') for x in processed_uids]\n",
    "    \n",
    "    ## Subset survey to uids not scraped\n",
    "    survey_df = survey_df[~survey_df['uid'].isin(processed_uids)]\n",
    "    \n",
    "    ## Change name of tfrecords\n",
    "    txt_to_add = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    survey_df['tfrecord_name'] = survey_df.apply(lambda row: row['tfrecord_name'].replace('.tfrecord', \"_\" + txt_to_add + '.tfrecord'), axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip tfrecords already processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>GID_2</th>\n",
       "      <th>year</th>\n",
       "      <th>most_recent_survey</th>\n",
       "      <th>ntl_group</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>tfrecord_name</th>\n",
       "      <th>use_for_cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NG201800000173</td>\n",
       "      <td>NGA.26.5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>8.827548</td>\n",
       "      <td>8.260982</td>\n",
       "      <td>forcnn_test_NG_5_1_all.tfrecord</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NG201800000377</td>\n",
       "      <td>NGA.16.9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>11.298931</td>\n",
       "      <td>11.001922</td>\n",
       "      <td>forcnn_test_NG_4_1_all.tfrecord</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NG201800000391</td>\n",
       "      <td>NGA.16.7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>11.576570</td>\n",
       "      <td>9.968071</td>\n",
       "      <td>forcnn_test_NG_2_1_all.tfrecord</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NG201800000452</td>\n",
       "      <td>NGA.36.13_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>10.390373</td>\n",
       "      <td>13.037673</td>\n",
       "      <td>forcnn_test_NG_4_1_all.tfrecord</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NG201800000343</td>\n",
       "      <td>NGA.8.9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>12.812301</td>\n",
       "      <td>12.719028</td>\n",
       "      <td>forcnn_test_NG_2_1_all.tfrecord</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              uid        GID_2  year  most_recent_survey  ntl_group  \\\n",
       "0  NG201800000173   NGA.26.5_1  2018                True          0   \n",
       "1  NG201800000377   NGA.16.9_1  2018                True          0   \n",
       "2  NG201800000391   NGA.16.7_1  2018                True          0   \n",
       "3  NG201800000452  NGA.36.13_1  2018                True          0   \n",
       "4  NG201800000343    NGA.8.9_1  2018                True          0   \n",
       "\n",
       "   longitude   latitude                    tfrecord_name use_for_cnn  \n",
       "0   8.827548   8.260982  forcnn_test_NG_5_1_all.tfrecord         yes  \n",
       "1  11.298931  11.001922  forcnn_test_NG_4_1_all.tfrecord         yes  \n",
       "2  11.576570   9.968071  forcnn_test_NG_2_1_all.tfrecord         yes  \n",
       "3  10.390373  13.037673  forcnn_test_NG_4_1_all.tfrecord         yes  \n",
       "4  12.812301  12.719028  forcnn_test_NG_2_1_all.tfrecord         yes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3517, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forcnn_test_NG_1_1_all.tfrecord',\n",
       " 'forcnn_test_NG_2_1_all.tfrecord',\n",
       " 'forcnn_test_NG_3_1_all.tfrecord',\n",
       " 'forcnn_test_NG_4_1_all.tfrecord',\n",
       " 'forcnn_test_NG_5_1_all.tfrecord',\n",
       " 'forcnn_train_NG_1_1_all.tfrecord',\n",
       " 'forcnn_train_NG_2_1_all.tfrecord',\n",
       " 'forcnn_train_NG_3_1_all.tfrecord',\n",
       " 'forcnn_train_NG_4_1_all.tfrecord',\n",
       " 'forcnn_train_NG_5_1_all.tfrecord',\n",
       " 'nocnn_NG_1_1_all.tfrecord',\n",
       " 'nocnn_NG_1_2_all.tfrecord',\n",
       " 'nocnn_NG_1_3_all.tfrecord',\n",
       " 'nocnn_NG_2_1_all.tfrecord',\n",
       " 'nocnn_NG_2_2_all.tfrecord',\n",
       " 'nocnn_NG_2_3_all.tfrecord',\n",
       " 'nocnn_NG_3_1_all.tfrecord',\n",
       " 'nocnn_NG_3_2_all.tfrecord',\n",
       " 'nocnn_NG_3_3_all.tfrecord',\n",
       " 'nocnn_NG_4_1_all.tfrecord',\n",
       " 'nocnn_NG_4_2_all.tfrecord',\n",
       " 'nocnn_NG_4_3_all.tfrecord',\n",
       " 'nocnn_NG_5_1_all.tfrecord',\n",
       " 'nocnn_NG_5_2_all.tfrecord',\n",
       " 'nocnn_NG_5_3_all.tfrecord']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of TF Records\n",
    "tf_record_list = list(np.unique(survey_df.tfrecord_name))\n",
    "\n",
    "len(tf_record_list)\n",
    "\n",
    "tf_record_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(out_path) == False:\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PTEEJI89XVY6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# If skip already scraped, remove existing tfrecords from tf_record_list\n",
    "if SKIP_IF_SCRAPED:\n",
    "    tf_records_exist = os.listdir(out_path)\n",
    "    tf_record_list = [x for x in tf_record_list if x not in tf_records_exist]\n",
    "    \n",
    "print(len(tf_record_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/erdemarslan/3ec02009f38f8df84c8e4807e7954af3\n",
    "if False:\n",
    "    import urllib3\n",
    "\n",
    "    def check_internet_conn():\n",
    "        http = urllib3.PoolManager(timeout=3.0)\n",
    "        r = http.request('GET', 'google.com', preload_content=False)\n",
    "        code = r.status\n",
    "        r.release_conn()\n",
    "        if code == 200:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blank error dataframe\n",
    "errors_df = pd.DataFrame()\n",
    "\n",
    "## Error file name\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%d_%m_%y_%H_%M_%S\")\n",
    "error_file_name = 'errors_' + current_time + '.csv'\n",
    "\n",
    "if True:\n",
    "    ### Loop through all tfrecords\n",
    "    for tfr_i in tf_record_list:\n",
    "\n",
    "        # Sometimes we get computational time out errors. If occurs, just skip and go to next.\n",
    "        # We can then go back and rescrape missed ones.\n",
    "\n",
    "        survey_df_yeari = survey_df[survey_df['tfrecord_name'] == tfr_i]\n",
    "        year_i = survey_df_yeari['year'].iloc[0]\n",
    "\n",
    "        ### Loop through chunks within tfrecord (can only pull so much data from GEE at a time)\n",
    "        survey_df_yeari['chunk_id'] = utils.chunk_ids(survey_df_yeari.shape[0], CHUNK_SIZE)\n",
    "\n",
    "        print(\"Putting \" + str(survey_df_yeari.shape[0]) + \" observations into \" + tfr_i)\n",
    "\n",
    "        proto_examples_all = []\n",
    "        for chunk_i in list(np.unique(survey_df_yeari.chunk_id)):\n",
    "            \n",
    "\n",
    "            try:\n",
    "\n",
    "                time.sleep(3)\n",
    "                print(\"Observation: \" + str(len(proto_examples_all)) + \"/\" + str(survey_df_yeari.shape[0]))\n",
    "\n",
    "                survey_df_yeari_chunki = survey_df_yeari[survey_df_yeari['chunk_id'] == chunk_i]\n",
    "\n",
    "                proto_examples_i = utils.prep_cnn_np(survey_df_yeari_chunki, SATELLITE, KERNEL_SIZE, year_i)\n",
    "                proto_examples_all.extend(proto_examples_i)\n",
    "\n",
    "            except:\n",
    "\n",
    "                print(\"Error ---\")\n",
    "                print(survey_df_yeari_chunki['uid'])\n",
    "\n",
    "                errors_df = errors_df.append(survey_df_yeari_chunki[['uid']], ignore_index = True)\n",
    "                errors_df.to_csv(os.path.join(out_path_errors, error_file_name))\n",
    "\n",
    "                time.sleep(15)\n",
    "                pass\n",
    "\n",
    "        ### Save data as tf record\n",
    "        out_path_i = os.path.join(out_path, tfr_i)\n",
    "        print(out_path_i)\n",
    "        with tf.io.TFRecordWriter(out_path_i) as writer:\n",
    "            for tf_example in proto_examples_all:\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "\n",
    "        print(\"Success \\o/\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_extract_data_gee_for_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
