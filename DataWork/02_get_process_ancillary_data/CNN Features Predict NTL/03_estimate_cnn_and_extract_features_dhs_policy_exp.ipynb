{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DA6XKs-DESD"
   },
   "source": [
    "# Estimate CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vOjYjPI4iy0H"
   },
   "outputs": [],
   "source": [
    "#TODO:\n",
    "#* Lets have forcnn be training and nocnn be validation. No need for separate test set. Hmmmm no., wont have all classes.\n",
    "#*In prepping, may want to ensure balance within (a) train and (b) validation\n",
    "\n",
    "# Functions up top, then parameters / for loop below (some stuff doesn't need to be repeated for the for loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2bzIvfOYrVP"
   },
   "source": [
    "Adapted from:\n",
    "\n",
    "https://codelabs.developers.google.com/codelabs/keras-flowers-transfer-learning#0\n",
    "\n",
    "https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/04_Keras_Flowers_transfer_learning_solution.ipynb#scrollTo=M3G-2aUBQJ-H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JJTMmXsEf8n"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "2Tdoud0HJNx1"
   },
   "outputs": [],
   "source": [
    "## Satellite and survey params\n",
    "SURVEY_NAME = 'DHS_nga_policy_experiment'\n",
    "\n",
    "# Parameters ------------------------------\n",
    "VERSION = 2\n",
    "\n",
    "if VERSION == 1:\n",
    "\n",
    "    SATELLITE         = 's2' \n",
    "    OUTCOME_VAR       = \"viirs\" \n",
    "    UNDERSAMPLE_INDIA = True\n",
    "    \n",
    "if VERSION == 2:\n",
    "\n",
    "    SATELLITE         = 'landsat' \n",
    "    OUTCOME_VAR       = \"ntlharmon\" \n",
    "    UNDERSAMPLE_INDIA = True\n",
    "\n",
    "# Objects based on parameters ------------\n",
    "OUT_NAME_SUFFIX   = SATELLITE + '_' + OUTCOME_VAR + '_underia' + str(UNDERSAMPLE_INDIA)\n",
    "\n",
    "## CNN params\n",
    "if SATELLITE == 's2':\n",
    "    IMAGE_SIZE = [224, 224]\n",
    "elif SATELLITE == 'landsat':\n",
    "    IMAGE_SIZE = [224, 224]\n",
    "\n",
    "if OUTCOME_VAR == 'viirs':\n",
    "    NUM_GROUPS = 5\n",
    "elif OUTCOME_VAR == 'ntlharmon':\n",
    "    NUM_GROUPS = 5\n",
    "\n",
    "EPOCHS           = 200\n",
    "BATCH_SIZE       = 16 #16, 32\n",
    "PATIENCE         = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aixnvSxAEfc0",
    "outputId": "c7c23065-d656-4686-a2a4-563ab8096963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage import exposure\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import config as cf\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBdsPW_tEkN9",
    "outputId": "1536ddbe-5437-4b4b-af79-c95a9d4ee306"
   },
   "outputs": [],
   "source": [
    "# Authenticate Google Drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "d67D5MGjEkQi"
   },
   "outputs": [],
   "source": [
    "# Authenticate Google Cloud\n",
    "#from google.colab import auth\n",
    "#auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "T4dgVWXFEm9L"
   },
   "outputs": [],
   "source": [
    "#GOOGLEDRIVE_DIRECTORY = os.path.join('/Volumes/GoogleDrive/My Drive/World Bank/IEs/Pakistan Poverty Estimation')\n",
    "#GOOGLEDRIVE_DIRECTORY = os.path.join('/content/gdrive/My Drive/World Bank/IEs/Pakistan Poverty Estimation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "083GuGrVFw_d"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSigR3d-EpvJ"
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "IhRluY8pErdJ"
   },
   "outputs": [],
   "source": [
    "# Get actual values function\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset\n",
    "\n",
    "#### NTL Group\n",
    "def decode_fn_ntl_group(record_bytes):\n",
    "    return tf.io.parse_single_example(\n",
    "        # Data\n",
    "        record_bytes,\n",
    "\n",
    "        # Schema\n",
    "        {\"viirs_ntl_group\": tf.io.FixedLenFeature([], dtype=tf.int64)}\n",
    "    )\n",
    "\n",
    "def extract_ntl_group(TF_FILES):\n",
    "    actual_values = []\n",
    "    for batch in tf.data.TFRecordDataset([TF_FILES]).map(decode_fn_ntl_group):\n",
    "        value = batch['viirs_ntl_group'].numpy()\n",
    "        actual_values.append(value)\n",
    "\n",
    "    return actual_values\n",
    "\n",
    "#### UID\n",
    "def decode_fn_uid(record_bytes):\n",
    "    return tf.io.parse_single_example(\n",
    "        # Data\n",
    "        record_bytes,\n",
    "\n",
    "        # Schema\n",
    "        {\"uid\": tf.io.FixedLenFeature([], dtype=tf.string)}\n",
    "    )\n",
    "\n",
    "def extract_uid(TF_FILES):\n",
    "    actual_values = []\n",
    "    for batch in tf.data.TFRecordDataset([TF_FILES]).map(decode_fn_uid):\n",
    "        value = batch['uid'].numpy()\n",
    "        actual_values.append(value)\n",
    "\n",
    "    return actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "_ZIHgcH7ErgF"
   },
   "outputs": [],
   "source": [
    "def dataset_to_numpy_util(dataset, N, process_image = True):\n",
    "    dataset = dataset.batch(N)\n",
    "    \n",
    "    for images, labels in dataset:\n",
    "        numpy_images = images.numpy()\n",
    "        numpy_labels = labels.numpy()\n",
    "\n",
    "        if process_image:\n",
    "            p2, p98 = np.percentile(numpy_images, (2,98))\n",
    "            numpy_images = exposure.rescale_intensity(numpy_images, in_range=(p2, p98)) \n",
    "        break;\n",
    "\n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "def display_one_image(image, title, subplot, red=False):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16, color='red' if red else 'black')\n",
    "    return subplot+1\n",
    "\n",
    "def display_9_images_from_dataset(dataset):\n",
    "    subplot=331\n",
    "    plt.figure(figsize=(13,13))\n",
    "    images, labels = dataset_to_numpy_util(dataset, 9)\n",
    "    for i, image in enumerate(images):\n",
    "        title = labels[i] # CLASSES[labels[i]]\n",
    "        subplot = display_one_image(image, title, subplot)\n",
    "        if i >= 8:\n",
    "            break;\n",
    "              \n",
    "    #plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def display_training_curves(training, validation, title, subplot):\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        #plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6FdImv2lG6sa"
   },
   "outputs": [],
   "source": [
    "## To extract uid & ntl_group\n",
    "def dataset_to_numpy_util_single_val(dataset, N):\n",
    "    dataset = dataset.batch(N)\n",
    "    \n",
    "    for val in dataset:\n",
    "        val = val.numpy()\n",
    "        break;\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "niVFllCzY-d6"
   },
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/break-list-chunks-size-n-python/\n",
    "def divide_chunks(l, n):\n",
    "        \n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjWMxaUZE6ll"
   },
   "source": [
    "### Functions for reading images and labels from TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "QMtjiV7TEriI"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames, sat_var, exp_det, train):\n",
    "    # read from TFRecords. For optimal performance, read from multiple\n",
    "    # TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    #### Define read_tfrcord\n",
    "    # Define here. Later map over this function, and not sure how to\n",
    "    # enter sat_var into the mapping\n",
    "    def read_tfrecord(example, sat_var = sat_var):\n",
    "        features = {'viirs_ntl_group': tf.io.FixedLenFeature([], tf.int64),\n",
    "                    sat_var: tf.io.FixedLenFeature([], tf.string)}\n",
    "        parsed_features = tf.io.parse_single_example(example, features)\n",
    "\n",
    "        image = tf.io.decode_png(parsed_features[sat_var], dtype=tf.dtypes.uint16)\n",
    "        image = image / 10000 # within 0 and 1\n",
    "\n",
    "        if sat_var != 'b_rgb':\n",
    "            image = tf.repeat(image, repeats = 3, axis=2)\n",
    "\n",
    "        # If training sample, augment the data\n",
    "        if train:\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_flip_up_down(image)\n",
    "            image = tf.image.random_brightness(image, 0.025)\n",
    "\n",
    "            if sat_var == 'b_rgb':\n",
    "                image = tf.image.random_contrast(image, 0.5, 1.5)\n",
    "\n",
    "        label = tf.one_hot(parsed_features[\"viirs_ntl_group\"], NUM_GROUPS)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    #### load_dataset function\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = exp_det\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "5XqDCjwuE_zt"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord_uid(example):\n",
    "    features = {'uid': tf.io.FixedLenFeature([], tf.string)}\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(example, features)\n",
    "\n",
    "    return parsed_features['uid']\n",
    "\n",
    "def load_dataset_uid(filenames, exp_det):\n",
    "    # read from TFRecords. For optimal performance, read from multiple\n",
    "    # TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = exp_det\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.map(read_tfrecord_uid, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "nPym-f4fE_31"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord_ntl_group(example):\n",
    "    features = {'viirs_ntl_group': tf.io.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.io.parse_single_example(example, features)\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"viirs_ntl_group\"], NUM_GROUPS)\n",
    "\n",
    "    return label\n",
    "\n",
    "def load_dataset_ntl_group(filenames, exp_det):\n",
    "    # read from TFRecords. For optimal performance, read from multiple\n",
    "    # TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = exp_det\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.map(read_tfrecord_ntl_group, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8RQkl4MFsLk"
   },
   "source": [
    "### Functions to create batched datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "wspCMcDKFrjd"
   },
   "outputs": [],
   "source": [
    "def get_batched_dataset(filenames, sat_var, exp_det, train=False):\n",
    "    dataset = load_dataset(filenames, sat_var, exp_det = exp_det, train = train)\n",
    "    dataset = dataset.cache() # This dataset fits in RAM\n",
    "    if train:\n",
    "        # Best practices for Keras:\n",
    "        # Training dataset: repeat then batch\n",
    "        # Evaluation dataset: do not repeat\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    # should shuffle too but this dataset was well shuffled on disk already\n",
    "    return dataset\n",
    "    # source: Dataset performance guide: https://www.tensorflow.org/guide/performance/datasets\n",
    "\n",
    "def get_batched_dataset_uid(filenames, exp_det, train=False):\n",
    "    dataset = load_dataset_uid(filenames, exp_det = exp_det)\n",
    "    dataset = dataset.cache() # This dataset fits in RAM\n",
    "    if train:\n",
    "        # Best practices for Keras:\n",
    "        # Training dataset: repeat then batch\n",
    "        # Evaluation dataset: do not repeat\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    # should shuffle too but this dataset was well shuffled on disk already\n",
    "    return dataset\n",
    "    # source: Dataset performance guide: https://www.tensorflow.org/guide/performance/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nmao2iZFMo6"
   },
   "source": [
    "## Load TFRecords and divide into train/test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaTeXk4rFRiM",
    "outputId": "6a0e34b9-f42d-4779-da1c-81fa0085bd02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_PATH = os.path.join(cf.DROPBOX_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData', 'Individual Datasets',\n",
    "                       'cnn_' + OUT_NAME_SUFFIX, 'tfrecords')\n",
    "GCS_PATTERN = os.path.join(TF_PATH, '*.tfrecord')\n",
    "\n",
    "#GCS_PATTERN = 'gs://ieconnectpovest/cnn_' + OUT_NAME_SUFFIX + '/tfrecords/*.tfrecord'\n",
    "all_filenames = tf.io.gfile.glob(GCS_PATTERN)\n",
    "len(all_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_test_NG_5_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_3_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_test_NG_2_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_4_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_5_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_test_NG_3_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_2_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_test_NG_4_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_test_NG_1_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_1_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_train_NG_2_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_1_3_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_train_NG_5_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_train_NG_4_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_1_2_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_train_NG_3_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_5_3_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/forcnn_train_NG_1_1_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_3_2_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_4_2_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_2_3_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_3_3_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_5_2_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_2_2_all.tfrecord',\n",
       " '/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/DHS_nga_policy_experiment/FinalData/Individual Datasets/cnn_landsat_ntlharmon_underiaTrue/tfrecords/nocnn_NG_4_3_all.tfrecord']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "WK1cNuLWFRkW"
   },
   "outputs": [],
   "source": [
    "#forcnn_filenames = [x for x in all_filenames if 'forcnn_' in x]\n",
    "#split = int(len(forcnn_filenames) * VALIDATION_SPLIT)\n",
    "#training_filenames = forcnn_filenames[split:]\n",
    "#validation_filenames = forcnn_filenames[:split]\n",
    "\n",
    "# forcnn_filenames = [x for x in all_filenames if 'forcnn_' in x] # TODO: Not sure need?\n",
    "\n",
    "training_filenames = [x for x in all_filenames if 'forcnn_train_' in x]\n",
    "validation_filenames = [x for x in all_filenames if 'forcnn_test_' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVv4_7GhFRmm",
    "outputId": "281c9975-6df3-4ef9-faaf-e5c059a5915f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "435\n"
     ]
    }
   ],
   "source": [
    "#TOTAL_OBS = len(extract_uid(all_filenames))\n",
    "#print(TOTAL_OBS)\n",
    "\n",
    "TOTAL_OBS_VALIDATION = len(extract_uid(validation_filenames))\n",
    "print(TOTAL_OBS_VALIDATION)\n",
    "\n",
    "TOTAL_OBS_TRAINING = len(extract_uid(training_filenames))\n",
    "print(TOTAL_OBS_TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "k9kEz9YRFiAO"
   },
   "outputs": [],
   "source": [
    "validation_steps = TOTAL_OBS_VALIDATION // BATCH_SIZE\n",
    "steps_per_epoch  = TOTAL_OBS_TRAINING   // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYgQff2pF8pX"
   },
   "source": [
    "## Example Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fsbsj6FdF44c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_rgb\n",
      "0\n",
      "b_ndvi\n",
      "0\n",
      "b_bu\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for sat_var in ['b_rgb', 'b_ndvi', 'b_bu']: # 'b_rgb', 'b_ndvi', 'b_bu'\n",
    "    \n",
    "    print(sat_var)\n",
    "    \n",
    "    # File names -----------------------------------------------------------------\n",
    "    # Paths for saving model, predictions (on test) and featurs (on training)\n",
    "    name_suffix = OUT_NAME_SUFFIX + \"_\" + sat_var\n",
    "\n",
    "    CNN_MODEL_PATH = os.path.join(cf.DROPBOX_DIRECTORY, 'Data', 'DHS', 'FinalData', \"Individual Datasets\",\n",
    "                                    'cnn_models', \n",
    "                                    'model_' + name_suffix + '.h5')\n",
    "\n",
    "    FEATURES_PATH = os.path.join(cf.DROPBOX_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData', \"Individual Datasets\",\n",
    "                                    'cnn_features', \"split_into_data_subsets\",\n",
    "                                    'features_' + name_suffix)\n",
    "    \n",
    "    ## Load model ------------------------------------------------------------------\n",
    "    model = load_model(CNN_MODEL_PATH)\n",
    "\n",
    "    ## Load data -------------------------------------------------------------------\n",
    "    all_dataset_exdtT = get_batched_dataset(all_filenames, sat_var, exp_det = True, train=False)\n",
    "\n",
    "    ## Grab features ---------------------------------------------------------------\n",
    "    feature_extractor = Model(inputs=model.inputs,\n",
    "                    outputs=model.get_layer(name='fc1').output,)\n",
    "\n",
    "    def extract_features(all_dataset_i_exdtT, all_filenames_i, i, FEATURES_PATH):\n",
    "        print(i)\n",
    "\n",
    "        features_i = feature_extractor.predict(all_dataset_i_exdtT)\n",
    "        features_i_df = pd.DataFrame(features_i).add_prefix('cnn_feat_')\n",
    "        features_i_df['uid'] = dataset_to_numpy_util_single_val(load_dataset_uid(all_filenames_i, exp_det = True),features_i_df.shape[0])\n",
    "        features_i_df.to_csv(FEATURES_PATH + '_' + str(i) + '.csv', index=False)\n",
    "\n",
    "\n",
    "    extract_features(all_dataset_exdtT, all_filenames, 0, FEATURES_PATH)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgzW_FeNkOBg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijdyyze7LLwC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "02_cnn_CLEAN_LOOP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
