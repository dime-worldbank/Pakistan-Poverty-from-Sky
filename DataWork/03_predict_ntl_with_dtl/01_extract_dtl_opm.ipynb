{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "particular-harbor",
   "metadata": {},
   "source": [
    "# Prepare Data for CNN\n",
    "\n",
    "Prepares data for CNN. \n",
    "1. Outputs numpy arrays of DTL values and NTL labels\n",
    "2. Creates parameter dictionary (eg, number of NTL labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-boxing",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tight-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a while\n",
    "%conda install geopandas\n",
    "%conda install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secondary-winter",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dc97df40947f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "### Libraries ###\n",
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import logging, os \n",
    "\n",
    "### User Defined Libraries ###\n",
    "import config as cf\n",
    "import feature_extraction as fe\n",
    "\n",
    "### Set Seeds ###\n",
    "seed_value = 42\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "### Parameters / Paths ###\n",
    "FINAL_TARGET_NAME = 'ntl_bins'\n",
    "#VIIRS_GDF_FILEPATH = cf.VIIRS_GDF_FILEPATH\n",
    "#DTL_DIRECTORY = cf.DTL_DIRECTORY\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from s3fs.core import S3FileSystem \n",
    "s3 = S3FileSystem()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = 'worldbank-pakistan-data'\n",
    "LOCAL_DIR = '/home/ec2-user/SageMaker/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-characterization",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_target(gdf, orig_target_name, n_bins):\n",
    "    '''\n",
    "    Creates log NTL variable and bins into 5 classes using k-means clutering.\n",
    "    '''\n",
    "    # Perform log(x+1) for defined domain\n",
    "    transformed_target_name = f'log_{orig_target_name}'\n",
    "    gdf[transformed_target_name] = np.log(gdf[orig_target_name] + 1)\n",
    "    # Bin target\n",
    "    target = gdf[transformed_target_name].to_numpy().reshape(-1,1)\n",
    "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='kmeans')\n",
    "    gdf[FINAL_TARGET_NAME] = discretizer.fit_transform(target)\n",
    "\n",
    "def sample_by_target(input_gdf, target_col_name, n):\n",
    "    '''\n",
    "    Create a sample dataframe containing n observations from each target bin.\n",
    "    '''\n",
    "\n",
    "    gdf = gpd.GeoDataFrame()\n",
    "    for x in input_gdf[target_col_name].unique():\n",
    "        bin_gdf = input_gdf[input_gdf[target_col_name] == x]\n",
    "        sample_gdf = bin_gdf.sample(n=n, random_state=1)\n",
    "        gdf = gdf.append(sample_gdf)\n",
    "    return gdf\n",
    "\n",
    "def normalize(X):\n",
    "    '''\n",
    "    Normalizes features.\n",
    "    '''\n",
    "    return X.astype('float32') / 255.0\n",
    "\n",
    "def prep_cnn_data(bands, n_ntl_bins, min_ntl_bin_count, year):\n",
    "\n",
    "    # PARAMETERS -------------------------------------------------------------\n",
    "\n",
    "    ## Define Parameters\n",
    "    # Daytime image parameters\n",
    "    image_height = 48 # VGG16 needs images to be rescale to 224x224\n",
    "    image_width = 48\n",
    "    N_bands = len(bands)\n",
    "\n",
    "    ## Save parameters for later use\n",
    "    cnn_param_dict = {'image_height': image_height, \n",
    "                    'image_width': image_width,\n",
    "                    'bands': bands,\n",
    "                    'N_bands': N_bands,\n",
    "                    'n_ntl_bins': n_ntl_bins,\n",
    "                    'min_ntl_bin_count': min_ntl_bin_count}\n",
    "\n",
    "    # Make directory for these parameters\n",
    "    params_str = 'Nbands' + str(N_bands) + \"_nNtlBins\" + str(n_ntl_bins) + \"_minNTLbinCount\" + str(min_ntl_bin_count)\n",
    "\n",
    "    # Save Locally\n",
    "    with open(os.path.join(LOCAL_DIR, 'CNN_parameters.json'), 'w') as fp:\n",
    "        json.dump(cnn_param_dict, fp)\n",
    "        \n",
    "    # Send to s3\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('CNN', params_str, 'CNN_parameters.json')).upload_file(os.path.join(LOCAL_DIR, 'CNN_parameters.json'))\n",
    "\n",
    "    # Run --------------------------------------------------------------------\n",
    "\n",
    "    ## LOAD DATA\n",
    "    viirs = pd.read_pickle(s3.open('{}/{}'.format(bucket, os.path.join('VIIRS', 'FinalData', 'viirs_annual_polygon.pkl'))))\n",
    "    viirs_gdf = gpd.GeoDataFrame(viirs, geometry='geometry')\n",
    "    viirs_gdf = viirs_gdf[ ~ np.isnan(viirs_gdf['tile_id'])]\n",
    "\n",
    "    ## PREP NTL\n",
    "    transform_target(viirs_gdf, 'median_rad_' + str(year), n_ntl_bins)\n",
    "\n",
    "    ## Total pixels in each category\n",
    "    print(viirs_gdf[FINAL_TARGET_NAME].value_counts())\n",
    "\n",
    "    ## Create Sample\n",
    "    # Subsets VIIRS dataframe\n",
    "    min_bin_count = min(viirs_gdf[FINAL_TARGET_NAME].value_counts())\n",
    "    gdf = sample_by_target(viirs_gdf, FINAL_TARGET_NAME, min_ntl_bin_count)\n",
    "\n",
    "    ## Path to DTL Files\n",
    "    DTL_DIRECTORY_DATA = os.path.join('Landsat','l8', str(year))\n",
    "    \n",
    "    ## Match DTL TO NTL\n",
    "    DTL, processed_gdf = fe.map_DTL_NTL(gdf, DTL_DIRECTORY_DATA, bands, image_height, image_width, year)\n",
    "    NTL = processed_gdf[FINAL_TARGET_NAME].to_numpy()\n",
    "    NTL_continuous = processed_gdf['median_rad_'+ str(year)].to_numpy()\n",
    "    \n",
    "    ## Save Locally\n",
    "    print(\"Saving\")\n",
    "    np.save(os.path.join(LOCAL_DIR, f'ntl_{str(year)}.npy'), NTL)\n",
    "    np.save(os.path.join(LOCAL_DIR, f'ntl_continuous_{str(year)}.npy'), NTL_continuous)\n",
    "    np.save(os.path.join(LOCAL_DIR, f'dtl_{str(year)}.npy'), DTL)\n",
    "    \n",
    "    ## Send to s3\n",
    "    print(\"Sending to s3\")\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('CNN', params_str, f'ntl_{str(year)}.npy')).upload_file(os.path.join(LOCAL_DIR, f'ntl_{str(year)}.npy'))\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('CNN', params_str, f'ntl_continuous_{str(year)}.npy')).upload_file(os.path.join(LOCAL_DIR, f'ntl_continuous_{str(year)}.npy'))\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('CNN', params_str, f'dtl_{str(year)}.npy')).upload_file(os.path.join(LOCAL_DIR, f'dtl_{str(year)}.npy'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-gather",
   "metadata": {},
   "source": [
    "## Extract Daytime Imagery to OPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_cnn_data(bands = ['4', '3', '2'], n_ntl_bins = 3, min_ntl_bin_count = 15, year = 2014)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
