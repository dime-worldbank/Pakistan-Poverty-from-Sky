{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z34KtcX5Pp7o"
   },
   "source": [
    "# __Predicting NTL using DTL__\n",
    "\n",
    "Runs CNN to predict nighttime lights using daytime images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybUBTyiNDore"
   },
   "source": [
    "# __Parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOdgNXFG8EmH"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "# Test2\n",
    "#PARAM_NAME = \"Nbands3_nNtlBins3_minNTLbinCount16861\"\n",
    "PARAM_NAME = \"Nbands3_nNtlBins3_minNTLbinCount100\"\n",
    "YEAR = 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vds1yHMwLJp2"
   },
   "source": [
    "## **Filepaths and Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "206o8Vv6OjtI"
   },
   "outputs": [],
   "source": [
    "# Set seeds. Note that using a GPU can still introduce randomness.\n",
    "# (also not taking into account tensorflow randomness)\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urMUqpA_1_fM",
    "outputId": "cb3b4f3e-a875-4612-c9b3-ce9b7d5262c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjmhWLqU95-J"
   },
   "outputs": [],
   "source": [
    "#drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbrNDZWq2UdD"
   },
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "import os, datetime\n",
    "\n",
    "CNN_DIR = os.path.join('/content/drive', 'My Drive', 'World Bank', 'IEs', 'Pakistan Poverty Estimation', 'Data', 'CNN', PARAM_NAME)\n",
    "\n",
    "CNN_FILENAME = os.path.join(CNN_DIR, f'script_CNN_{str(YEAR)}.h5')\n",
    "CNN_CONT_FILENAME = os.path.join(CNN_DIR, f'script_CNN_cont_{str(YEAR)}.h5') # continuous\n",
    "\n",
    "CNN_PARAMS_FILENAME = os.path.join(CNN_DIR, 'CNN_parameters.json')\n",
    "NTL_FILENAME = os.path.join(CNN_DIR, f'ntl_{str(YEAR)}.npy')\n",
    "NTL_CONT_FILENAME = os.path.join(CNN_DIR, f'ntl_continuous_{str(YEAR)}.npy')\n",
    "DTL_FILENAME = os.path.join(CNN_DIR, f'dtl_{str(YEAR)}.npy')\n",
    "PREDICTION_FILENAME = os.path.join(CNN_DIR, f'cnn_predictions_truth_values_{str(YEAR)}.csv')\n",
    "PREDICTION_FILENAME_CONT = os.path.join(CNN_DIR, f'cnn_predictions_continuous_truth_values_{str(YEAR)}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWeveSe00gul"
   },
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "import logging, os \n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5k-bEJvLVvj"
   },
   "source": [
    "## **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkAYWJCg0gut"
   },
   "outputs": [],
   "source": [
    "def transform_target(gdf, orig_target_name, n_bins):\n",
    "    '''\n",
    "    Creates log NTL variable and bins into 5 classes using k-means clutering.\n",
    "    '''\n",
    "    # Perform log(x+1) for defined domain\n",
    "    transformed_target_name = f'log_{orig_target_name}'\n",
    "    gdf[transformed_target_name] = np.log(gdf[orig_target_name] + 1)\n",
    "    # Bin target\n",
    "    target = gdf[transformed_target_name].to_numpy().reshape(-1,1)\n",
    "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='kmeans')\n",
    "    gdf[FINAL_TARGET_NAME] = discretizer.fit_transform(target)\n",
    "\n",
    "def normalize(X):\n",
    "    '''\n",
    "    Normalizes features.\n",
    "    '''\n",
    "    return X.astype('float32') / 255.0\n",
    "\n",
    "def define_model_imagenet(height, width, channels, num_classes):\n",
    "    '''\n",
    "    Defines and compiles CNN model.\n",
    "    \n",
    "    Inputs:\n",
    "        height, width, channels, num_classes (int)\n",
    "    Returns:\n",
    "        model (keras.Model object)\n",
    "    '''\n",
    "\n",
    "    # https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5\n",
    "    # https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2\n",
    "\n",
    "    #### Base model\n",
    "    input_shape = (height, width, channels)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #### Model Customization\n",
    "    # We take the last layer of our the model and add it to our classifier\n",
    "    last = base_model.layers[-1].output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(100, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    # We compile the model\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def define_model_imagenet_cont(height, width, channels, num_classes):\n",
    "    '''\n",
    "    Defines and compiles CNN model [continuous].\n",
    "    \n",
    "    Inputs:\n",
    "        height, width, channels, num_classes (int)\n",
    "    Returns:\n",
    "        model (keras.Model object)\n",
    "    '''\n",
    "\n",
    "    # https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5\n",
    "    # https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2\n",
    "\n",
    "    #### Base model\n",
    "    input_shape = (height, width, channels)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #### Model Customization\n",
    "    # We take the last layer of our the model and add it to our classifier\n",
    "    last = base_model.layers[-1].output\n",
    "    x = Flatten()(last)\n",
    "    x = Dense(100, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    #x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    x = Dense(1, kernel_initializer='normal')(x)\n",
    "\n",
    "    model = Model(base_model.input, x)\n",
    "    # We compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, trainX, trainY, testX, testY, CNN_FILENAME):\n",
    "    '''\n",
    "    Fits model, evaluates model, saves best model over epochs and cross-validations.\n",
    "    \n",
    "    Inputs:\n",
    "        model (CNN model) keras.Model object\n",
    "        trainX, trainY (numpy.ndarray) 4D array of DTL features and 2D array of targets for training\n",
    "        testX, testY (numpy.ndarray) 4D array of DTL features and 2D array of targets for testing\n",
    "        current_kfold (int) iteration in kfold cross-val, default=None for no cross-val\n",
    "        display_metrics (bool) Default=False\n",
    "    Returns:\n",
    "        None\n",
    "    # https://towardsdatascience.com/step-by-step-guide-to-using-pretrained-models-in-keras-c9097b647b29\n",
    "    '''\n",
    "\n",
    "    # Use early stopping to help with overfitting\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=False)\n",
    "\n",
    "    # Save best model based on accuracy\n",
    "    mc = ModelCheckpoint(CNN_FILENAME, monitor='val_loss', mode='min', \n",
    "                         verbose=True, save_best_only=True)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(trainX, trainY, \n",
    "            epochs=100, \n",
    "            batch_size=500, \n",
    "            validation_data=(testX, testY), \n",
    "            callbacks=[es, mc], \n",
    "            verbose=False)\n",
    "\n",
    "    # Show accuracy\n",
    "    loss, accuracy = model.evaluate(testX, testY, verbose=False)\n",
    "    print(f'                              Accuracy: {accuracy}')\n",
    "\n",
    "    #return model\n",
    "        \n",
    "\n",
    "def evaluate_with_crossval(model, dataX, dataY, k=2):\n",
    "    '''\n",
    "    Performs evaulation with K-fold cross validation.\n",
    "    \n",
    "    Inputs:\n",
    "        model (keras.Model object)\n",
    "        dataX, dataY (numpy.ndarray) 4D array of DTL features and 2D array of targets \n",
    "                                     for training\n",
    "        k (int)\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # Define k-fold cross-val\n",
    "    kfold = KFold(k, shuffle=True, random_state=1)\n",
    "    # Loop through folds\n",
    "    count = 1\n",
    "    for train_idx, test_idx in kfold.split(dataX):\n",
    "        print(f'{datetime.datetime.now()}    --- Current K-fold: {count} ---')\n",
    "        # Select subsets for training and testing\n",
    "        trainX, trainY, testX, testY = dataX[train_idx], dataY[train_idx], \\\n",
    "                                       dataX[test_idx], dataY[test_idx]\n",
    "        # Pass to evaluate_model function\n",
    "        evaluate_model(model, trainX, trainY, testX, testY)\n",
    "        count += 1\n",
    "\n",
    "def display_eval_metrics(model, testX, testY, n_ntl_bins):\n",
    "    '''\n",
    "    Displays evaluation metrics for a given trained model.\n",
    "    '''\n",
    "    # Get predictions\n",
    "    predY = model.predict(testX)\n",
    "    predY = np.argmax(predY, axis = 1)\n",
    "    testY_bins = np.argmax(testY, axis = 1)\n",
    "    # Generate classification report\n",
    "    classes = ['Radiance Level %01d' %i for i in range(1,n_ntl_bins+1)]\n",
    "    print(classification_report(testY_bins, predY, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4lWj5moLdQW"
   },
   "source": [
    "## **Load Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7mQb5uJ6BEq"
   },
   "outputs": [],
   "source": [
    "with open(CNN_PARAMS_FILENAME, 'r') as fp:\n",
    "    cnn_param_dict = json.load(fp)\n",
    "\n",
    "N_bands = cnn_param_dict['N_bands']\n",
    "n_ntl_bins = cnn_param_dict['n_ntl_bins']\n",
    "image_height = cnn_param_dict['image_height']\n",
    "image_width = cnn_param_dict['image_width']\n",
    "bands = cnn_param_dict['bands']\n",
    "min_ntl_bin_count = cnn_param_dict['bands']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ0rFqCiLhM0"
   },
   "source": [
    "## **Load and Prep Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuCKwuARKt_E"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "NTL = np.load(NTL_FILENAME)\n",
    "DTL = np.load(DTL_FILENAME)\n",
    "\n",
    "# SPLIT DATA INTO TRAINING AND TESTING\n",
    "trainX, testX, raw_trainY, raw_testY = train_test_split(DTL, NTL, \n",
    "                                                        test_size=0.2)\n",
    "\n",
    "\n",
    "# PREP TRAINING AND TESTING DATA\n",
    "trainY = to_categorical(raw_trainY)\n",
    "testY = to_categorical(raw_testY)\n",
    "\n",
    "\n",
    "#print(np.unique(NTL, return_counts=True))\n",
    "\n",
    "#print(np.unique(raw_trainY, return_counts=True))\n",
    "#print(np.unique(raw_testY, return_counts=True))\n",
    "\n",
    "#print(np.unique(trainY, return_counts=True))\n",
    "#print(np.unique(testY, return_counts=True))\n",
    "\n",
    "# PREP PIXELS IN FEATURES\n",
    "trainX, testX = normalize(trainX), normalize(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xh8-K6jYtyvG"
   },
   "outputs": [],
   "source": [
    "# Prep Continuous X and Ys\n",
    "NTL = np.load(NTL_CONT_FILENAME)\n",
    "\n",
    "NTL_LOG = np.log(NTL + 1)\n",
    "\n",
    "trainX_cont, testX_cont, raw_trainY_cont, raw_testY_cont = train_test_split(DTL, NTL_LOG, \n",
    "                                                                            test_size=0.2)\n",
    "\n",
    "trainX_cont, testX_cont = normalize(trainX_cont), normalize(testX_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hr7NIkb6vWJu",
    "outputId": "63425cca-6044-4348-eee5-aac55ff5da7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model_cont = define_model_imagenet_cont(image_height, image_width, N_bands, n_ntl_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfwxDuUEvmgm",
    "outputId": "f3c44f26-0802-4e37-953c-df0751cfe477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61814, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61814 to 1.24220, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.24220 to 1.02511, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02511 to 0.94041, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.94041\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.94041 to 0.89676, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.89676 to 0.82917, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.82917 to 0.77192, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.77192 to 0.72897, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.72897 to 0.69778, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.69778 to 0.67579, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.67579 to 0.66061, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.66061 to 0.65039, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.65039 to 0.64279, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.64279 to 0.63709, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.63709 to 0.63321, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.63321 to 0.63211, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.63211\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.63211\n",
      "                              Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_cont, trainX_cont, raw_trainY_cont, testX_cont, raw_testY_cont, CNN_CONT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hg_Pgo6zwPB-"
   },
   "outputs": [],
   "source": [
    "best_model = load_model(CNN_CONT_FILENAME)\n",
    "\n",
    "### Save Dataframe of Predicted Values\n",
    "\n",
    "# Predict Values\n",
    "predY = best_model.predict(testX_cont)\n",
    "#predY = np.argmax(predY, axis = 1)\n",
    "#testY_bins = np.argmax(testY, axis = 1)\n",
    "\n",
    "# Make Dataframe\n",
    "results_df = pd.DataFrame({'predY': predY[:,0], 'testY': raw_testY_cont})\n",
    "\n",
    "# Save Dataframe\n",
    "results_df.to_csv(PREDICTION_FILENAME_CONT, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "G6kJKGSDxTHf",
    "outputId": "f89a6a1f-109c-4336-8b9f-2f77a8d6f883"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predY</th>\n",
       "      <th>testY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.919813</td>\n",
       "      <td>1.482614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.872260</td>\n",
       "      <td>0.546836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.130655</td>\n",
       "      <td>0.386482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.805316</td>\n",
       "      <td>0.117846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.092091</td>\n",
       "      <td>0.454955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predY     testY\n",
       "0  0.919813  1.482614\n",
       "1  0.872260  0.546836\n",
       "2  1.130655  0.386482\n",
       "3  0.805316  0.117846\n",
       "4  1.092091  0.454955"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results_df.head()\n",
    "#raw_testY_cont\n",
    "#predY\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKlWDX3gLkde"
   },
   "source": [
    "## **Run Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icaSC1870guy"
   },
   "outputs": [],
   "source": [
    "model = define_model_imagenet(image_height, image_width, N_bands, n_ntl_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTt_30BEMrss",
    "outputId": "71355b8c-4ec6-43c9-9850-d5b01086ddbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.23411, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.23411 to 1.12425, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.12425 to 1.06902, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.06902 to 1.04433, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.04433 to 1.03642, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.03642 to 1.01644, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01644 to 0.99934, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.99934 to 0.99246, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.99246 to 0.98840, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.98840 to 0.98603, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.98603 to 0.97117, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.97117\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.97117\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.97117 to 0.96999, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.96999 to 0.96352, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.96352 to 0.95990, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.95990 to 0.95157, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.95157\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.95157\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.95157\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.95157\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.95157\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.95157\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.95157 to 0.94671, saving model to /content/drive/My Drive/World Bank/IEs/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount100/script_CNN_2014.h5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.94671\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.94671\n",
      "                              Accuracy: 0.5833333134651184\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, trainX, trainY, testX, testY, CNN_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0akMTs7NK4iJ",
    "outputId": "d5c373b4-e22c-4191-c7c1-e1ec29593311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Radiance Level 1       0.65      0.59      0.62        22\n",
      "Radiance Level 2       0.43      0.38      0.40        16\n",
      "Radiance Level 3       0.62      0.73      0.67        22\n",
      "\n",
      "        accuracy                           0.58        60\n",
      "       macro avg       0.56      0.56      0.56        60\n",
      "    weighted avg       0.58      0.58      0.58        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY IN-DEPTH EVALUTAION METRICS\n",
    "best_model = load_model(CNN_FILENAME)\n",
    "display_eval_metrics(model, testX, testY, n_ntl_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VYvJlW58z-M"
   },
   "outputs": [],
   "source": [
    "### Save Dataframe of Predicted Values\n",
    "\n",
    "# Predict Values\n",
    "predY = best_model.predict(testX) # model.predict(testX)\n",
    "predY = np.argmax(predY, axis = 1)\n",
    "testY_bins = np.argmax(testY, axis = 1)\n",
    "\n",
    "# Make Dataframe\n",
    "results_df = pd.DataFrame({'predY': predY, 'testY': testY_bins})\n",
    "\n",
    "# Save Dataframe\n",
    "results_df.to_csv(PREDICTION_FILENAME, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_smbAxFWvWrP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUJ79Dvkvb-3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIaYzmPcvjTS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABUz9Hk8wPmd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "01_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
