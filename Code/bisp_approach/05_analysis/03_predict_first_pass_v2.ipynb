{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict household income from satellite imagery data\n",
    "\n",
    "First pass.\n",
    "\n",
    "General ML pipeline steps:\n",
    "1. Import data\n",
    "2. Split data into test/train sets\n",
    "3. Preprocess test/train sets separately\n",
    "4. Generate features from data\n",
    "5. For each regressor-hyperparameter combination:\n",
    "    - Train regressor with given hyperparameters and training data and labels\n",
    "    - Generate predicted labels for test data with trained regressor\n",
    "    - Evaluate regressor-hyperparameter performance against actual test labels and get $R^2$\n",
    "6. Explore best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Import configuration file\n",
    "import config as cf\n",
    "\n",
    "# Display options \n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = -1\n",
    "\n",
    "# Turn off big pink warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data and drop \"future\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33794, 59)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA_PATH = os.path.join('..', '..', '..', 'Data', 'FinalData', 'BISP', 'bisp_satellite_data_combined_buffer_1km.csv')\n",
    "DATA_PATH = os.path.join('/Users/robmarty/Dropbox/World Bank/IEs/', 'Pakistan Poverty Estimation from Satellites', 'Data', 'FinalData', 'BISP', 'bisp_satellite_data_combined_buffer_1km.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Remove Select Variables\n",
    "df = df[df.columns.drop(list(df.filter(regex='2011')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='2012')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='2013')))]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>period</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>hh_inc</th>\n",
       "      <th>hh_inc_lastmonth</th>\n",
       "      <th>viirs_2014</th>\n",
       "      <th>viirs_2015</th>\n",
       "      <th>viirs_2016</th>\n",
       "      <th>viirs_2017</th>\n",
       "      <th>viirs_2018</th>\n",
       "      <th>dmspols_1992</th>\n",
       "      <th>dmspols_1993</th>\n",
       "      <th>dmspols_1994</th>\n",
       "      <th>dmspols_1995</th>\n",
       "      <th>dmspols_1996</th>\n",
       "      <th>dmspols_1997</th>\n",
       "      <th>dmspols_1998</th>\n",
       "      <th>dmspols_1999</th>\n",
       "      <th>dmspols_2000</th>\n",
       "      <th>dmspols_2001</th>\n",
       "      <th>dmspols_2002</th>\n",
       "      <th>dmspols_2003</th>\n",
       "      <th>dmspols_2004</th>\n",
       "      <th>dmspols_2005</th>\n",
       "      <th>dmspols_2006</th>\n",
       "      <th>dmspols_2007</th>\n",
       "      <th>dmspols_2008</th>\n",
       "      <th>dmspols_2009</th>\n",
       "      <th>dmspols_2010</th>\n",
       "      <th>viirs</th>\n",
       "      <th>dmspols</th>\n",
       "      <th>l7_1</th>\n",
       "      <th>l7_2</th>\n",
       "      <th>l7_3</th>\n",
       "      <th>l7_4</th>\n",
       "      <th>l7_5</th>\n",
       "      <th>l7_6</th>\n",
       "      <th>l7_7</th>\n",
       "      <th>l7_12</th>\n",
       "      <th>l7_13</th>\n",
       "      <th>l7_14</th>\n",
       "      <th>l7_15</th>\n",
       "      <th>l7_16</th>\n",
       "      <th>l7_17</th>\n",
       "      <th>l7_23</th>\n",
       "      <th>l7_24</th>\n",
       "      <th>l7_25</th>\n",
       "      <th>l7_26</th>\n",
       "      <th>l7_27</th>\n",
       "      <th>l7_34</th>\n",
       "      <th>l7_35</th>\n",
       "      <th>l7_36</th>\n",
       "      <th>l7_37</th>\n",
       "      <th>l7_45</th>\n",
       "      <th>l7_46</th>\n",
       "      <th>l7_47</th>\n",
       "      <th>l7_56</th>\n",
       "      <th>l7_57</th>\n",
       "      <th>l7_67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100389</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2.089507</td>\n",
       "      <td>2.307763</td>\n",
       "      <td>2.850603</td>\n",
       "      <td>3.653005</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.141392</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>951.897734</td>\n",
       "      <td>1282.748257</td>\n",
       "      <td>1417.251598</td>\n",
       "      <td>2574.000436</td>\n",
       "      <td>2469.137711</td>\n",
       "      <td>3000.408919</td>\n",
       "      <td>1889.609384</td>\n",
       "      <td>-0.148055</td>\n",
       "      <td>-0.196422</td>\n",
       "      <td>-0.460054</td>\n",
       "      <td>-0.443503</td>\n",
       "      <td>-0.518308</td>\n",
       "      <td>-0.330005</td>\n",
       "      <td>-0.049816</td>\n",
       "      <td>-0.334803</td>\n",
       "      <td>-0.316211</td>\n",
       "      <td>-0.401027</td>\n",
       "      <td>-0.191297</td>\n",
       "      <td>-0.289821</td>\n",
       "      <td>-0.270659</td>\n",
       "      <td>-0.358370</td>\n",
       "      <td>-0.142842</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>-0.076494</td>\n",
       "      <td>0.153327</td>\n",
       "      <td>-0.097133</td>\n",
       "      <td>0.132958</td>\n",
       "      <td>0.227157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100401</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>159000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>2.052437</td>\n",
       "      <td>2.296554</td>\n",
       "      <td>2.769960</td>\n",
       "      <td>3.702374</td>\n",
       "      <td>3.488333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.133366</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>941.063694</td>\n",
       "      <td>1268.392009</td>\n",
       "      <td>1402.777070</td>\n",
       "      <td>2547.212362</td>\n",
       "      <td>2463.117111</td>\n",
       "      <td>2998.701940</td>\n",
       "      <td>1876.871453</td>\n",
       "      <td>-0.148149</td>\n",
       "      <td>-0.196990</td>\n",
       "      <td>-0.460442</td>\n",
       "      <td>-0.447113</td>\n",
       "      <td>-0.522274</td>\n",
       "      <td>-0.332090</td>\n",
       "      <td>-0.050309</td>\n",
       "      <td>-0.335155</td>\n",
       "      <td>-0.320172</td>\n",
       "      <td>-0.405501</td>\n",
       "      <td>-0.193459</td>\n",
       "      <td>-0.289731</td>\n",
       "      <td>-0.274281</td>\n",
       "      <td>-0.362588</td>\n",
       "      <td>-0.144556</td>\n",
       "      <td>0.016784</td>\n",
       "      <td>-0.081409</td>\n",
       "      <td>0.151521</td>\n",
       "      <td>-0.098060</td>\n",
       "      <td>0.135080</td>\n",
       "      <td>0.230092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>101101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>219000.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>2.052437</td>\n",
       "      <td>2.296554</td>\n",
       "      <td>2.769960</td>\n",
       "      <td>3.702374</td>\n",
       "      <td>3.488333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.133366</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>940.979913</td>\n",
       "      <td>1268.248763</td>\n",
       "      <td>1401.871616</td>\n",
       "      <td>2547.740466</td>\n",
       "      <td>2459.946143</td>\n",
       "      <td>2998.786463</td>\n",
       "      <td>1874.074672</td>\n",
       "      <td>-0.148137</td>\n",
       "      <td>-0.196723</td>\n",
       "      <td>-0.460559</td>\n",
       "      <td>-0.446633</td>\n",
       "      <td>-0.522317</td>\n",
       "      <td>-0.331466</td>\n",
       "      <td>-0.050044</td>\n",
       "      <td>-0.335298</td>\n",
       "      <td>-0.319645</td>\n",
       "      <td>-0.405560</td>\n",
       "      <td>-0.192796</td>\n",
       "      <td>-0.290122</td>\n",
       "      <td>-0.273984</td>\n",
       "      <td>-0.362881</td>\n",
       "      <td>-0.144142</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>-0.081320</td>\n",
       "      <td>0.152351</td>\n",
       "      <td>-0.098712</td>\n",
       "      <td>0.135180</td>\n",
       "      <td>0.230811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>102103</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>2.052437</td>\n",
       "      <td>2.296554</td>\n",
       "      <td>2.769960</td>\n",
       "      <td>3.702374</td>\n",
       "      <td>3.488333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.133366</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>940.630258</td>\n",
       "      <td>1267.752248</td>\n",
       "      <td>1400.750653</td>\n",
       "      <td>2547.949666</td>\n",
       "      <td>2457.645344</td>\n",
       "      <td>2998.886568</td>\n",
       "      <td>1871.886858</td>\n",
       "      <td>-0.148127</td>\n",
       "      <td>-0.196517</td>\n",
       "      <td>-0.460737</td>\n",
       "      <td>-0.446407</td>\n",
       "      <td>-0.522464</td>\n",
       "      <td>-0.331111</td>\n",
       "      <td>-0.049840</td>\n",
       "      <td>-0.335508</td>\n",
       "      <td>-0.319400</td>\n",
       "      <td>-0.405737</td>\n",
       "      <td>-0.192422</td>\n",
       "      <td>-0.290526</td>\n",
       "      <td>-0.273921</td>\n",
       "      <td>-0.363243</td>\n",
       "      <td>-0.143962</td>\n",
       "      <td>0.018041</td>\n",
       "      <td>-0.081296</td>\n",
       "      <td>0.152961</td>\n",
       "      <td>-0.099191</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.231380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>102237</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.968358</td>\n",
       "      <td>2.182109</td>\n",
       "      <td>2.637059</td>\n",
       "      <td>3.357345</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>34.25</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>38.25</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>37.750000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.75</td>\n",
       "      <td>33.75</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.75</td>\n",
       "      <td>42.5</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>45.5</td>\n",
       "      <td>2.023836</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>930.478318</td>\n",
       "      <td>1257.594150</td>\n",
       "      <td>1390.361758</td>\n",
       "      <td>2564.562136</td>\n",
       "      <td>2449.709546</td>\n",
       "      <td>2998.677095</td>\n",
       "      <td>1868.266880</td>\n",
       "      <td>-0.149500</td>\n",
       "      <td>-0.198154</td>\n",
       "      <td>-0.467544</td>\n",
       "      <td>-0.449452</td>\n",
       "      <td>-0.526372</td>\n",
       "      <td>-0.335075</td>\n",
       "      <td>-0.050140</td>\n",
       "      <td>-0.341945</td>\n",
       "      <td>-0.321559</td>\n",
       "      <td>-0.409063</td>\n",
       "      <td>-0.195361</td>\n",
       "      <td>-0.296896</td>\n",
       "      <td>-0.275867</td>\n",
       "      <td>-0.366439</td>\n",
       "      <td>-0.146658</td>\n",
       "      <td>0.022905</td>\n",
       "      <td>-0.078033</td>\n",
       "      <td>0.157077</td>\n",
       "      <td>-0.100758</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.232263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  period  LOCALITY    hh_inc  hh_inc_lastmonth  viirs_2014  \\\n",
       "7   100389  2013    1         73000.0   6000.0            2.089507     \n",
       "8   100401  2013    1         159000.0  13500.0           2.052437     \n",
       "20  101101  2013    1         219000.0  21000.0           2.052437     \n",
       "32  102103  2013    1         148000.0  13000.0           2.052437     \n",
       "40  102237  2013    1         4500.0    88.0              1.968358     \n",
       "\n",
       "    viirs_2015  viirs_2016  viirs_2017  viirs_2018  dmspols_1992  \\\n",
       "7   2.307763    2.850603    3.653005    3.750000    43.0           \n",
       "8   2.296554    2.769960    3.702374    3.488333    43.0           \n",
       "20  2.296554    2.769960    3.702374    3.488333    43.0           \n",
       "32  2.296554    2.769960    3.702374    3.488333    43.0           \n",
       "40  2.182109    2.637059    3.357345    3.315000    43.0           \n",
       "\n",
       "    dmspols_1993  dmspols_1994  dmspols_1995  dmspols_1996  dmspols_1997  \\\n",
       "7   33.666667     35.50         45.333333     40.0          33.166667      \n",
       "8   33.666667     35.50         45.333333     40.0          33.166667      \n",
       "20  33.666667     35.50         45.333333     40.0          33.166667      \n",
       "32  33.666667     35.50         45.333333     40.0          33.166667      \n",
       "40  32.500000     34.25         43.000000     38.0          31.750000      \n",
       "\n",
       "    dmspols_1998  dmspols_1999  dmspols_2000  dmspols_2001  dmspols_2002  \\\n",
       "7   39.50         40.333333     37.333333     39.666667     38.833333      \n",
       "8   39.50         40.333333     37.333333     39.666667     38.833333      \n",
       "20  39.50         40.333333     37.333333     39.666667     38.833333      \n",
       "32  39.50         40.333333     37.333333     39.666667     38.833333      \n",
       "40  38.25         38.750000     36.000000     38.250000     37.750000      \n",
       "\n",
       "    dmspols_2003  dmspols_2004  dmspols_2005  dmspols_2006  dmspols_2007  \\\n",
       "7   33.666667     34.00         34.50         40.666667     45.00          \n",
       "8   33.666667     34.00         34.50         40.666667     45.00          \n",
       "20  33.666667     34.00         34.50         40.666667     45.00          \n",
       "32  33.666667     34.00         34.50         40.666667     45.00          \n",
       "40  32.000000     32.75         33.75         40.000000     43.75          \n",
       "\n",
       "    dmspols_2008  dmspols_2009  dmspols_2010     viirs    dmspols        l7_1  \\\n",
       "7   43.0          30.333333     46.0          2.141392  45.333333  951.897734   \n",
       "8   43.0          30.333333     46.0          2.133366  45.333333  941.063694   \n",
       "20  43.0          30.333333     46.0          2.133366  45.333333  940.979913   \n",
       "32  43.0          30.333333     46.0          2.133366  45.333333  940.630258   \n",
       "40  42.5          30.000000     45.5          2.023836  44.500000  930.478318   \n",
       "\n",
       "           l7_2         l7_3         l7_4         l7_5         l7_6  \\\n",
       "7   1282.748257  1417.251598  2574.000436  2469.137711  3000.408919   \n",
       "8   1268.392009  1402.777070  2547.212362  2463.117111  2998.701940   \n",
       "20  1268.248763  1401.871616  2547.740466  2459.946143  2998.786463   \n",
       "32  1267.752248  1400.750653  2547.949666  2457.645344  2998.886568   \n",
       "40  1257.594150  1390.361758  2564.562136  2449.709546  2998.677095   \n",
       "\n",
       "           l7_7     l7_12     l7_13     l7_14     l7_15     l7_16     l7_17  \\\n",
       "7   1889.609384 -0.148055 -0.196422 -0.460054 -0.443503 -0.518308 -0.330005   \n",
       "8   1876.871453 -0.148149 -0.196990 -0.460442 -0.447113 -0.522274 -0.332090   \n",
       "20  1874.074672 -0.148137 -0.196723 -0.460559 -0.446633 -0.522317 -0.331466   \n",
       "32  1871.886858 -0.148127 -0.196517 -0.460737 -0.446407 -0.522464 -0.331111   \n",
       "40  1868.266880 -0.149500 -0.198154 -0.467544 -0.449452 -0.526372 -0.335075   \n",
       "\n",
       "       l7_23     l7_24     l7_25     l7_26     l7_27     l7_34     l7_35  \\\n",
       "7  -0.049816 -0.334803 -0.316211 -0.401027 -0.191297 -0.289821 -0.270659   \n",
       "8  -0.050309 -0.335155 -0.320172 -0.405501 -0.193459 -0.289731 -0.274281   \n",
       "20 -0.050044 -0.335298 -0.319645 -0.405560 -0.192796 -0.290122 -0.273984   \n",
       "32 -0.049840 -0.335508 -0.319400 -0.405737 -0.192422 -0.290526 -0.273921   \n",
       "40 -0.050140 -0.341945 -0.321559 -0.409063 -0.195361 -0.296896 -0.275867   \n",
       "\n",
       "       l7_36     l7_37     l7_45     l7_46     l7_47     l7_56     l7_57  \\\n",
       "7  -0.358370 -0.142842  0.020793 -0.076494  0.153327 -0.097133  0.132958   \n",
       "8  -0.362588 -0.144556  0.016784 -0.081409  0.151521 -0.098060  0.135080   \n",
       "20 -0.362881 -0.144142  0.017532 -0.081320  0.152351 -0.098712  0.135180   \n",
       "32 -0.363243 -0.143962  0.018041 -0.081296  0.152961 -0.099191  0.135294   \n",
       "40 -0.366439 -0.146658  0.022905 -0.078033  0.157077 -0.100758  0.134656   \n",
       "\n",
       "       l7_67  \n",
       "7   0.227157  \n",
       "8   0.230092  \n",
       "20  0.230811  \n",
       "32  0.231380  \n",
       "40  0.232263  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['period'].isin([2011, 2013])]\n",
    "df = df.loc[df['period'].isin([2013])]\n",
    "df = df.dropna(axis=0, subset=['hh_inc', 'viirs'])\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.viirs = np.log(df.viirs+1)\n",
    "#df.hh_inc = np.log(df.hh_inc+1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'hh_inc'\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "# Separate feature sets from label sets\n",
    "x_df = df.drop(labels=[LABEL], axis=1)\n",
    "scaler = preprocessing.MinMaxScaler() \n",
    "scaled_values = scaler.fit_transform(x_df) \n",
    "x_df.loc[:,:] = scaled_values\n",
    "\n",
    "y_df = df[LABEL]\n",
    "\n",
    "# Split into test and train sets for features and labels\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x_df, y_df, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_FEATURES = df.filter(regex='l7', axis=1).columns.tolist()\n",
    "DAY_FEATURES_VIIRS = DAY_FEATURES + ['viirs']\n",
    "DAY_FEATURES_DMSPOLS = DAY_FEATURES + ['dmspols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.13502369],\n",
       "       [0.13502369, 1.        ]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(max_depth=20)\n",
    "trained = regressor.fit(x_train[DAY_FEATURES_VIIRS], y_train)\n",
    "hh_income_predict = trained.predict(x_test[DAY_FEATURES_VIIRS])\n",
    "\n",
    "from matplotlib import pyplot\n",
    "pyplot.scatter(y_test, hh_income_predict)\n",
    "pyplot.show()\n",
    "\n",
    "np.corrcoef(y_test, hh_income_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess data\n",
    "\n",
    "All vars are numeric - impute missing data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FEATURES MISSING:\n",
      "dmspols_2011    38\n",
      "l7_2011_1       0 \n",
      "l7_2011_2       0 \n",
      "l7_2011_3       0 \n",
      "l7_2011_4       0 \n",
      "l7_2011_5       0 \n",
      "l7_2011_6       0 \n",
      "l7_2011_7       0 \n",
      "viirs_2012      38\n",
      "dtype: int64\n",
      "\n",
      "TEST FEATURES MISSING:\n",
      "dmspols_2011    14\n",
      "l7_2011_1       0 \n",
      "l7_2011_2       0 \n",
      "l7_2011_3       0 \n",
      "l7_2011_4       0 \n",
      "l7_2011_5       0 \n",
      "l7_2011_6       0 \n",
      "l7_2011_7       0 \n",
      "viirs_2012      14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows are missing across columns\n",
    "print(\"TRAINING FEATURES MISSING:\")\n",
    "print(pd.isnull(x_train).sum())\n",
    "print(\"\")\n",
    "print(\"TEST FEATURES MISSING:\")\n",
    "print(pd.isnull(x_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (x_train, x_test):\n",
    "    for j in i.columns:\n",
    "        \n",
    "        if i[j].isnull().sum():\n",
    "            # Create imputed flag\n",
    "            new_name = i[j].name + '_imputed'\n",
    "            i[new_name] = pd.isnull(i[j]).astype('int')\n",
    "            # Fill with mean\n",
    "            i[j] = i[j].fillna(i[j].mean())\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FEATURES MISSING:\n",
      "dmspols_2011            0\n",
      "l7_2011_1               0\n",
      "l7_2011_2               0\n",
      "l7_2011_3               0\n",
      "l7_2011_4               0\n",
      "l7_2011_5               0\n",
      "l7_2011_6               0\n",
      "l7_2011_7               0\n",
      "viirs_2012              0\n",
      "dmspols_2011_imputed    0\n",
      "viirs_2012_imputed      0\n",
      "dtype: int64\n",
      "\n",
      "TEST FEATURES MISSING:\n",
      "dmspols_2011            0\n",
      "l7_2011_1               0\n",
      "l7_2011_2               0\n",
      "l7_2011_3               0\n",
      "l7_2011_4               0\n",
      "l7_2011_5               0\n",
      "l7_2011_6               0\n",
      "l7_2011_7               0\n",
      "viirs_2012              0\n",
      "dmspols_2011_imputed    0\n",
      "viirs_2012_imputed      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# All missing values were imputed\n",
    "print(\"TRAINING FEATURES MISSING:\")\n",
    "print(pd.isnull(x_train).sum())\n",
    "print(\"\")\n",
    "print(\"TEST FEATURES MISSING:\")\n",
    "print(pd.isnull(x_test).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Generation\n",
    "\n",
    "[Landsat 7 specs](https://landsat.usgs.gov/sites/default/files/documents/si_product_guide.pdf#page=14)\n",
    "\n",
    "Create indices from every possible pair of Landsat 7 band.\n",
    "- Normalized Difference Vegetation Index, NDVI = $\\frac{NIR - Red}{NIR + Red}$ is formed from the (NIR, Red) pair.\n",
    "- Normalized Difference Built-up Index, NDBI = $\\frac{SWIR1 - NIR}{SWIR1 + NIR}$ is formed from the (NIR, SWIR1) pair.\n",
    "- Normalized Difference Water Index, NDWO = $\\frac{NIR - SWIR1}{NIR + SWIR1}$ is also formed from the (NIR, SWIR1) pair.\n",
    "- Modified NDWI, MNDWI = $\\frac{Green - SWIR1}{Green + SWIR1}$ is formed from the (NIR, Green) pair. And so on.\n",
    "\n",
    "\n",
    "| Band | 1 | 2 | 3 | 4 | 5 | 6 | 7\n",
    "| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- \n",
    "| 1 | NA \n",
    "| 2 | ? | NA \n",
    "| 3 | ? | ? | NA \n",
    "| 4 | ? | ? | NDVI | NA\n",
    "| 5 | ? | MNDWI | ? | NDBI, NDWI | NA \n",
    "| 6 | ? | ? | ? | ? | ? | NA \n",
    "| 7 | ? | ? | ? | ? | ? | ? | NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ratios \n",
    "# Note that ratio of Band A to Band B is the same as ratio of Band B to Band A\n",
    "# Solution: only create ratios where A < B\n",
    "for df in (x_train, x_test):\n",
    "    for i in range(1, 8):\n",
    "        for j in range(1, 8):\n",
    "\n",
    "            if i >= j:\n",
    "                continue\n",
    "            else:\n",
    "                band1 = f'l7_2011_{i}'\n",
    "                band2 = f'l7_2011_{j}'\n",
    "                new_var = f'ratio_{i}_{j}'\n",
    "                df[new_var] = abs((df[band1] - df[band2]) / (df[band1] + df[band2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>dmspols_2011_imputed</th>\n",
       "      <th>viirs_2012_imputed</th>\n",
       "      <th>ratio_1_2</th>\n",
       "      <th>ratio_1_3</th>\n",
       "      <th>ratio_1_4</th>\n",
       "      <th>ratio_1_5</th>\n",
       "      <th>ratio_1_6</th>\n",
       "      <th>ratio_1_7</th>\n",
       "      <th>ratio_2_3</th>\n",
       "      <th>ratio_2_4</th>\n",
       "      <th>ratio_2_5</th>\n",
       "      <th>ratio_2_6</th>\n",
       "      <th>ratio_2_7</th>\n",
       "      <th>ratio_3_4</th>\n",
       "      <th>ratio_3_5</th>\n",
       "      <th>ratio_3_6</th>\n",
       "      <th>ratio_3_7</th>\n",
       "      <th>ratio_4_5</th>\n",
       "      <th>ratio_4_6</th>\n",
       "      <th>ratio_4_7</th>\n",
       "      <th>ratio_5_6</th>\n",
       "      <th>ratio_5_7</th>\n",
       "      <th>ratio_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1058.988085</td>\n",
       "      <td>1385.168556</td>\n",
       "      <td>1602.108980</td>\n",
       "      <td>2406.603022</td>\n",
       "      <td>2465.198634</td>\n",
       "      <td>3039.765911</td>\n",
       "      <td>2121.646178</td>\n",
       "      <td>5.494750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133453</td>\n",
       "      <td>0.204097</td>\n",
       "      <td>0.388856</td>\n",
       "      <td>0.399017</td>\n",
       "      <td>0.483263</td>\n",
       "      <td>0.334103</td>\n",
       "      <td>0.072621</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.280501</td>\n",
       "      <td>0.373926</td>\n",
       "      <td>0.210013</td>\n",
       "      <td>0.200686</td>\n",
       "      <td>0.212202</td>\n",
       "      <td>0.309715</td>\n",
       "      <td>0.139520</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.116254</td>\n",
       "      <td>0.062929</td>\n",
       "      <td>0.104373</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.177882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>6.0</td>\n",
       "      <td>868.614348</td>\n",
       "      <td>1174.826667</td>\n",
       "      <td>1321.466522</td>\n",
       "      <td>2431.912174</td>\n",
       "      <td>2139.191594</td>\n",
       "      <td>3039.880435</td>\n",
       "      <td>1569.171884</td>\n",
       "      <td>0.312616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149851</td>\n",
       "      <td>0.206774</td>\n",
       "      <td>0.473651</td>\n",
       "      <td>0.422427</td>\n",
       "      <td>0.555525</td>\n",
       "      <td>0.287374</td>\n",
       "      <td>0.058743</td>\n",
       "      <td>0.348538</td>\n",
       "      <td>0.290996</td>\n",
       "      <td>0.442511</td>\n",
       "      <td>0.143712</td>\n",
       "      <td>0.295852</td>\n",
       "      <td>0.236292</td>\n",
       "      <td>0.394010</td>\n",
       "      <td>0.085692</td>\n",
       "      <td>0.064037</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>0.215627</td>\n",
       "      <td>0.173909</td>\n",
       "      <td>0.153712</td>\n",
       "      <td>0.319091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1134.106337</td>\n",
       "      <td>1482.951823</td>\n",
       "      <td>1742.763310</td>\n",
       "      <td>2160.221933</td>\n",
       "      <td>2511.618200</td>\n",
       "      <td>3034.363860</td>\n",
       "      <td>2189.763166</td>\n",
       "      <td>0.129844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133297</td>\n",
       "      <td>0.211569</td>\n",
       "      <td>0.311479</td>\n",
       "      <td>0.377843</td>\n",
       "      <td>0.455864</td>\n",
       "      <td>0.317599</td>\n",
       "      <td>0.080544</td>\n",
       "      <td>0.185901</td>\n",
       "      <td>0.257516</td>\n",
       "      <td>0.343437</td>\n",
       "      <td>0.192449</td>\n",
       "      <td>0.106959</td>\n",
       "      <td>0.180721</td>\n",
       "      <td>0.270372</td>\n",
       "      <td>0.113667</td>\n",
       "      <td>0.075216</td>\n",
       "      <td>0.168279</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.094257</td>\n",
       "      <td>0.068460</td>\n",
       "      <td>0.161673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>5.0</td>\n",
       "      <td>893.232153</td>\n",
       "      <td>1160.535694</td>\n",
       "      <td>1302.790337</td>\n",
       "      <td>2077.571532</td>\n",
       "      <td>2340.158590</td>\n",
       "      <td>2987.358532</td>\n",
       "      <td>1897.636535</td>\n",
       "      <td>0.326881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130153</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.398660</td>\n",
       "      <td>0.447495</td>\n",
       "      <td>0.539641</td>\n",
       "      <td>0.359890</td>\n",
       "      <td>0.057749</td>\n",
       "      <td>0.283201</td>\n",
       "      <td>0.336968</td>\n",
       "      <td>0.440422</td>\n",
       "      <td>0.241027</td>\n",
       "      <td>0.229201</td>\n",
       "      <td>0.284761</td>\n",
       "      <td>0.392660</td>\n",
       "      <td>0.185865</td>\n",
       "      <td>0.059439</td>\n",
       "      <td>0.179625</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.121482</td>\n",
       "      <td>0.104423</td>\n",
       "      <td>0.223075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>20.0</td>\n",
       "      <td>855.555766</td>\n",
       "      <td>1197.115463</td>\n",
       "      <td>1298.970879</td>\n",
       "      <td>2869.879732</td>\n",
       "      <td>2305.694817</td>\n",
       "      <td>3020.864444</td>\n",
       "      <td>1695.336342</td>\n",
       "      <td>0.643381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166398</td>\n",
       "      <td>0.205806</td>\n",
       "      <td>0.540695</td>\n",
       "      <td>0.458723</td>\n",
       "      <td>0.558585</td>\n",
       "      <td>0.329211</td>\n",
       "      <td>0.040806</td>\n",
       "      <td>0.411302</td>\n",
       "      <td>0.316483</td>\n",
       "      <td>0.432375</td>\n",
       "      <td>0.172249</td>\n",
       "      <td>0.376821</td>\n",
       "      <td>0.279284</td>\n",
       "      <td>0.398602</td>\n",
       "      <td>0.132373</td>\n",
       "      <td>0.109009</td>\n",
       "      <td>0.025631</td>\n",
       "      <td>0.257281</td>\n",
       "      <td>0.134265</td>\n",
       "      <td>0.152550</td>\n",
       "      <td>0.281058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dmspols_2011    l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "358   53.0          1058.988085  1385.168556  1602.108980  2406.603022   \n",
       "2438  6.0           868.614348   1174.826667  1321.466522  2431.912174   \n",
       "4966  0.0           1134.106337  1482.951823  1742.763310  2160.221933   \n",
       "3805  5.0           893.232153   1160.535694  1302.790337  2077.571532   \n",
       "1511  20.0          855.555766   1197.115463  1298.970879  2869.879732   \n",
       "\n",
       "        l7_2011_5    l7_2011_6    l7_2011_7  viirs_2012  dmspols_2011_imputed  \\\n",
       "358   2465.198634  3039.765911  2121.646178  5.494750    0                      \n",
       "2438  2139.191594  3039.880435  1569.171884  0.312616    0                      \n",
       "4966  2511.618200  3034.363860  2189.763166  0.129844    0                      \n",
       "3805  2340.158590  2987.358532  1897.636535  0.326881    0                      \n",
       "1511  2305.694817  3020.864444  1695.336342  0.643381    0                      \n",
       "\n",
       "      viirs_2012_imputed  ratio_1_2  ratio_1_3  ratio_1_4  ratio_1_5  \\\n",
       "358   0                   0.133453   0.204097   0.388856   0.399017    \n",
       "2438  0                   0.149851   0.206774   0.473651   0.422427    \n",
       "4966  0                   0.133297   0.211569   0.311479   0.377843    \n",
       "3805  0                   0.130153   0.186500   0.398660   0.447495    \n",
       "1511  0                   0.166398   0.205806   0.540695   0.458723    \n",
       "\n",
       "      ratio_1_6  ratio_1_7  ratio_2_3  ratio_2_4  ratio_2_5  ratio_2_6  \\\n",
       "358   0.483263   0.334103   0.072621   0.269382   0.280501   0.373926    \n",
       "2438  0.555525   0.287374   0.058743   0.348538   0.290996   0.442511    \n",
       "4966  0.455864   0.317599   0.080544   0.185901   0.257516   0.343437    \n",
       "3805  0.539641   0.359890   0.057749   0.283201   0.336968   0.440422    \n",
       "1511  0.558585   0.329211   0.040806   0.411302   0.316483   0.432375    \n",
       "\n",
       "      ratio_2_7  ratio_3_4  ratio_3_5  ratio_3_6  ratio_3_7  ratio_4_5  \\\n",
       "358   0.210013   0.200686   0.212202   0.309715   0.139520   0.012028    \n",
       "2438  0.143712   0.295852   0.236292   0.394010   0.085692   0.064037    \n",
       "4966  0.192449   0.106959   0.180721   0.270372   0.113667   0.075216    \n",
       "3805  0.241027   0.229201   0.284761   0.392660   0.185865   0.059439    \n",
       "1511  0.172249   0.376821   0.279284   0.398602   0.132373   0.109009    \n",
       "\n",
       "      ratio_4_6  ratio_4_7  ratio_5_6  ratio_5_7  ratio_6_7  \n",
       "358   0.116254   0.062929   0.104373   0.074900   0.177882   \n",
       "2438  0.111110   0.215627   0.173909   0.153712   0.319091   \n",
       "4966  0.168279   0.006791   0.094257   0.068460   0.161673   \n",
       "3805  0.179625   0.045264   0.121482   0.104423   0.223075   \n",
       "1511  0.025631   0.257281   0.134265   0.152550   0.281058   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>dmspols_2011_imputed</th>\n",
       "      <th>viirs_2012_imputed</th>\n",
       "      <th>ratio_1_2</th>\n",
       "      <th>ratio_1_3</th>\n",
       "      <th>ratio_1_4</th>\n",
       "      <th>ratio_1_5</th>\n",
       "      <th>ratio_1_6</th>\n",
       "      <th>ratio_1_7</th>\n",
       "      <th>ratio_2_3</th>\n",
       "      <th>ratio_2_4</th>\n",
       "      <th>ratio_2_5</th>\n",
       "      <th>ratio_2_6</th>\n",
       "      <th>ratio_2_7</th>\n",
       "      <th>ratio_3_4</th>\n",
       "      <th>ratio_3_5</th>\n",
       "      <th>ratio_3_6</th>\n",
       "      <th>ratio_3_7</th>\n",
       "      <th>ratio_4_5</th>\n",
       "      <th>ratio_4_6</th>\n",
       "      <th>ratio_4_7</th>\n",
       "      <th>ratio_5_6</th>\n",
       "      <th>ratio_5_7</th>\n",
       "      <th>ratio_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>839.539600</td>\n",
       "      <td>1140.913113</td>\n",
       "      <td>1211.132724</td>\n",
       "      <td>2883.450827</td>\n",
       "      <td>2225.548448</td>\n",
       "      <td>3011.056571</td>\n",
       "      <td>1528.228169</td>\n",
       "      <td>0.366964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.181206</td>\n",
       "      <td>0.548997</td>\n",
       "      <td>0.452192</td>\n",
       "      <td>0.563943</td>\n",
       "      <td>0.290860</td>\n",
       "      <td>0.029855</td>\n",
       "      <td>0.432997</td>\n",
       "      <td>0.322189</td>\n",
       "      <td>0.450423</td>\n",
       "      <td>0.145108</td>\n",
       "      <td>0.408422</td>\n",
       "      <td>0.295173</td>\n",
       "      <td>0.426301</td>\n",
       "      <td>0.115755</td>\n",
       "      <td>0.128773</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0.307190</td>\n",
       "      <td>0.150003</td>\n",
       "      <td>0.185765</td>\n",
       "      <td>0.326666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>722.351766</td>\n",
       "      <td>1035.490446</td>\n",
       "      <td>1061.942096</td>\n",
       "      <td>2937.096120</td>\n",
       "      <td>2030.396642</td>\n",
       "      <td>3002.826433</td>\n",
       "      <td>1297.845107</td>\n",
       "      <td>0.547749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178138</td>\n",
       "      <td>0.190322</td>\n",
       "      <td>0.605213</td>\n",
       "      <td>0.475178</td>\n",
       "      <td>0.612179</td>\n",
       "      <td>0.284870</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.478682</td>\n",
       "      <td>0.324508</td>\n",
       "      <td>0.487167</td>\n",
       "      <td>0.112438</td>\n",
       "      <td>0.468901</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.477490</td>\n",
       "      <td>0.099968</td>\n",
       "      <td>0.182527</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.387078</td>\n",
       "      <td>0.193202</td>\n",
       "      <td>0.220102</td>\n",
       "      <td>0.396445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>16.500000</td>\n",
       "      <td>887.069376</td>\n",
       "      <td>1161.080987</td>\n",
       "      <td>1328.149637</td>\n",
       "      <td>2625.712482</td>\n",
       "      <td>2264.979245</td>\n",
       "      <td>3000.837155</td>\n",
       "      <td>1627.782148</td>\n",
       "      <td>0.832364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133785</td>\n",
       "      <td>0.199114</td>\n",
       "      <td>0.494948</td>\n",
       "      <td>0.437147</td>\n",
       "      <td>0.543678</td>\n",
       "      <td>0.294535</td>\n",
       "      <td>0.067117</td>\n",
       "      <td>0.386774</td>\n",
       "      <td>0.322206</td>\n",
       "      <td>0.442045</td>\n",
       "      <td>0.167345</td>\n",
       "      <td>0.328176</td>\n",
       "      <td>0.260728</td>\n",
       "      <td>0.386392</td>\n",
       "      <td>0.101367</td>\n",
       "      <td>0.073759</td>\n",
       "      <td>0.066670</td>\n",
       "      <td>0.234614</td>\n",
       "      <td>0.139742</td>\n",
       "      <td>0.163688</td>\n",
       "      <td>0.296645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1004.152275</td>\n",
       "      <td>1226.656331</td>\n",
       "      <td>1349.472617</td>\n",
       "      <td>2188.364242</td>\n",
       "      <td>2160.560562</td>\n",
       "      <td>3010.192118</td>\n",
       "      <td>1731.231527</td>\n",
       "      <td>6.271641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099741</td>\n",
       "      <td>0.146719</td>\n",
       "      <td>0.370934</td>\n",
       "      <td>0.365407</td>\n",
       "      <td>0.499718</td>\n",
       "      <td>0.265805</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>0.281611</td>\n",
       "      <td>0.275714</td>\n",
       "      <td>0.420958</td>\n",
       "      <td>0.170586</td>\n",
       "      <td>0.237120</td>\n",
       "      <td>0.231077</td>\n",
       "      <td>0.380928</td>\n",
       "      <td>0.123919</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.158088</td>\n",
       "      <td>0.116628</td>\n",
       "      <td>0.164315</td>\n",
       "      <td>0.110317</td>\n",
       "      <td>0.269742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>19.712733</td>\n",
       "      <td>641.214888</td>\n",
       "      <td>439.215760</td>\n",
       "      <td>368.688427</td>\n",
       "      <td>324.121692</td>\n",
       "      <td>255.604827</td>\n",
       "      <td>2936.902443</td>\n",
       "      <td>213.807066</td>\n",
       "      <td>3.548001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186962</td>\n",
       "      <td>0.269854</td>\n",
       "      <td>0.328479</td>\n",
       "      <td>0.429975</td>\n",
       "      <td>0.641591</td>\n",
       "      <td>0.499879</td>\n",
       "      <td>0.087297</td>\n",
       "      <td>0.150777</td>\n",
       "      <td>0.264257</td>\n",
       "      <td>0.739810</td>\n",
       "      <td>0.345177</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.181139</td>\n",
       "      <td>0.776930</td>\n",
       "      <td>0.265893</td>\n",
       "      <td>0.118188</td>\n",
       "      <td>0.801215</td>\n",
       "      <td>0.205073</td>\n",
       "      <td>0.839872</td>\n",
       "      <td>0.089043</td>\n",
       "      <td>0.864280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dmspols_2011    l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "1602  5.500000      839.539600   1140.913113  1211.132724  2883.450827   \n",
       "1966  7.500000      722.351766   1035.490446  1061.942096  2937.096120   \n",
       "3157  16.500000     887.069376   1161.080987  1328.149637  2625.712482   \n",
       "1065  61.000000     1004.152275  1226.656331  1349.472617  2188.364242   \n",
       "793   19.712733     641.214888   439.215760   368.688427   324.121692    \n",
       "\n",
       "        l7_2011_5    l7_2011_6    l7_2011_7  viirs_2012  dmspols_2011_imputed  \\\n",
       "1602  2225.548448  3011.056571  1528.228169  0.366964    0                      \n",
       "1966  2030.396642  3002.826433  1297.845107  0.547749    0                      \n",
       "3157  2264.979245  3000.837155  1627.782148  0.832364    0                      \n",
       "1065  2160.560562  3010.192118  1731.231527  6.271641    0                      \n",
       "793   255.604827   2936.902443  213.807066   3.548001    1                      \n",
       "\n",
       "      viirs_2012_imputed  ratio_1_2  ratio_1_3  ratio_1_4  ratio_1_5  \\\n",
       "1602  0                   0.152174   0.181206   0.548997   0.452192    \n",
       "1966  0                   0.178138   0.190322   0.605213   0.475178    \n",
       "3157  0                   0.133785   0.199114   0.494948   0.437147    \n",
       "1065  0                   0.099741   0.146719   0.370934   0.365407    \n",
       "793   1                   0.186962   0.269854   0.328479   0.429975    \n",
       "\n",
       "      ratio_1_6  ratio_1_7  ratio_2_3  ratio_2_4  ratio_2_5  ratio_2_6  \\\n",
       "1602  0.563943   0.290860   0.029855   0.432997   0.322189   0.450423    \n",
       "1966  0.612179   0.284870   0.012611   0.478682   0.324508   0.487167    \n",
       "3157  0.543678   0.294535   0.067117   0.386774   0.322206   0.442045    \n",
       "1065  0.499718   0.265805   0.047675   0.281611   0.275714   0.420958    \n",
       "793   0.641591   0.499879   0.087297   0.150777   0.264257   0.739810    \n",
       "\n",
       "      ratio_2_7  ratio_3_4  ratio_3_5  ratio_3_6  ratio_3_7  ratio_4_5  \\\n",
       "1602  0.145108   0.408422   0.295173   0.426301   0.115755   0.128773    \n",
       "1966  0.112438   0.468901   0.313179   0.477490   0.099968   0.182527    \n",
       "3157  0.167345   0.328176   0.260728   0.386392   0.101367   0.073759    \n",
       "1065  0.170586   0.237120   0.231077   0.380928   0.123919   0.006393    \n",
       "793   0.345177   0.064327   0.181139   0.776930   0.265893   0.118188    \n",
       "\n",
       "      ratio_4_6  ratio_4_7  ratio_5_6  ratio_5_7  ratio_6_7  \n",
       "1602  0.021648   0.307190   0.150003   0.185765   0.326666   \n",
       "1966  0.011066   0.387078   0.193202   0.220102   0.396445   \n",
       "3157  0.066670   0.234614   0.139742   0.163688   0.296645   \n",
       "1065  0.158088   0.116628   0.164315   0.110317   0.269742   \n",
       "793   0.801215   0.205073   0.839872   0.089043   0.864280   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check that lengths match\n",
    "print(len(x_train) == len(y_train))\n",
    "print(len(x_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define feature groups\n",
    "\n",
    "1. Daytime-only: Landsat 7 band data and computed indices\n",
    "2. Nighttime-only: DMSP and VIIRS data + imputed flags\n",
    "3. All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day-only: ['l7_2011_1', 'l7_2011_2', 'l7_2011_3', 'l7_2011_4', 'l7_2011_5', 'l7_2011_6', 'l7_2011_7', 'ratio_1_2', 'ratio_1_3', 'ratio_1_4', 'ratio_1_5', 'ratio_1_6', 'ratio_1_7', 'ratio_2_3', 'ratio_2_4', 'ratio_2_5', 'ratio_2_6', 'ratio_2_7', 'ratio_3_4', 'ratio_3_5', 'ratio_3_6', 'ratio_3_7', 'ratio_4_5', 'ratio_4_6', 'ratio_4_7', 'ratio_5_6', 'ratio_5_7', 'ratio_6_7']\n",
      "-----\n",
      "Night-only: ['dmspols_2011', 'viirs_2012', 'dmspols_2011_imputed', 'viirs_2012_imputed']\n"
     ]
    }
   ],
   "source": [
    "DAY_FEATURES = df.filter(regex='l7|ratio', axis=1).columns.tolist()\n",
    "NIGHT_FEATURES = ['dmspols_2011', 'viirs_2012', 'dmspols_2011_imputed', 'viirs_2012_imputed']\n",
    "ALL_FEATURES = df.columns.tolist()\n",
    "\n",
    "print(\"Day-only:\", DAY_FEATURES)\n",
    "print(\"-----\")\n",
    "print(\"Night-only:\", NIGHT_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pickle cleaned data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [x_train, x_test, y_train, y_test]\n",
    "\n",
    "output_path = os.path.join('output', 'final_data.pkl')\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(obj=clean_data,\n",
    "                file=f,\n",
    "                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Regressors\n",
    "\n",
    "### 5.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a TrainedRegressor object to hold key results information\n",
    "class TrainedRegressor:\n",
    "    \n",
    "    def __init__(self, method, params, features, regressor):\n",
    "        self.method = method\n",
    "        self.params = params\n",
    "        self.regressor = regressor\n",
    "        self.features = features\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Trained {self.method} on feature set {self.features} with params {self.params}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: Training LinearRegression on DAY_FEATURES with params {'n_jobs': -1}\n",
      "Model 2: Training LinearRegression on NIGHT_FEATURES with params {'n_jobs': -1}\n",
      "Model 3: Training LinearRegression on ALL_FEATURES with params {'n_jobs': -1}\n",
      "Model 4: Training Lasso on DAY_FEATURES with params {'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}\n",
      "Model 5: Training Lasso on NIGHT_FEATURES with params {'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}\n",
      "Model 6: Training Lasso on ALL_FEATURES with params {'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}\n",
      "Model 7: Training Ridge on DAY_FEATURES with params {'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}\n",
      "Model 8: Training Ridge on NIGHT_FEATURES with params {'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}\n",
      "Model 9: Training Ridge on ALL_FEATURES with params {'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}\n",
      "Model 10: Training LinearSVR on DAY_FEATURES with params {'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 11: Training LinearSVR on NIGHT_FEATURES with params {'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 12: Training LinearSVR on ALL_FEATURES with params {'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 13: Training DecisionTreeRegressor on DAY_FEATURES with params {'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 14: Training DecisionTreeRegressor on NIGHT_FEATURES with params {'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 15: Training DecisionTreeRegressor on ALL_FEATURES with params {'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 16: Training BaggingRegressor on DAY_FEATURES with params {'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 17: Training BaggingRegressor on NIGHT_FEATURES with params {'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 18: Training BaggingRegressor on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 19: Training GradientBoostingRegressor on DAY_FEATURES with params {'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 20: Training GradientBoostingRegressor on NIGHT_FEATURES with params {'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 21: Training GradientBoostingRegressor on ALL_FEATURES with params {'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 22: Training RandomForestRegressor on DAY_FEATURES with params {'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 23: Training RandomForestRegressor on NIGHT_FEATURES with params {'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 24: Training RandomForestRegressor on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "# Use GRID_MAIN for full grid search\n",
    "parameters = cf.GRID_TEST\n",
    "\n",
    "trained_list = []\n",
    "count = 0\n",
    "# print('Training model ', end='')\n",
    "for i in parameters['regressors']:\n",
    "    for j in parameters[i]:\n",
    "        for k in ('DAY_FEATURES', 'NIGHT_FEATURES', 'ALL_FEATURES'):\n",
    "        \n",
    "            #print(str(count), end=' ')\n",
    "            count += 1\n",
    "            print(f'Model {count}: Training {i} on {k} with params {str(j)}')\n",
    "\n",
    "            # Initialize regressor, fit data, then append TrainedRegressor object to list\n",
    "            regressor = eval(i)(**j)\n",
    "            trained = regressor.fit(x_train[eval(k)], y_train)\n",
    "            trained_list.append(TrainedRegressor(i, str(j), k, trained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "for i in trained_list:\n",
    "    \n",
    "    # Get predicted results from test data\n",
    "    features = eval(i.features)\n",
    "    pred_labels = i.regressor.predict(x_test[features])\n",
    "    \n",
    "    # Append results to dataframe and sort by R^2\n",
    "    pred_dict = {\n",
    "        'regressor': i.method,\n",
    "        'features': i.features,\n",
    "        'params': i.params,\n",
    "        'r2': r2_score(y_true=y_test, y_pred=pred_labels)        \n",
    "    }\n",
    "    \n",
    "    results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "        .sort_values(by='r2', ascending=False, axis=0) \\\n",
    "        [['regressor', 'params', 'features', 'r2']]\n",
    "\n",
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regressor</th>\n",
       "      <th>params</th>\n",
       "      <th>features</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'n_jobs': -1}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.004410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.005233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.013722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>{'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>{'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.018725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.025748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.026175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.027755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.028450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>{'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.029901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'n_jobs': -1}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.035409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'n_jobs': -1}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.035435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}</td>\n",
       "      <td>ALL_FEATURES</td>\n",
       "      <td>-0.041239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}</td>\n",
       "      <td>NIGHT_FEATURES</td>\n",
       "      <td>-0.043606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}</td>\n",
       "      <td>DAY_FEATURES</td>\n",
       "      <td>-0.052988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    regressor  \\\n",
       "0   DecisionTreeRegressor       \n",
       "1   GradientBoostingRegressor   \n",
       "2   GradientBoostingRegressor   \n",
       "3   GradientBoostingRegressor   \n",
       "4   Ridge                       \n",
       "5   Lasso                       \n",
       "6   LinearRegression            \n",
       "7   RandomForestRegressor       \n",
       "23  RandomForestRegressor       \n",
       "8   DecisionTreeRegressor       \n",
       "9   RandomForestRegressor       \n",
       "10  DecisionTreeRegressor       \n",
       "11  LinearSVR                   \n",
       "12  LinearSVR                   \n",
       "13  Lasso                       \n",
       "14  Lasso                       \n",
       "15  Ridge                       \n",
       "16  Ridge                       \n",
       "17  LinearSVR                   \n",
       "18  LinearRegression            \n",
       "19  LinearRegression            \n",
       "20  BaggingRegressor            \n",
       "21  BaggingRegressor            \n",
       "22  BaggingRegressor            \n",
       "\n",
       "                                                                                                                         params  \\\n",
       "0   {'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}                           \n",
       "1   {'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}   \n",
       "2   {'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}   \n",
       "3   {'loss': 'ls', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'mse', 'max_features': 'sqrt', 'random_state': 0}   \n",
       "4   {'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}                                                  \n",
       "5   {'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}                                                 \n",
       "6   {'n_jobs': -1}                                                                                                                \n",
       "7   {'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}            \n",
       "23  {'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}            \n",
       "8   {'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}                           \n",
       "9   {'n_estimators': 100, 'criterion': 'mse', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}            \n",
       "10  {'criterion': 'mse', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}                           \n",
       "11  {'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}                               \n",
       "12  {'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}                               \n",
       "13  {'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}                                                 \n",
       "14  {'alpha': 0.01, 'max_iter': 1000.0, 'selection': 'random', 'random_state': 0}                                                 \n",
       "15  {'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}                                                  \n",
       "16  {'alpha': 0.01, 'max_iter': 1000.0, 'solver': 'cholesky', 'random_state': 0}                                                  \n",
       "17  {'epsilon': 0, 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}                               \n",
       "18  {'n_jobs': -1}                                                                                                                \n",
       "19  {'n_jobs': -1}                                                                                                                \n",
       "20  {'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}                                                     \n",
       "21  {'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}                                                     \n",
       "22  {'n_estimators': 100, 'max_features': 1, 'random_state': 0, 'n_jobs': -1}                                                     \n",
       "\n",
       "          features        r2  \n",
       "0   ALL_FEATURES   -0.001394  \n",
       "1   NIGHT_FEATURES -0.001550  \n",
       "2   ALL_FEATURES   -0.001606  \n",
       "3   DAY_FEATURES   -0.001608  \n",
       "4   NIGHT_FEATURES -0.003138  \n",
       "5   NIGHT_FEATURES -0.003138  \n",
       "6   NIGHT_FEATURES -0.003138  \n",
       "7   NIGHT_FEATURES -0.003434  \n",
       "23  ALL_FEATURES   -0.004410  \n",
       "8   NIGHT_FEATURES -0.004975  \n",
       "9   DAY_FEATURES   -0.005233  \n",
       "10  DAY_FEATURES   -0.013722  \n",
       "11  DAY_FEATURES   -0.018393  \n",
       "12  ALL_FEATURES   -0.018725  \n",
       "13  DAY_FEATURES   -0.025748  \n",
       "14  ALL_FEATURES   -0.026175  \n",
       "15  DAY_FEATURES   -0.027755  \n",
       "16  ALL_FEATURES   -0.028450  \n",
       "17  NIGHT_FEATURES -0.029901  \n",
       "18  ALL_FEATURES   -0.035409  \n",
       "19  DAY_FEATURES   -0.035435  \n",
       "20  ALL_FEATURES   -0.041239  \n",
       "21  NIGHT_FEATURES -0.043606  \n",
       "22  DAY_FEATURES   -0.052988  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
