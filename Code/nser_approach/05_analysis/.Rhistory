tweet <- "at drive-inn (thika road). a driver of an exhauster truck loses control checking the guardrails. no serious injuries to pe sons bt to the vehicle itself. @kenhakenya https://t.co/j4raxybmsb"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "20:03 accident on thika road gsu depression tuvumiliane cops on it via @njugunastevens"
tweet <- "10:36 minor accident at the kangemi stage after the bridge heading to town via @zollynash"
tweet <- "accident at globe roundabout"
tweet <- "06:42 accident along kenyatta avenue opp 680 involving 3 vehicles! https://t.co/exz5sfsgvz via @munenewengwa"
tweet <- "accident along langata rd past 1824 an audi car"
fuzzy_match_landmark <- TRUE
fuzzy_match_landmark.min.word.length <- c(5,11) # minimum word length for fuzzy match
fuzzy_match_landmark.dist <- c(1,2) # maximum levenstein distance to use
fuzzy_match_ngram_max <- 3
prepositions_list <- c("near", "at")
crash_words <- c("accidents", "accident", "crash", "overturn", "collision", "wreck") # hit?
junction_words <- c("intersection", "junction")
first_letters_same <- TRUE
last_letters_same <- TRUE # !!!!!!!! fails for roysambo/u. Maybe: if 1 letter off, only first letter needs to be same. But be more restrictive with 2?
import_files <- FALSE
tier_1_prepositions <- c("at", "next to","around", "just after", "opposite","opp", "apa", "hapa","happened at","just before","at the","outside")
tier_2_prepositions <- c("near", "after", "toward","along", "towards")
tier_3_prepositions <- c("past","from","on")
# Import
landmark_gazetteer_orig <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
roads <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "roads_augmented", "osm_roads_aug.Rds"))
neighborhoods <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "nairobi_estates", "nairobi_estates.Rds"))
print(tweet)
# Checks ---------------------------------------------------------------------
if(length(fuzzy_match_landmark.min.word.length) != length(fuzzy_match_landmark.dist)){
stop("fuzzy_match_landmark.min.word.length and fuzzy_match_landmark.dist must be the same length")
}
# Load Location Files --------------------------------------------------------
if(import_files){
landmark_gazetteer <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
roads <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "roads_augmented", "osm_roads_aug.Rds"))
neighborhoods <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "nairobi_estates", "nairobi_estates.Rds"))
} else{
landmark_gazetteer <- landmark_gazetteer_orig
}
# Extra Cleaning
landmark_gazetteer$name <- landmark_gazetteer$name %>% str_replace_all("[[:punct:]]", "")
roads$name <- roads$name %>% as.character %>% tolower
# Names into Lists
landmark_list <- landmark_gazetteer$name
roads_list <- roads$name %>% as.character %>% tolower
neighborhoods_list <- neighborhoods$estate
# Clean Prepositions List ----------------------------------------------------
tier_1_prepositions_startendword <- paste0("\\b",tier_1_prepositions,"\\b")
tier_2_prepositions_startendword <- paste0("\\b",tier_2_prepositions,"\\b")
tier_3_prepositions_startendword <- paste0("\\b",tier_3_prepositions,"\\b")
# Clean Tweet ------------------------------------------------------------------
tweet <- iconv(tweet, "latin1", "ASCII", sub="")
tweet <- tweet %>%
str_to_lower %>%
str_replace_all("\\br/about\\b", "round about") %>%
str_replace_all("\\.", " ") %>%
str_replace_all("via @[a-z_,A-Z_,0-9_]*", "") %>%
str_replace_all("\\@", "at ") %>% # "@cabanas, saying crash is at cabanas"
str_replace_all("@[a-z_,A-Z_,0-9_]*", "") %>%
str_replace_all(","," , ") %>% # Add space between commas (eg, "road,allsops")
str_replace_all("\n", "") %>%
str_replace_all("~", "") %>%
str_replace_all("\\b(http|https)://t.co/[0-9,A-Z, a-z]*\\b", "") %>%
str_replace_all("\\b(http|https)://t.co/[0-9,A-Z, a-z]", "") %>%
str_replace_all("\\b(http|https)://t.co\\b", "") %>%
str_replace_all("\\b(http|https):", "") %>%
str_replace_all("~more*", "") %>%
str_replace_all("(RT|rt) @[a-z,A-Z,0-9, _]*:", "") %>%
str_replace_all("^[0-9][0-9]\\:[0-9][0-9]", "") %>%
str_replace_all("[[:punct:]]", "") %>%
str_replace_all("\\bamp\\b", "and") %>%
# Replace words likely to trigger false positive
# Buses that include a landmark (ie, bus that primarily goes to that area)
# Could generalize: if "bus" after landmark, don't use.
str_replace_all("\\bgithurai bus\\b", "blankword blankword") %>%
str_replace_all("\\bgithurai matatu\\b", "blankword blankword") %>%
str_replace_all("\\bgithurai 45 bus\\b", "blankword blankword blankword") %>%
str_replace_all("\\bgithurai 45 matatu\\b", "blankword blankword blankword") %>%
str_replace_all("\\bcity hoppa bus\\b", "blankword blankword blankword") %>%
str_replace_all("\\bhoppa bus\\b", "blankword blankword") %>%
str_replace_all("\\brongai bus\\b", "blankword blankword") %>%
str_replace_all("\\brongai matatu\\b", "blankword blankword") %>%
str_replace_all("\\brongai matatus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos bus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos minibus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos matatu\\b", "blankword blankword") %>%
str_squish
# Locations in Tweet -----------------------------------------------------------
landmark_match <- phrase_in_sentence_exact(tweet, landmark_list)
road_match <- phrase_in_sentence_exact(tweet, roads_list)
neighborhood_match <- phrase_in_sentence_exact(tweet, neighborhoods_list)
if(fuzzy_match_landmark == TRUE){
landmark_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
landmark_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
landmark_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(landmark_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
road_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
road_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
roads_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(road_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
neighborhood_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
neighborhood_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
neighborhoods_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(neighborhood_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
# Remove fuzzy match if:
# (1) tweet spelling is one word and
# (2) tweet spelling is correctly spelled
if(nrow(landmark_match_fuzzy) > 0) landmark_match_fuzzy <- landmark_match_fuzzy[!((str_count(landmark_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(landmark_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(road_match_fuzzy) > 0) road_match_fuzzy <- road_match_fuzzy[!((str_count(road_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(road_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(neighborhood_match_fuzzy) > 0) neighborhood_match_fuzzy <- neighborhood_match_fuzzy[!((str_count(neighborhood_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(neighborhood_match_fuzzy$matched_words_tweet_spelling))),]
# Add fuzzy match to full match list
landmark_match <- bind_rows(landmark_match, landmark_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
road_match <- bind_rows(road_match, road_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
neighborhood_match <- bind_rows(neighborhood_match, neighborhood_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
}
df_out
# Test Geolocation Algorithm
# TODO: In classification, add "how_got_type" for how found -- so can see which one
# is more accurate; subset; etc.
# Spellign: severe --> seven? If word is already spelled correctly (eg, "called"), don't consider. Hmmmm might not work
# CLUSTER TRUTH TWEETS -- HOW MANY CRASHES ACTUALLY MISS
# Setup ------------------------------------------------------------------------
if(Sys.info()["user"] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()["user"] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
source(file.path(project_file_path, "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
library(pbmcapply)
INCORRECT_TWEETS <- FALSE
tweet <- "08:17 @danielnjorogeh their is a minor accident at spring valley via @willie50996679"
tweet <- "accident at githurai overpass please use service lane and rejoin highway after githurai stage"
tweet <- "05:15 accident at 411 kitengela namanga rd. nduthi and toyota wish via @lkiage"
tweet <- "accident at gardent city sf cd cid"
tweet <- "accident at green park estate on mombasa road"
tweet <- "accident near canadian embassy along limuru rd causing a heavy traffic snarl up... both in and out bound locked in traffic. no traffic police yet"
tweet <- "accident past yaya center near garden city"
tweet <- "accident past yaya center near garden city on thika rd"
tweet <- "08:06 multiple accidents on waiyaki way..at 87 and uthiru. via @8isaac5"
tweet <- "there is an accident words words at garden city near safari park on thika rd"
tweet <- "20:40 20:39 accident on mombasa rd. next to airtel. via @ochiengbonn\r\n just via @jacfar4661"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "a pedestrian has been knocked down at airtel msa rd. thats what is slowing traffic from gm"
tweet <- "10:27 accident on kiambu rd muthaiga after cid headquarters towards town.. recovery going on https://t.co/cprdjkfkm7 via @sal_gooh"
tweet <- "93 07:59 lorry overturn opposite alpha center apo cabanas causing jam but police on scene #trafficupdate via @gabu_don"
tweet <- "11:24 two accidents near mai mahiu town. traffic police on site @ntsa_kenya via @kenmoturi"
tweet <- "accident at blue post"
tweet <- "accident on mombasa rd just after belle vue out bound truck carrying glass cargo laying invite side and broken glass on road"
tweet <- "a certain mheshimiwa car has been hit @ the back under pangani footbridge. ...with sirens on....it's a scenery already."
tweet <- "at drive-inn (thika road). a driver of an exhauster truck loses control checking the guardrails. no serious injuries to pe sons bt to the vehicle itself. @kenhakenya https://t.co/j4raxybmsb"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "20:03 accident on thika road gsu depression tuvumiliane cops on it via @njugunastevens"
tweet <- "10:36 minor accident at the kangemi stage after the bridge heading to town via @zollynash"
tweet <- "accident at globe roundabout"
tweet <- "06:42 accident along kenyatta avenue opp 680 involving 3 vehicles! https://t.co/exz5sfsgvz via @munenewengwa"
tweet <- "accident along langata rd past 1824 an audi car"
tweet <- "accident at bypass and langata rd"
tweet <- "accident on valley road"
tweet <- "accident just outside 1824"
fuzzy_match_landmark <- TRUE
fuzzy_match_landmark.min.word.length <- c(5,11) # minimum word length for fuzzy match
fuzzy_match_landmark.dist <- c(1,2) # maximum levenstein distance to use
fuzzy_match_ngram_max <- 3
prepositions_list <- c("near", "at")
crash_words <- c("accidents", "accident", "crash", "overturn", "collision", "wreck") # hit?
junction_words <- c("intersection", "junction")
first_letters_same <- TRUE
last_letters_same <- TRUE # !!!!!!!! fails for roysambo/u. Maybe: if 1 letter off, only first letter needs to be same. But be more restrictive with 2?
import_files <- FALSE
tier_1_prepositions <- c("at", "next to","around", "just after", "opposite","opp", "apa", "hapa","happened at","just before","at the","outside")
tier_2_prepositions <- c("near", "after", "toward","along", "towards")
tier_3_prepositions <- c("past","from","on")
# Import
landmark_gazetteer_orig <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
roads <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "roads_augmented", "osm_roads_aug.Rds"))
neighborhoods <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "nairobi_estates", "nairobi_estates.Rds"))
locate_crash(tweet)
neighborhoods
roads
n_end
print(tweet)
# Checks ---------------------------------------------------------------------
if(length(fuzzy_match_landmark.min.word.length) != length(fuzzy_match_landmark.dist)){
stop("fuzzy_match_landmark.min.word.length and fuzzy_match_landmark.dist must be the same length")
}
# Load Location Files --------------------------------------------------------
if(import_files){
landmark_gazetteer <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
roads <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "roads_augmented", "osm_roads_aug.Rds"))
neighborhoods <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "nairobi_estates", "nairobi_estates.Rds"))
} else{
landmark_gazetteer <- landmark_gazetteer_orig
}
# Extra Cleaning
landmark_gazetteer$name <- landmark_gazetteer$name %>% str_replace_all("[[:punct:]]", "")
roads$name <- roads$name %>% as.character %>% tolower
# Names into Lists
landmark_list <- landmark_gazetteer$name
roads_list <- roads$name %>% as.character %>% tolower
neighborhoods_list <- neighborhoods$estate
# Clean Prepositions List ----------------------------------------------------
tier_1_prepositions_startendword <- paste0("\\b",tier_1_prepositions,"\\b")
tier_2_prepositions_startendword <- paste0("\\b",tier_2_prepositions,"\\b")
tier_3_prepositions_startendword <- paste0("\\b",tier_3_prepositions,"\\b")
# Clean Tweet ------------------------------------------------------------------
tweet <- iconv(tweet, "latin1", "ASCII", sub="")
tweet <- tweet %>%
str_to_lower %>%
str_replace_all("\\br/about\\b", "round about") %>%
str_replace_all("\\.", " ") %>%
str_replace_all("via @[a-z_,A-Z_,0-9_]*", "") %>%
str_replace_all("\\@", "at ") %>% # "@cabanas, saying crash is at cabanas"
str_replace_all("@[a-z_,A-Z_,0-9_]*", "") %>%
str_replace_all(","," , ") %>% # Add space between commas (eg, "road,allsops")
str_replace_all("\n", "") %>%
str_replace_all("~", "") %>%
str_replace_all("\\b(http|https)://t.co/[0-9,A-Z, a-z]*\\b", "") %>%
str_replace_all("\\b(http|https)://t.co/[0-9,A-Z, a-z]", "") %>%
str_replace_all("\\b(http|https)://t.co\\b", "") %>%
str_replace_all("\\b(http|https):", "") %>%
str_replace_all("~more*", "") %>%
str_replace_all("(RT|rt) @[a-z,A-Z,0-9, _]*:", "") %>%
str_replace_all("^[0-9][0-9]\\:[0-9][0-9]", "") %>%
str_replace_all("[[:punct:]]", "") %>%
str_replace_all("\\bamp\\b", "and") %>%
# Replace words likely to trigger false positive
# Buses that include a landmark (ie, bus that primarily goes to that area)
# Could generalize: if "bus" after landmark, don't use.
str_replace_all("\\bgithurai bus\\b", "blankword blankword") %>%
str_replace_all("\\bgithurai matatu\\b", "blankword blankword") %>%
str_replace_all("\\bgithurai 45 bus\\b", "blankword blankword blankword") %>%
str_replace_all("\\bgithurai 45 matatu\\b", "blankword blankword blankword") %>%
str_replace_all("\\bcity hoppa bus\\b", "blankword blankword blankword") %>%
str_replace_all("\\bhoppa bus\\b", "blankword blankword") %>%
str_replace_all("\\brongai bus\\b", "blankword blankword") %>%
str_replace_all("\\brongai matatu\\b", "blankword blankword") %>%
str_replace_all("\\brongai matatus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos bus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos minibus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos matatu\\b", "blankword blankword") %>%
str_squish
# Locations in Tweet -----------------------------------------------------------
landmark_match <- phrase_in_sentence_exact(tweet, landmark_list)
road_match <- phrase_in_sentence_exact(tweet, roads_list)
neighborhood_match <- phrase_in_sentence_exact(tweet, neighborhoods_list)
if(fuzzy_match_landmark == TRUE){
landmark_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
landmark_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
landmark_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(landmark_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
road_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
road_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
roads_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(road_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
neighborhood_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
neighborhood_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
neighborhoods_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(neighborhood_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
# Remove fuzzy match if:
# (1) tweet spelling is one word and
# (2) tweet spelling is correctly spelled
if(nrow(landmark_match_fuzzy) > 0) landmark_match_fuzzy <- landmark_match_fuzzy[!((str_count(landmark_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(landmark_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(road_match_fuzzy) > 0) road_match_fuzzy <- road_match_fuzzy[!((str_count(road_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(road_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(neighborhood_match_fuzzy) > 0) neighborhood_match_fuzzy <- neighborhood_match_fuzzy[!((str_count(neighborhood_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(neighborhood_match_fuzzy$matched_words_tweet_spelling))),]
# Add fuzzy match to full match list
landmark_match <- bind_rows(landmark_match, landmark_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
road_match <- bind_rows(road_match, road_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
neighborhood_match <- bind_rows(neighborhood_match, neighborhood_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
}
if(nrow(landmark_match) > 0) landmark_match$location_type <- "landmark"
if(nrow(road_match) > 0) road_match$location_type <- "road"
if(nrow(neighborhood_match) > 0) neighborhood_match$location_type <- "neighborhood"
locations_in_tweet <- bind_rows(landmark_match, road_match, neighborhood_match)
# Choosing which landmarks to use --------------------------------------------
df_out <- data.frame(matrix(nrow=1,ncol=0))
# Locations of Words in Tweet --------------------------------------------------
#### Locations (landmark, roads, neighborhood)
word_locations <- lapply(as.character(locations_in_tweet$matched_words_tweet_spelling), phrase_locate, tweet) %>% bind_rows
locations_in_tweet <- merge(locations_in_tweet, word_locations, by.x="matched_words_tweet_spelling", by.y="word")
#### Other word types
crash_word_locations <- lapply(crash_words, phrase_locate, tweet) %>% bind_rows
preposition_word_locations <- lapply(prepositions_list, phrase_locate, tweet) %>% bind_rows
locations_in_tweet_original <- locations_in_tweet
landmark_match_general <- merge(landmark_match, landmark_gazetteer, by.x="matched_words_correct_spelling", by.y="name", all.x=T, all.y=F)
# If there are any general landmarks
if("general" %in% landmark_match_general$general_specific){
landmark_match_general <- landmark_match_general[landmark_match_general$general_specific %in% "general",]
# If there are roads
if(nrow(road_match) > 0){
# Add distance to road to general landmarks
coordinates(landmark_match_general) <- ~lon+lat
crs(landmark_match_general) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
roads_in_tweet <- roads[roads$name %in% road_match$matched_words_correct_spelling,]
roads_in_tweet$id <- 1
roads_in_tweet <- raster::aggregate(roads_in_tweet, by="id")
landmark_match_general$distance_to_road <- as.numeric(gDistance(landmark_match_general, roads_in_tweet, byid = T)) * 111.12
# (1) List of general landmarks far from a road; (2) remove these
landmark_match_general <- landmark_match_general[landmark_match_general$distance_to_road >= 0.5,]
landmark_match <- landmark_match[!(landmark_match$matched_words_tweet_spelling %in% landmark_match_general$matched_words_tweet_spelling),]
# If there are no roads, remove general landmarks
} else{
landmark_gazetteer <- landmark_gazetteer[!(landmark_gazetteer$general_specific %in% "general"),]
landmark_match_temp <- landmark_match[landmark_match$matched_words_correct_spelling %in% landmark_gazetteer$name,]
if(nrow(landmark_match_temp) > 0){
landmark_match <- landmark_match_temp
locations_in_tweet <- locations_in_tweet[(locations_in_tweet$matched_words_correct_spelling %in% landmark_gazetteer$name) |
!(locations_in_tweet$location_type %in% "landmark"),]
}
#landmark_match <- landmark_match[!(landmark_match$matched_words_tweet_spelling %in% landmark_match_general$matched_words_tweet_spelling),]
}
}
# Locations in Tweet -----------------------------------------------------------
landmark_match <- phrase_in_sentence_exact(tweet, landmark_list)
road_match <- phrase_in_sentence_exact(tweet, roads_list)
neighborhood_match <- phrase_in_sentence_exact(tweet, neighborhoods_list)
if(fuzzy_match_landmark == TRUE){
landmark_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
landmark_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
landmark_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(landmark_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
road_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
road_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
roads_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(road_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
neighborhood_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
neighborhood_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
neighborhoods_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(neighborhood_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
# Remove fuzzy match if:
# (1) tweet spelling is one word and
# (2) tweet spelling is correctly spelled
if(nrow(landmark_match_fuzzy) > 0) landmark_match_fuzzy <- landmark_match_fuzzy[!((str_count(landmark_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(landmark_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(road_match_fuzzy) > 0) road_match_fuzzy <- road_match_fuzzy[!((str_count(road_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(road_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(neighborhood_match_fuzzy) > 0) neighborhood_match_fuzzy <- neighborhood_match_fuzzy[!((str_count(neighborhood_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(neighborhood_match_fuzzy$matched_words_tweet_spelling))),]
# Add fuzzy match to full match list
landmark_match <- bind_rows(landmark_match, landmark_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
road_match <- bind_rows(road_match, road_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
neighborhood_match <- bind_rows(neighborhood_match, neighborhood_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
}
if(nrow(landmark_match) > 0) landmark_match$location_type <- "landmark"
if(nrow(road_match) > 0) road_match$location_type <- "road"
if(nrow(neighborhood_match) > 0) neighborhood_match$location_type <- "neighborhood"
locations_in_tweet <- bind_rows(landmark_match, road_match, neighborhood_match)
# Choosing which landmarks to use --------------------------------------------
df_out <- data.frame(matrix(nrow=1,ncol=0))
locations_in_tweet
tweet
tier_1_prepositions
tier_1_prepositions
tier_1_prepositions_regex
# Grab Landmarks After Prepositions ------------------------------------------
tweet
# Grab Landmarks After Prepositions ------------------------------------------
tweet
phrase_in_sentence_exact(tier_1_prepositions, tweet)
phrase_in_sentence_exact
phrase_in_sentence_exact(tweet, tier_1_prepositions)
# Grab Landmarks After Prepositions ------------------------------------------
tier_1_prepositions_in_tweet <- phrase_in_sentence_exact(tweet, tier_1_prepositions)
tier_1_prepositions_in_tweet
word_locations <- lapply(as.character(tier_1_prepositions_in_tweet$matched_words_tweet_spelling), phrase_locate, tweet) %>% bind_rows
word_locations
tier_1_prepositions_locations <- lapply(as.character(tier_1_prepositions_in_tweet$matched_words_tweet_spelling), phrase_locate, tweet) %>% bind_rows
tier_1_prepositions_locations
tier_1_prepositions_locations <- lapply(as.character(tier_1_prepositions_in_tweet$matched_words_tweet_spelling), phrase_locate, tweet) %>% bind_rows
word(tweet)
word(tweet,4)
tweet_no_stopwords <- tweet %>% str_replace_all("the", " ") %>% str_squish
tweet_no_stopwords
# Grab Landmarks After Prepositions ------------------------------------------
tweet_no_stopwords <- tweet %>% str_replace_all("the", " ") %>% str_squish
tier_1_prepositions_in_tweet <- phrase_in_sentence_exact(tweet_no_stopwords, tier_1_prepositions)
tier_1_prepositions_locations <- lapply(as.character(tier_1_prepositions_in_tweet$matched_words_tweet_spelling), phrase_locate, tweet_no_stopwords) %>% bind_rows
tier_1_prepositions_in_tweet
# Test Geolocation Algorithm
# TODO: In classification, add "how_got_type" for how found -- so can see which one
# is more accurate; subset; etc.
# Spellign: severe --> seven? If word is already spelled correctly (eg, "called"), don't consider. Hmmmm might not work
# CLUSTER TRUTH TWEETS -- HOW MANY CRASHES ACTUALLY MISS
# Setup ------------------------------------------------------------------------
if(Sys.info()["user"] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()["user"] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
source(file.path(project_file_path, "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
library(pbmcapply)
INCORRECT_TWEETS <- FALSE
tweet <- "08:17 @danielnjorogeh their is a minor accident at spring valley via @willie50996679"
tweet <- "accident at githurai overpass please use service lane and rejoin highway after githurai stage"
tweet <- "05:15 accident at 411 kitengela namanga rd. nduthi and toyota wish via @lkiage"
tweet <- "accident at gardent city sf cd cid"
tweet <- "accident at green park estate on mombasa road"
tweet <- "accident near canadian embassy along limuru rd causing a heavy traffic snarl up... both in and out bound locked in traffic. no traffic police yet"
tweet <- "accident past yaya center near garden city"
tweet <- "accident past yaya center near garden city on thika rd"
tweet <- "08:06 multiple accidents on waiyaki way..at 87 and uthiru. via @8isaac5"
tweet <- "there is an accident words words at garden city near safari park on thika rd"
tweet <- "20:40 20:39 accident on mombasa rd. next to airtel. via @ochiengbonn\r\n just via @jacfar4661"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "a pedestrian has been knocked down at airtel msa rd. thats what is slowing traffic from gm"
tweet <- "10:27 accident on kiambu rd muthaiga after cid headquarters towards town.. recovery going on https://t.co/cprdjkfkm7 via @sal_gooh"
tweet <- "93 07:59 lorry overturn opposite alpha center apo cabanas causing jam but police on scene #trafficupdate via @gabu_don"
tweet <- "11:24 two accidents near mai mahiu town. traffic police on site @ntsa_kenya via @kenmoturi"
tweet <- "accident at blue post"
tweet <- "accident on mombasa rd just after belle vue out bound truck carrying glass cargo laying invite side and broken glass on road"
tweet <- "a certain mheshimiwa car has been hit @ the back under pangani footbridge. ...with sirens on....it's a scenery already."
tweet <- "at drive-inn (thika road). a driver of an exhauster truck loses control checking the guardrails. no serious injuries to pe sons bt to the vehicle itself. @kenhakenya https://t.co/j4raxybmsb"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "20:03 accident on thika road gsu depression tuvumiliane cops on it via @njugunastevens"
tweet <- "10:36 minor accident at the kangemi stage after the bridge heading to town via @zollynash"
tweet <- "accident at globe roundabout"
tweet <- "06:42 accident along kenyatta avenue opp 680 involving 3 vehicles! https://t.co/exz5sfsgvz via @munenewengwa"
tweet <- "accident along langata rd past 1824 an audi car"
tweet <- "accident at bypass and langata rd"
tweet <- "accident on valley road"
tweet <- "accident just outside 1824"
tweet <- "20:36 @npsofficial_ke accident on msa rd at airport junction overpass, cycler dead, 3vehicl~more â????¢ https://t.co/c1f1d6lflo via @ryan_mucilih"
tweet <- "a certain mheshimiwa car has been hit @ the back under pangani footbridge. ...with sirens on....it's a scenery already."
tweet <- "minor accident on brookside drive towards lower kabete road"
tweet <- "12:09 several heavy trucks accidents all between daystar university jun~more â????¢ https://t.co/kd0tjqhlsp https://t.co/fp7mqwpoja via @mwolooto"
fuzzy_match_landmark <- TRUE
fuzzy_match_landmark.min.word.length <- c(5,11) # minimum word length for fuzzy match
fuzzy_match_landmark.dist <- c(1,2) # maximum levenstein distance to use
fuzzy_match_ngram_max <- 3
prepositions_list <- c("near", "at")
crash_words <- c("accidents", "accident", "crash", "overturn", "collision", "wreck") # hit?
junction_words <- c("intersection", "junction")
first_letters_same <- TRUE
last_letters_same <- TRUE # !!!!!!!! fails for roysambo/u. Maybe: if 1 letter off, only first letter needs to be same. But be more restrictive with 2?
import_files <- FALSE
tier_1_prepositions <- c("at", "next to","around", "just after", "opposite","opp", "apa", "hapa","happened at","just before","at the","outside")
tier_2_prepositions <- c("near", "after", "toward","along", "towards")
tier_3_prepositions <- c("past","from","on")
# Import
landmark_gazetteer_orig <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
roads <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "roads_augmented", "osm_roads_aug.Rds"))
neighborhoods <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "nairobi_estates", "nairobi_estates.Rds"))
locate_crash("10:27 accident on kiambu rd muthaiga after cid headquarters towards town.. recovery going on https://t.co/cprdjkfkm7 via @sal_gooh")
