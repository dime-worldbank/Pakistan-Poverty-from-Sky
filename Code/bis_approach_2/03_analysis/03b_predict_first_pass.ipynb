{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict household income from satellite imagery data\n",
    "\n",
    "First pass.\n",
    "\n",
    "General ML pipeline steps:\n",
    "1. Import data\n",
    "2. Split data into test/train sets\n",
    "3. Preprocess test/train sets separately\n",
    "4. Generate features from data\n",
    "5. For each regressor-hyperparameter combination:\n",
    "    - Train regressor with given hyperparameters and training data and labels\n",
    "    - Generate predicted labels for test data with trained regressor\n",
    "    - Evaluate regressor-hyperparameter performance against actual test labels and get $R^2$\n",
    "6. Explore best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import configuration file\n",
    "import config as cf\n",
    "\n",
    "# Display options \n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = -1\n",
    "\n",
    "# Turn off big pink warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data file path \n",
    "final_data_file_path = \"/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/FinalData\"\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test grid to make sure everything works - limited models and parameters\n",
    "GRID_TEST_CLASS = {\n",
    "    'regressors': ['LinearSVC','DecisionTreeClassifier', 'BaggingClassifier',\n",
    "                    'GradientBoostingClassifier', 'RandomForestClassifier'],\n",
    "    'LinearSVC': [\n",
    "        {'penalty': penalty, 'C': C, 'loss': loss, 'max_iter': max_iter,\n",
    "        'random_state': 0} \\\n",
    "        for penalty in ('l2', ) \\\n",
    "        for C in (1e-2, 1e2) \\\n",
    "        for loss in ('epsilon_insensitive', ) \\\n",
    "        for max_iter in (1e3, 1e5)\n",
    "    ],\n",
    "    'DecisionTreeClassifier': [\n",
    "        {'criterion': criterion, 'splitter': splitter, 'max_depth': max_depth,\n",
    "        'max_features': max_features, 'random_state': 0} \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for splitter in ('best', ) \\\n",
    "        for max_depth in (1, 5, 10, 20, 30) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ],\n",
    "    'BaggingClassifier': [\n",
    "        {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "        'random_state': 0, 'n_jobs': -1} \\\n",
    "        for n_estimators in (100, 1000, 10000) \\\n",
    "        for max_features in (0.3, 0.5, 1.0)\n",
    "    ],\n",
    "    'GradientBoostingClassifier': [\n",
    "        {'loss': loss, 'learning_rate': rate, 'n_estimators': n_estimators,\n",
    "        'criterion': criterion, 'max_features': max_features,\n",
    "        'random_state': 0} \\\n",
    "        for loss in ('deviance', ) \\\n",
    "        for rate in (1e-4, )\n",
    "        for n_estimators in (100, ) \\\n",
    "        for criterion in ('friedman_mse', ) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ],\n",
    "    'RandomForestClassifier': [\n",
    "        {'n_estimators': n_estimators, 'criterion': criterion,\n",
    "        'max_depth': max_depth, 'max_features': max_features, 'n_jobs': -1,\n",
    "        'random_state': 0} \\\n",
    "        for n_estimators in (10, 100, 1000) \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for max_depth in (1, ) \\\n",
    "        for max_features in ('sqrt', )\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data and drop \"future\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5416, 46)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(final_data_file_path, 'Outputs for Analysis TEMP', 'bisp_sat_inc_data.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>viirs_2013</th>\n",
       "      <th>viirs_2014</th>\n",
       "      <th>viirs_2015</th>\n",
       "      <th>viirs_2016</th>\n",
       "      <th>viirs_2017</th>\n",
       "      <th>viirs_2018</th>\n",
       "      <th>dmspols_1992</th>\n",
       "      <th>dmspols_1993</th>\n",
       "      <th>dmspols_1994</th>\n",
       "      <th>dmspols_1995</th>\n",
       "      <th>dmspols_1996</th>\n",
       "      <th>dmspols_1997</th>\n",
       "      <th>dmspols_1998</th>\n",
       "      <th>dmspols_1999</th>\n",
       "      <th>dmspols_2000</th>\n",
       "      <th>dmspols_2001</th>\n",
       "      <th>dmspols_2002</th>\n",
       "      <th>dmspols_2003</th>\n",
       "      <th>dmspols_2004</th>\n",
       "      <th>dmspols_2005</th>\n",
       "      <th>dmspols_2006</th>\n",
       "      <th>dmspols_2007</th>\n",
       "      <th>dmspols_2008</th>\n",
       "      <th>dmspols_2009</th>\n",
       "      <th>dmspols_2010</th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>dmspols_2012</th>\n",
       "      <th>dmspols_2013</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>l7_2013_1</th>\n",
       "      <th>l7_2013_2</th>\n",
       "      <th>l7_2013_3</th>\n",
       "      <th>l7_2013_4</th>\n",
       "      <th>l7_2013_5</th>\n",
       "      <th>l7_2013_6</th>\n",
       "      <th>l7_2013_7</th>\n",
       "      <th>hhinc_2011</th>\n",
       "      <th>hhinc_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100389</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>2.141392</td>\n",
       "      <td>2.089507</td>\n",
       "      <td>2.307763</td>\n",
       "      <td>2.850603</td>\n",
       "      <td>3.653005</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>902.331348</td>\n",
       "      <td>1224.739396</td>\n",
       "      <td>1393.123911</td>\n",
       "      <td>2555.792708</td>\n",
       "      <td>2474.174317</td>\n",
       "      <td>3005.856769</td>\n",
       "      <td>1922.539802</td>\n",
       "      <td>951.897734</td>\n",
       "      <td>1282.748257</td>\n",
       "      <td>1417.251598</td>\n",
       "      <td>2574.000436</td>\n",
       "      <td>2469.137711</td>\n",
       "      <td>3000.408919</td>\n",
       "      <td>1889.609384</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>73000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100401</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>2.133366</td>\n",
       "      <td>2.052437</td>\n",
       "      <td>2.296554</td>\n",
       "      <td>2.769960</td>\n",
       "      <td>3.702374</td>\n",
       "      <td>3.488333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>885.841488</td>\n",
       "      <td>1200.548350</td>\n",
       "      <td>1366.253764</td>\n",
       "      <td>2512.672843</td>\n",
       "      <td>2451.849595</td>\n",
       "      <td>3004.616242</td>\n",
       "      <td>1890.566155</td>\n",
       "      <td>941.063694</td>\n",
       "      <td>1268.392009</td>\n",
       "      <td>1402.777070</td>\n",
       "      <td>2547.212362</td>\n",
       "      <td>2463.117111</td>\n",
       "      <td>2998.701940</td>\n",
       "      <td>1876.871453</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>159000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100581</td>\n",
       "      <td>1.824753</td>\n",
       "      <td>1.937131</td>\n",
       "      <td>1.875487</td>\n",
       "      <td>2.047540</td>\n",
       "      <td>2.557241</td>\n",
       "      <td>3.198625</td>\n",
       "      <td>3.286000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>34.25</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>38.25</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>37.750000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.75</td>\n",
       "      <td>33.75</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.75</td>\n",
       "      <td>42.5</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>45.5</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>886.021385</td>\n",
       "      <td>1206.745127</td>\n",
       "      <td>1373.031277</td>\n",
       "      <td>2550.999418</td>\n",
       "      <td>2462.909660</td>\n",
       "      <td>3006.164678</td>\n",
       "      <td>1900.649840</td>\n",
       "      <td>935.162060</td>\n",
       "      <td>1263.157696</td>\n",
       "      <td>1398.079866</td>\n",
       "      <td>2572.847832</td>\n",
       "      <td>2458.750073</td>\n",
       "      <td>2999.056008</td>\n",
       "      <td>1880.909223</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101101</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>2.133366</td>\n",
       "      <td>2.052437</td>\n",
       "      <td>2.296554</td>\n",
       "      <td>2.769960</td>\n",
       "      <td>3.702374</td>\n",
       "      <td>3.488333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>886.196798</td>\n",
       "      <td>1201.037263</td>\n",
       "      <td>1366.468559</td>\n",
       "      <td>2514.479913</td>\n",
       "      <td>2450.865939</td>\n",
       "      <td>3004.699563</td>\n",
       "      <td>1890.108734</td>\n",
       "      <td>940.979913</td>\n",
       "      <td>1268.248763</td>\n",
       "      <td>1401.871616</td>\n",
       "      <td>2547.740466</td>\n",
       "      <td>2459.946143</td>\n",
       "      <td>2998.786463</td>\n",
       "      <td>1874.074672</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>219000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101236</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>2.141392</td>\n",
       "      <td>2.089507</td>\n",
       "      <td>2.307763</td>\n",
       "      <td>2.850603</td>\n",
       "      <td>3.653005</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>891.264553</td>\n",
       "      <td>1209.613090</td>\n",
       "      <td>1374.709528</td>\n",
       "      <td>2535.919345</td>\n",
       "      <td>2453.881552</td>\n",
       "      <td>3005.134086</td>\n",
       "      <td>1897.493484</td>\n",
       "      <td>943.113959</td>\n",
       "      <td>1271.824645</td>\n",
       "      <td>1403.386186</td>\n",
       "      <td>2563.689111</td>\n",
       "      <td>2453.279467</td>\n",
       "      <td>2999.725311</td>\n",
       "      <td>1869.047929</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  viirs_2012  viirs_2013  viirs_2014  viirs_2015  viirs_2016  \\\n",
       "0  100389  2.052018    2.141392    2.089507    2.307763    2.850603     \n",
       "1  100401  1.964332    2.133366    2.052437    2.296554    2.769960     \n",
       "2  100581  1.824753    1.937131    1.875487    2.047540    2.557241     \n",
       "3  101101  1.964332    2.133366    2.052437    2.296554    2.769960     \n",
       "4  101236  2.052018    2.141392    2.089507    2.307763    2.850603     \n",
       "\n",
       "   viirs_2017  viirs_2018  dmspols_1992  dmspols_1993  dmspols_1994  \\\n",
       "0  3.653005    3.750000    43.0          33.666667     35.50          \n",
       "1  3.702374    3.488333    43.0          33.666667     35.50          \n",
       "2  3.198625    3.286000    43.0          32.500000     34.25          \n",
       "3  3.702374    3.488333    43.0          33.666667     35.50          \n",
       "4  3.653005    3.750000    43.0          33.666667     35.50          \n",
       "\n",
       "   dmspols_1995  dmspols_1996  dmspols_1997  dmspols_1998  dmspols_1999  \\\n",
       "0  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "1  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "2  43.000000     38.0          31.750000     38.25         38.750000      \n",
       "3  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "4  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "\n",
       "   dmspols_2000  dmspols_2001  dmspols_2002  dmspols_2003  dmspols_2004  \\\n",
       "0  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "1  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "2  36.000000     38.250000     37.750000     32.000000     32.75          \n",
       "3  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "4  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "\n",
       "   dmspols_2005  dmspols_2006  dmspols_2007  dmspols_2008  dmspols_2009  \\\n",
       "0  34.50         40.666667     45.00         43.0          30.333333      \n",
       "1  34.50         40.666667     45.00         43.0          30.333333      \n",
       "2  33.75         40.000000     43.75         42.5          30.000000      \n",
       "3  34.50         40.666667     45.00         43.0          30.333333      \n",
       "4  34.50         40.666667     45.00         43.0          30.333333      \n",
       "\n",
       "   dmspols_2010  dmspols_2011  dmspols_2012  dmspols_2013   l7_2011_1  \\\n",
       "0  46.0          32.666667     47.666667     45.333333     902.331348   \n",
       "1  46.0          32.666667     47.666667     45.333333     885.841488   \n",
       "2  45.5          30.500000     47.500000     44.500000     886.021385   \n",
       "3  46.0          32.666667     47.666667     45.333333     886.196798   \n",
       "4  46.0          32.666667     47.666667     45.333333     891.264553   \n",
       "\n",
       "     l7_2011_2    l7_2011_3    l7_2011_4    l7_2011_5    l7_2011_6  \\\n",
       "0  1224.739396  1393.123911  2555.792708  2474.174317  3005.856769   \n",
       "1  1200.548350  1366.253764  2512.672843  2451.849595  3004.616242   \n",
       "2  1206.745127  1373.031277  2550.999418  2462.909660  3006.164678   \n",
       "3  1201.037263  1366.468559  2514.479913  2450.865939  3004.699563   \n",
       "4  1209.613090  1374.709528  2535.919345  2453.881552  3005.134086   \n",
       "\n",
       "     l7_2011_7   l7_2013_1    l7_2013_2    l7_2013_3    l7_2013_4  \\\n",
       "0  1922.539802  951.897734  1282.748257  1417.251598  2574.000436   \n",
       "1  1890.566155  941.063694  1268.392009  1402.777070  2547.212362   \n",
       "2  1900.649840  935.162060  1263.157696  1398.079866  2572.847832   \n",
       "3  1890.108734  940.979913  1268.248763  1401.871616  2547.740466   \n",
       "4  1897.493484  943.113959  1271.824645  1403.386186  2563.689111   \n",
       "\n",
       "     l7_2013_5    l7_2013_6    l7_2013_7  hhinc_2011  hhinc_2013  \n",
       "0  2469.137711  3000.408919  1889.609384  9000.0      73000.0     \n",
       "1  2463.117111  2998.701940  1876.871453  75000.0     159000.0    \n",
       "2  2458.750073  2999.056008  1880.909223  48000.0     0.0         \n",
       "3  2459.946143  2998.786463  1874.074672  31200.0     219000.0    \n",
       "4  2453.279467  2999.725311  1869.047929  14000.0    NaN          "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NAs\n",
    "df = df.loc[(df['hhinc_2011'] >= 0)]\n",
    "df = df.loc[(df['hhinc_2011'] <= 20000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1663\n",
       "1    1613\n",
       "2    1590\n",
       "Name: hhinc_2011, dtype: int64"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DV as Quantiles\n",
    "df['hhinc_2011'] = pd.qcut(df['hhinc_2011'], 3, labels=False)\n",
    "df['hhinc_2011'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>hhinc_2011</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>902.331348</td>\n",
       "      <td>1224.739396</td>\n",
       "      <td>1393.123911</td>\n",
       "      <td>2555.792708</td>\n",
       "      <td>2474.174317</td>\n",
       "      <td>3005.856769</td>\n",
       "      <td>1922.539802</td>\n",
       "      <td>0</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>100389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>885.841488</td>\n",
       "      <td>1200.548350</td>\n",
       "      <td>1366.253764</td>\n",
       "      <td>2512.672843</td>\n",
       "      <td>2451.849595</td>\n",
       "      <td>3004.616242</td>\n",
       "      <td>1890.566155</td>\n",
       "      <td>1</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>100401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.500000</td>\n",
       "      <td>886.021385</td>\n",
       "      <td>1206.745127</td>\n",
       "      <td>1373.031277</td>\n",
       "      <td>2550.999418</td>\n",
       "      <td>2462.909660</td>\n",
       "      <td>3006.164678</td>\n",
       "      <td>1900.649840</td>\n",
       "      <td>1</td>\n",
       "      <td>1.824753</td>\n",
       "      <td>100581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>886.196798</td>\n",
       "      <td>1201.037263</td>\n",
       "      <td>1366.468559</td>\n",
       "      <td>2514.479913</td>\n",
       "      <td>2450.865939</td>\n",
       "      <td>3004.699563</td>\n",
       "      <td>1890.108734</td>\n",
       "      <td>0</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>101101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>891.264553</td>\n",
       "      <td>1209.613090</td>\n",
       "      <td>1374.709528</td>\n",
       "      <td>2535.919345</td>\n",
       "      <td>2453.881552</td>\n",
       "      <td>3005.134086</td>\n",
       "      <td>1897.493484</td>\n",
       "      <td>0</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>101236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dmspols_2011   l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "0  32.666667     902.331348  1224.739396  1393.123911  2555.792708   \n",
       "1  32.666667     885.841488  1200.548350  1366.253764  2512.672843   \n",
       "2  30.500000     886.021385  1206.745127  1373.031277  2550.999418   \n",
       "3  32.666667     886.196798  1201.037263  1366.468559  2514.479913   \n",
       "4  32.666667     891.264553  1209.613090  1374.709528  2535.919345   \n",
       "\n",
       "     l7_2011_5    l7_2011_6    l7_2011_7  hhinc_2011  viirs_2012     uid  \n",
       "0  2474.174317  3005.856769  1922.539802  0           2.052018    100389  \n",
       "1  2451.849595  3004.616242  1890.566155  1           1.964332    100401  \n",
       "2  2462.909660  3006.164678  1900.649840  1           1.824753    100581  \n",
       "3  2450.865939  3004.699563  1890.108734  0           1.964332    101101  \n",
       "4  2453.881552  3005.134086  1897.493484  0           2.052018    101236  "
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only 2011 columns, but include viirs_2012\n",
    "df = df.filter(regex='_2011', axis=1).join(df[['viirs_2012','uid']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4866, 11)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns where the label is missing\n",
    "df = df.loc[~pd.isnull(df['hhinc_2011'])]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'hhinc_2011'\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "# Separate feature sets from label sets\n",
    "x_df = df.drop(labels=[LABEL], axis=1)\n",
    "y_df = df[LABEL]\n",
    "\n",
    "# Split into test and train sets for features and labels\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x_df, y_df, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess data\n",
    "\n",
    "All vars are numeric - impute missing data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FEATURES MISSING:\n",
      "dmspols_2011    34\n",
      "l7_2011_1       0 \n",
      "l7_2011_2       0 \n",
      "l7_2011_3       0 \n",
      "l7_2011_4       0 \n",
      "l7_2011_5       0 \n",
      "l7_2011_6       0 \n",
      "l7_2011_7       0 \n",
      "viirs_2012      34\n",
      "uid             0 \n",
      "dtype: int64\n",
      "\n",
      "TEST FEATURES MISSING:\n",
      "dmspols_2011    18\n",
      "l7_2011_1       0 \n",
      "l7_2011_2       0 \n",
      "l7_2011_3       0 \n",
      "l7_2011_4       0 \n",
      "l7_2011_5       0 \n",
      "l7_2011_6       0 \n",
      "l7_2011_7       0 \n",
      "viirs_2012      18\n",
      "uid             0 \n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows are missing across columns\n",
    "print(\"TRAINING FEATURES MISSING:\")\n",
    "print(pd.isnull(x_train).sum())\n",
    "print(\"\")\n",
    "print(\"TEST FEATURES MISSING:\")\n",
    "print(pd.isnull(x_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (x_train, x_test):\n",
    "    for j in i.columns:\n",
    "        \n",
    "        if i[j].isnull().sum():\n",
    "            # Create imputed flag\n",
    "            new_name = i[j].name + '_imputed'\n",
    "            i[new_name] = pd.isnull(i[j]).astype('int')\n",
    "            # Fill with mean\n",
    "            i[j] = i[j].fillna(i[j].mean())\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FEATURES MISSING:\n",
      "dmspols_2011            0\n",
      "l7_2011_1               0\n",
      "l7_2011_2               0\n",
      "l7_2011_3               0\n",
      "l7_2011_4               0\n",
      "l7_2011_5               0\n",
      "l7_2011_6               0\n",
      "l7_2011_7               0\n",
      "viirs_2012              0\n",
      "uid                     0\n",
      "dmspols_2011_imputed    0\n",
      "viirs_2012_imputed      0\n",
      "dtype: int64\n",
      "\n",
      "TEST FEATURES MISSING:\n",
      "dmspols_2011            0\n",
      "l7_2011_1               0\n",
      "l7_2011_2               0\n",
      "l7_2011_3               0\n",
      "l7_2011_4               0\n",
      "l7_2011_5               0\n",
      "l7_2011_6               0\n",
      "l7_2011_7               0\n",
      "viirs_2012              0\n",
      "uid                     0\n",
      "dmspols_2011_imputed    0\n",
      "viirs_2012_imputed      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# All missing values were imputed\n",
    "print(\"TRAINING FEATURES MISSING:\")\n",
    "print(pd.isnull(x_train).sum())\n",
    "print(\"\")\n",
    "print(\"TEST FEATURES MISSING:\")\n",
    "print(pd.isnull(x_test).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Generation\n",
    "\n",
    "[Landsat 7 specs](https://landsat.usgs.gov/sites/default/files/documents/si_product_guide.pdf#page=14)\n",
    "\n",
    "Create indices from every possible pair of Landsat 7 band.\n",
    "- Normalized Difference Vegetation Index, NDVI = $\\frac{NIR - Red}{NIR + Red}$ is formed from the (NIR, Red) pair.\n",
    "- Normalized Difference Built-up Index, NDBI = $\\frac{SWIR1 - NIR}{SWIR1 + NIR}$ is formed from the (NIR, SWIR1) pair.\n",
    "- Normalized Difference Water Index, NDWO = $\\frac{NIR - SWIR1}{NIR + SWIR1}$ is also formed from the (NIR, SWIR1) pair.\n",
    "- Modified NDWI, MNDWI = $\\frac{Green - SWIR1}{Green + SWIR1}$ is formed from the (NIR, Green) pair. And so on.\n",
    "\n",
    "\n",
    "| Band | 1 | 2 | 3 | 4 | 5 | 6 | 7\n",
    "| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- \n",
    "| 1 | NA \n",
    "| 2 | ? | NA \n",
    "| 3 | ? | ? | NA \n",
    "| 4 | ? | ? | NDVI | NA\n",
    "| 5 | ? | MNDWI | ? | NDBI, NDWI | NA \n",
    "| 6 | ? | ? | ? | ? | ? | NA \n",
    "| 7 | ? | ? | ? | ? | ? | ? | NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ratios \n",
    "# Note that ratio of Band A to Band B is the same as ratio of Band B to Band A\n",
    "# Solution: only create ratios where A < B\n",
    "for df in (x_train, x_test):\n",
    "    for i in range(1, 8):\n",
    "        for j in range(1, 8):\n",
    "\n",
    "            if i >= j:\n",
    "                continue\n",
    "            else:\n",
    "                band1 = f'l7_2011_{i}'\n",
    "                band2 = f'l7_2011_{j}'\n",
    "                new_var = f'ratio_{i}_{j}'\n",
    "                df[new_var] = abs((df[band1] - df[band2]) / (df[band1] + df[band2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>uid</th>\n",
       "      <th>dmspols_2011_imputed</th>\n",
       "      <th>viirs_2012_imputed</th>\n",
       "      <th>ratio_1_2</th>\n",
       "      <th>ratio_1_3</th>\n",
       "      <th>ratio_1_4</th>\n",
       "      <th>ratio_1_5</th>\n",
       "      <th>ratio_1_6</th>\n",
       "      <th>ratio_1_7</th>\n",
       "      <th>ratio_2_3</th>\n",
       "      <th>ratio_2_4</th>\n",
       "      <th>ratio_2_5</th>\n",
       "      <th>ratio_2_6</th>\n",
       "      <th>ratio_2_7</th>\n",
       "      <th>ratio_3_4</th>\n",
       "      <th>ratio_3_5</th>\n",
       "      <th>ratio_3_6</th>\n",
       "      <th>ratio_3_7</th>\n",
       "      <th>ratio_4_5</th>\n",
       "      <th>ratio_4_6</th>\n",
       "      <th>ratio_4_7</th>\n",
       "      <th>ratio_5_6</th>\n",
       "      <th>ratio_5_7</th>\n",
       "      <th>ratio_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>8.250000</td>\n",
       "      <td>1163.895851</td>\n",
       "      <td>1550.294314</td>\n",
       "      <td>1817.927038</td>\n",
       "      <td>2933.406005</td>\n",
       "      <td>2526.418045</td>\n",
       "      <td>3052.574993</td>\n",
       "      <td>2039.724398</td>\n",
       "      <td>0.493734</td>\n",
       "      <td>37500574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142362</td>\n",
       "      <td>0.219339</td>\n",
       "      <td>0.431872</td>\n",
       "      <td>0.369216</td>\n",
       "      <td>0.447929</td>\n",
       "      <td>0.273387</td>\n",
       "      <td>0.079458</td>\n",
       "      <td>0.308475</td>\n",
       "      <td>0.239439</td>\n",
       "      <td>0.326379</td>\n",
       "      <td>0.136331</td>\n",
       "      <td>0.234772</td>\n",
       "      <td>0.163084</td>\n",
       "      <td>0.253495</td>\n",
       "      <td>0.057495</td>\n",
       "      <td>0.074542</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>0.179702</td>\n",
       "      <td>0.094310</td>\n",
       "      <td>0.106587</td>\n",
       "      <td>0.198898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1042.715843</td>\n",
       "      <td>1380.166134</td>\n",
       "      <td>1518.158721</td>\n",
       "      <td>2497.521366</td>\n",
       "      <td>2146.843169</td>\n",
       "      <td>3010.179651</td>\n",
       "      <td>1475.236047</td>\n",
       "      <td>0.212836</td>\n",
       "      <td>33502329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139276</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.410934</td>\n",
       "      <td>0.346169</td>\n",
       "      <td>0.485446</td>\n",
       "      <td>0.171775</td>\n",
       "      <td>0.047611</td>\n",
       "      <td>0.288150</td>\n",
       "      <td>0.217373</td>\n",
       "      <td>0.371272</td>\n",
       "      <td>0.033295</td>\n",
       "      <td>0.243885</td>\n",
       "      <td>0.171537</td>\n",
       "      <td>0.329485</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>0.075506</td>\n",
       "      <td>0.093080</td>\n",
       "      <td>0.257324</td>\n",
       "      <td>0.167410</td>\n",
       "      <td>0.185420</td>\n",
       "      <td>0.342208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1658.599069</td>\n",
       "      <td>2283.994472</td>\n",
       "      <td>2757.122636</td>\n",
       "      <td>3403.197847</td>\n",
       "      <td>4255.314664</td>\n",
       "      <td>3038.856125</td>\n",
       "      <td>3459.023276</td>\n",
       "      <td>0.431078</td>\n",
       "      <td>61500427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158625</td>\n",
       "      <td>0.248776</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.439086</td>\n",
       "      <td>0.293831</td>\n",
       "      <td>0.351809</td>\n",
       "      <td>0.093854</td>\n",
       "      <td>0.196794</td>\n",
       "      <td>0.301457</td>\n",
       "      <td>0.141815</td>\n",
       "      <td>0.204601</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.048608</td>\n",
       "      <td>0.112916</td>\n",
       "      <td>0.111264</td>\n",
       "      <td>0.056557</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.166771</td>\n",
       "      <td>0.103222</td>\n",
       "      <td>0.064662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>723.232666</td>\n",
       "      <td>989.416884</td>\n",
       "      <td>1095.922251</td>\n",
       "      <td>2654.296055</td>\n",
       "      <td>2021.743690</td>\n",
       "      <td>3015.491732</td>\n",
       "      <td>1458.030316</td>\n",
       "      <td>0.446720</td>\n",
       "      <td>9301283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155422</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.571739</td>\n",
       "      <td>0.473050</td>\n",
       "      <td>0.613113</td>\n",
       "      <td>0.336868</td>\n",
       "      <td>0.051073</td>\n",
       "      <td>0.456918</td>\n",
       "      <td>0.342834</td>\n",
       "      <td>0.505898</td>\n",
       "      <td>0.191470</td>\n",
       "      <td>0.415542</td>\n",
       "      <td>0.296960</td>\n",
       "      <td>0.466888</td>\n",
       "      <td>0.141783</td>\n",
       "      <td>0.135275</td>\n",
       "      <td>0.063705</td>\n",
       "      <td>0.290898</td>\n",
       "      <td>0.197280</td>\n",
       "      <td>0.161997</td>\n",
       "      <td>0.348151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>4.666667</td>\n",
       "      <td>636.219512</td>\n",
       "      <td>884.598432</td>\n",
       "      <td>941.108159</td>\n",
       "      <td>2344.991144</td>\n",
       "      <td>2054.886760</td>\n",
       "      <td>2979.426829</td>\n",
       "      <td>1397.264228</td>\n",
       "      <td>0.298406</td>\n",
       "      <td>39503329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.163319</td>\n",
       "      <td>0.193294</td>\n",
       "      <td>0.573180</td>\n",
       "      <td>0.527169</td>\n",
       "      <td>0.648074</td>\n",
       "      <td>0.374257</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.452191</td>\n",
       "      <td>0.398127</td>\n",
       "      <td>0.542136</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>0.371756</td>\n",
       "      <td>0.519908</td>\n",
       "      <td>0.195074</td>\n",
       "      <td>0.065935</td>\n",
       "      <td>0.119156</td>\n",
       "      <td>0.253250</td>\n",
       "      <td>0.183648</td>\n",
       "      <td>0.190496</td>\n",
       "      <td>0.361497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dmspols_2011    l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "3432  8.250000      1163.895851  1550.294314  1817.927038  2933.406005   \n",
       "3006  4.000000      1042.715843  1380.166134  1518.158721  2497.521366   \n",
       "5279  5.000000      1658.599069  2283.994472  2757.122636  3403.197847   \n",
       "700   8.000000      723.232666   989.416884   1095.922251  2654.296055   \n",
       "3641  4.666667      636.219512   884.598432   941.108159   2344.991144   \n",
       "\n",
       "        l7_2011_5    l7_2011_6    l7_2011_7  viirs_2012       uid  \\\n",
       "3432  2526.418045  3052.574993  2039.724398  0.493734    37500574   \n",
       "3006  2146.843169  3010.179651  1475.236047  0.212836    33502329   \n",
       "5279  4255.314664  3038.856125  3459.023276  0.431078    61500427   \n",
       "700   2021.743690  3015.491732  1458.030316  0.446720    9301283    \n",
       "3641  2054.886760  2979.426829  1397.264228  0.298406    39503329   \n",
       "\n",
       "      dmspols_2011_imputed  viirs_2012_imputed  ratio_1_2  ratio_1_3  \\\n",
       "3432  0                     0                   0.142362   0.219339    \n",
       "3006  0                     0                   0.139276   0.185656    \n",
       "5279  0                     0                   0.158625   0.248776    \n",
       "700   0                     0                   0.155422   0.204870    \n",
       "3641  0                     0                   0.163319   0.193294    \n",
       "\n",
       "      ratio_1_4  ratio_1_5  ratio_1_6  ratio_1_7  ratio_2_3  ratio_2_4  \\\n",
       "3432  0.431872   0.369216   0.447929   0.273387   0.079458   0.308475    \n",
       "3006  0.410934   0.346169   0.485446   0.171775   0.047611   0.288150    \n",
       "5279  0.344660   0.439086   0.293831   0.351809   0.093854   0.196794    \n",
       "700   0.571739   0.473050   0.613113   0.336868   0.051073   0.456918    \n",
       "3641  0.573180   0.527169   0.648074   0.374257   0.030952   0.452191    \n",
       "\n",
       "      ratio_2_5  ratio_2_6  ratio_2_7  ratio_3_4  ratio_3_5  ratio_3_6  \\\n",
       "3432  0.239439   0.326379   0.136331   0.234772   0.163084   0.253495    \n",
       "3006  0.217373   0.371272   0.033295   0.243885   0.171537   0.329485    \n",
       "5279  0.301457   0.141815   0.204601   0.104877   0.213648   0.048608    \n",
       "700   0.342834   0.505898   0.191470   0.415542   0.296960   0.466888    \n",
       "3641  0.398127   0.542136   0.224670   0.427219   0.371756   0.519908    \n",
       "\n",
       "      ratio_3_7  ratio_4_5  ratio_4_6  ratio_4_7  ratio_5_6  ratio_5_7  \\\n",
       "3432  0.057495   0.074542   0.019908   0.179702   0.094310   0.106587    \n",
       "3006  0.014339   0.075506   0.093080   0.257324   0.167410   0.185420    \n",
       "5279  0.112916   0.111264   0.056557   0.008135   0.166771   0.103222    \n",
       "700   0.141783   0.135275   0.063705   0.290898   0.197280   0.161997    \n",
       "3641  0.195074   0.065935   0.119156   0.253250   0.183648   0.190496    \n",
       "\n",
       "      ratio_6_7  \n",
       "3432  0.198898   \n",
       "3006  0.342208   \n",
       "5279  0.064662   \n",
       "700   0.348151   \n",
       "3641  0.361497   "
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>uid</th>\n",
       "      <th>dmspols_2011_imputed</th>\n",
       "      <th>viirs_2012_imputed</th>\n",
       "      <th>ratio_1_2</th>\n",
       "      <th>ratio_1_3</th>\n",
       "      <th>ratio_1_4</th>\n",
       "      <th>ratio_1_5</th>\n",
       "      <th>ratio_1_6</th>\n",
       "      <th>ratio_1_7</th>\n",
       "      <th>ratio_2_3</th>\n",
       "      <th>ratio_2_4</th>\n",
       "      <th>ratio_2_5</th>\n",
       "      <th>ratio_2_6</th>\n",
       "      <th>ratio_2_7</th>\n",
       "      <th>ratio_3_4</th>\n",
       "      <th>ratio_3_5</th>\n",
       "      <th>ratio_3_6</th>\n",
       "      <th>ratio_3_7</th>\n",
       "      <th>ratio_4_5</th>\n",
       "      <th>ratio_4_6</th>\n",
       "      <th>ratio_4_7</th>\n",
       "      <th>ratio_5_6</th>\n",
       "      <th>ratio_5_7</th>\n",
       "      <th>ratio_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>864.398108</td>\n",
       "      <td>1131.496652</td>\n",
       "      <td>1245.548763</td>\n",
       "      <td>2627.650946</td>\n",
       "      <td>2213.787773</td>\n",
       "      <td>3023.319505</td>\n",
       "      <td>1643.098399</td>\n",
       "      <td>0.496819</td>\n",
       "      <td>7905808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133824</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.504934</td>\n",
       "      <td>0.438372</td>\n",
       "      <td>0.555318</td>\n",
       "      <td>0.310549</td>\n",
       "      <td>0.047981</td>\n",
       "      <td>0.398004</td>\n",
       "      <td>0.323527</td>\n",
       "      <td>0.455333</td>\n",
       "      <td>0.184388</td>\n",
       "      <td>0.356837</td>\n",
       "      <td>0.279892</td>\n",
       "      <td>0.416450</td>\n",
       "      <td>0.137625</td>\n",
       "      <td>0.085484</td>\n",
       "      <td>0.070018</td>\n",
       "      <td>0.230534</td>\n",
       "      <td>0.154576</td>\n",
       "      <td>0.147966</td>\n",
       "      <td>0.295777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>6.333333</td>\n",
       "      <td>799.658946</td>\n",
       "      <td>1100.635495</td>\n",
       "      <td>1403.190504</td>\n",
       "      <td>2282.755067</td>\n",
       "      <td>2646.810799</td>\n",
       "      <td>3025.422264</td>\n",
       "      <td>2280.678344</td>\n",
       "      <td>0.325722</td>\n",
       "      <td>3501957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158384</td>\n",
       "      <td>0.273978</td>\n",
       "      <td>0.481148</td>\n",
       "      <td>0.535955</td>\n",
       "      <td>0.581887</td>\n",
       "      <td>0.480798</td>\n",
       "      <td>0.120837</td>\n",
       "      <td>0.349389</td>\n",
       "      <td>0.412594</td>\n",
       "      <td>0.466495</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.238627</td>\n",
       "      <td>0.307067</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.238197</td>\n",
       "      <td>0.073851</td>\n",
       "      <td>0.139910</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>0.074304</td>\n",
       "      <td>0.140356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>957.338180</td>\n",
       "      <td>1270.395755</td>\n",
       "      <td>1382.035766</td>\n",
       "      <td>2840.356935</td>\n",
       "      <td>2284.700640</td>\n",
       "      <td>3021.468741</td>\n",
       "      <td>1675.123582</td>\n",
       "      <td>0.683521</td>\n",
       "      <td>37202289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140527</td>\n",
       "      <td>0.181543</td>\n",
       "      <td>0.495832</td>\n",
       "      <td>0.409422</td>\n",
       "      <td>0.518781</td>\n",
       "      <td>0.272667</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.381916</td>\n",
       "      <td>0.285310</td>\n",
       "      <td>0.407998</td>\n",
       "      <td>0.137405</td>\n",
       "      <td>0.345378</td>\n",
       "      <td>0.246177</td>\n",
       "      <td>0.372302</td>\n",
       "      <td>0.095869</td>\n",
       "      <td>0.108420</td>\n",
       "      <td>0.030897</td>\n",
       "      <td>0.258053</td>\n",
       "      <td>0.138851</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>0.286664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>53.500000</td>\n",
       "      <td>1017.534107</td>\n",
       "      <td>1423.928737</td>\n",
       "      <td>1702.397823</td>\n",
       "      <td>2622.532511</td>\n",
       "      <td>2620.549927</td>\n",
       "      <td>3040.629318</td>\n",
       "      <td>2038.411176</td>\n",
       "      <td>8.751615</td>\n",
       "      <td>36102201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166455</td>\n",
       "      <td>0.251794</td>\n",
       "      <td>0.440926</td>\n",
       "      <td>0.440621</td>\n",
       "      <td>0.498525</td>\n",
       "      <td>0.334063</td>\n",
       "      <td>0.089072</td>\n",
       "      <td>0.296210</td>\n",
       "      <td>0.295865</td>\n",
       "      <td>0.362119</td>\n",
       "      <td>0.177476</td>\n",
       "      <td>0.212751</td>\n",
       "      <td>0.212390</td>\n",
       "      <td>0.282147</td>\n",
       "      <td>0.089824</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.073827</td>\n",
       "      <td>0.125323</td>\n",
       "      <td>0.074204</td>\n",
       "      <td>0.124950</td>\n",
       "      <td>0.197324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>15.666667</td>\n",
       "      <td>889.260093</td>\n",
       "      <td>1208.297851</td>\n",
       "      <td>1352.438426</td>\n",
       "      <td>2646.467470</td>\n",
       "      <td>2353.721173</td>\n",
       "      <td>3019.848243</td>\n",
       "      <td>1806.447430</td>\n",
       "      <td>0.623078</td>\n",
       "      <td>5101034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.206619</td>\n",
       "      <td>0.496986</td>\n",
       "      <td>0.451579</td>\n",
       "      <td>0.545032</td>\n",
       "      <td>0.340240</td>\n",
       "      <td>0.056289</td>\n",
       "      <td>0.373089</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>0.428450</td>\n",
       "      <td>0.198408</td>\n",
       "      <td>0.323596</td>\n",
       "      <td>0.270167</td>\n",
       "      <td>0.381359</td>\n",
       "      <td>0.143724</td>\n",
       "      <td>0.058547</td>\n",
       "      <td>0.065895</td>\n",
       "      <td>0.188645</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.131551</td>\n",
       "      <td>0.251415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dmspols_2011    l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "634   13.000000     864.398108   1131.496652  1245.548763  2627.650946   \n",
       "261   6.333333      799.658946   1100.635495  1403.190504  2282.755067   \n",
       "3389  11.500000     957.338180   1270.395755  1382.035766  2840.356935   \n",
       "3273  53.500000     1017.534107  1423.928737  1702.397823  2622.532511   \n",
       "389   15.666667     889.260093   1208.297851  1352.438426  2646.467470   \n",
       "\n",
       "        l7_2011_5    l7_2011_6    l7_2011_7  viirs_2012       uid  \\\n",
       "634   2213.787773  3023.319505  1643.098399  0.496819    7905808    \n",
       "261   2646.810799  3025.422264  2280.678344  0.325722    3501957    \n",
       "3389  2284.700640  3021.468741  1675.123582  0.683521    37202289   \n",
       "3273  2620.549927  3040.629318  2038.411176  8.751615    36102201   \n",
       "389   2353.721173  3019.848243  1806.447430  0.623078    5101034    \n",
       "\n",
       "      dmspols_2011_imputed  viirs_2012_imputed  ratio_1_2  ratio_1_3  \\\n",
       "634   0                     0                   0.133824   0.180645    \n",
       "261   0                     0                   0.158384   0.273978    \n",
       "3389  0                     0                   0.140527   0.181543    \n",
       "3273  0                     0                   0.166455   0.251794    \n",
       "389   0                     0                   0.152100   0.206619    \n",
       "\n",
       "      ratio_1_4  ratio_1_5  ratio_1_6  ratio_1_7  ratio_2_3  ratio_2_4  \\\n",
       "634   0.504934   0.438372   0.555318   0.310549   0.047981   0.398004    \n",
       "261   0.481148   0.535955   0.581887   0.480798   0.120837   0.349389    \n",
       "3389  0.495832   0.409422   0.518781   0.272667   0.042090   0.381916    \n",
       "3273  0.440926   0.440621   0.498525   0.334063   0.089072   0.296210    \n",
       "389   0.496986   0.451579   0.545032   0.340240   0.056289   0.373089    \n",
       "\n",
       "      ratio_2_5  ratio_2_6  ratio_2_7  ratio_3_4  ratio_3_5  ratio_3_6  \\\n",
       "634   0.323527   0.455333   0.184388   0.356837   0.279892   0.416450    \n",
       "261   0.412594   0.466495   0.348989   0.238627   0.307067   0.366307    \n",
       "3389  0.285310   0.407998   0.137405   0.345378   0.246177   0.372302    \n",
       "3273  0.295865   0.362119   0.177476   0.212751   0.212390   0.282147    \n",
       "389   0.321566   0.428450   0.198408   0.323596   0.270167   0.381359    \n",
       "\n",
       "      ratio_3_7  ratio_4_5  ratio_4_6  ratio_4_7  ratio_5_6  ratio_5_7  \\\n",
       "634   0.137625   0.085484   0.070018   0.230534   0.154576   0.147966    \n",
       "261   0.238197   0.073851   0.139910   0.000455   0.066748   0.074304    \n",
       "3389  0.095869   0.108420   0.030897   0.258053   0.138851   0.153940    \n",
       "3273  0.089824   0.000378   0.073827   0.125323   0.074204   0.124950    \n",
       "389   0.143724   0.058547   0.065895   0.188645   0.123964   0.131551    \n",
       "\n",
       "      ratio_6_7  \n",
       "634   0.295777   \n",
       "261   0.140356   \n",
       "3389  0.286664   \n",
       "3273  0.197324   \n",
       "389   0.251415   "
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check that lengths match\n",
    "print(len(x_train) == len(y_train))\n",
    "print(len(x_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define feature groups\n",
    "\n",
    "1. Daytime-only: Landsat 7 band data and computed indices\n",
    "2. Nighttime-only: DMSP and VIIRS data + imputed flags\n",
    "3. All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day-only: ['l7_2011_1', 'l7_2011_2', 'l7_2011_3', 'l7_2011_4', 'l7_2011_5', 'l7_2011_6', 'l7_2011_7', 'ratio_1_2', 'ratio_1_3', 'ratio_1_4', 'ratio_1_5', 'ratio_1_6', 'ratio_1_7', 'ratio_2_3', 'ratio_2_4', 'ratio_2_5', 'ratio_2_6', 'ratio_2_7', 'ratio_3_4', 'ratio_3_5', 'ratio_3_6', 'ratio_3_7', 'ratio_4_5', 'ratio_4_6', 'ratio_4_7', 'ratio_5_6', 'ratio_5_7', 'ratio_6_7']\n",
      "-----\n",
      "Night-only: ['dmspols_2011', 'viirs_2012', 'dmspols_2011_imputed', 'viirs_2012_imputed']\n"
     ]
    }
   ],
   "source": [
    "DAY_FEATURES = df.filter(regex='l7|ratio', axis=1).columns.tolist()\n",
    "NIGHT_FEATURES = ['dmspols_2011', 'viirs_2012', 'dmspols_2011_imputed', 'viirs_2012_imputed']\n",
    "ALL_FEATURES = df.columns.tolist()\n",
    "\n",
    "print(\"Day-only:\", DAY_FEATURES)\n",
    "print(\"-----\")\n",
    "print(\"Night-only:\", NIGHT_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pickle cleaned data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [x_train, x_test, y_train, y_test]\n",
    "\n",
    "output_path = os.path.join('output', 'final_data.pkl')\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(obj=clean_data,\n",
    "                file=f,\n",
    "                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Regressors\n",
    "\n",
    "### 5.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = x_test.append(x_train)\n",
    "y_all = y_test.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a TrainedRegressor object to hold key results information\n",
    "class TrainedRegressor:\n",
    "    \n",
    "    def __init__(self, method, params, features, regressor):\n",
    "        self.method = method\n",
    "        self.params = params\n",
    "        self.regressor = regressor\n",
    "        self.features = features\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Trained {self.method} on feature set {self.features} with params {self.params}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 1: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 2: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 3: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 4: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 5: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 6: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 7: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 8: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 9: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 10: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 11: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 12: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 13: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 14: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 15: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 16: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 17: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 18: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 19: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 20: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 21: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 22: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 23: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 24: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 25: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 26: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 27: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 28: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 29: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 30: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 31: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 32: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 33: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 34: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 35: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 36: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 37: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 38: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 39: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 40: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 41: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 42: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 43: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 44: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 45: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 10000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 46: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 10000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 47: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 48: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 10000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 49: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 10000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 50: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 51: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 10000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-526-39fae16e587c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# 2. All Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtrained_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mtrained_list_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainedRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 378\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use GRID_MAIN for full grid search\n",
    "# parameters = cf.GRID_TEST_CLASS\n",
    "parameters = GRID_TEST_CLASS\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df_all = pd.DataFrame()\n",
    "results_df_trainedonly_all = pd.DataFrame()\n",
    "\n",
    "x_trainedonly_all = x_all.copy()\n",
    "\n",
    "trained_list = []\n",
    "trained_list_all = []\n",
    "count = 0\n",
    "# print('Training model ', end='')\n",
    "for i in parameters['regressors']:\n",
    "    for j in parameters[i]:\n",
    "        for k in ('DAY_FEATURES', 'NIGHT_FEATURES', 'ALL_FEATURES'):\n",
    "        \n",
    "            print(f'Model {count}: Training {i} on {k} with params {str(j)}')\n",
    "\n",
    "            # A. Train ------------------------------------\n",
    "            # Initialize regressor, fit data, then append TrainedRegressor object to list\n",
    "            # 1. Train Data\n",
    "            regressor = eval(i)(**j)\n",
    "            trained = regressor.fit(x_train[eval(k)], y_train)\n",
    "            trained_list.append(TrainedRegressor(i, str(j), k, trained))\n",
    "\n",
    "            # 2. All Data\n",
    "            trained_all = regressor.fit(x_all[eval(k)], y_all)\n",
    "            trained_list_all.append(TrainedRegressor(i, str(j), k, trained_all))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # B. Results -------------------------------------\n",
    "            # 1. Trained Model on Test Data - - - - - - - - - -\n",
    "            pred_labels = trained_list[count].regressor.predict(x_test[eval(k)])\n",
    "\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list[count].method,\n",
    "                'features': trained_list[count].features,\n",
    "                'params': trained_list[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_test, y_pred=pred_labels)        \n",
    "            }\n",
    "    \n",
    "            results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            results_df.to_csv(\"/Users/robmarty/Desktop/results.csv\")\n",
    "            \n",
    "            x_test['y_true'] = y_test\n",
    "            x_test['y_predict_' + str(count)] = pred_labels\n",
    "            x_test.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'opm_data_with_predictions_traineddatamodel_testdatapredict.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 2. Trained All Model on All Data - - - - - - - - - -\n",
    "            pred_labels_all = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list_all[count].method,\n",
    "                'features': trained_list_all[count].features,\n",
    "                'params': trained_list_all[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_all)        \n",
    "            }\n",
    "    \n",
    "            results_df_all = results_df_all.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            results_df_all.to_csv(\"/Users/robmarty/Desktop/results_all.csv\")\n",
    "\n",
    "            # ALL\n",
    "            x_trainedonly_all['y_true'] = y_all\n",
    "            x_trainedonly_all['y_predict_' + str(count)] = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "            x_trainedonly_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'opm_data_with_predictions_alldatamodel_alldatapredict.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 3. Trained Model on All Data - - - - - - - - - -\n",
    "            pred_labels_trainedonly_all = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list[count].method,\n",
    "                'features': trained_list[count].features,\n",
    "                'params': trained_list[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_trainedonly_all)        \n",
    "            }\n",
    "    \n",
    "            results_df_trainedonly_all = results_df_trainedonly_all.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            results_df_trainedonly_all.to_csv(\"/Users/robmarty/Desktop/results_trainedonly_all.csv\")\n",
    "\n",
    "            # ALL\n",
    "            x_all['y_true'] = y_all\n",
    "            x_all['y_predict_' + str(count)] = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "            x_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'opm_data_with_predictions_testdatamodel_alldatapredict.csv'))\n",
    "\n",
    "            ####\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test\n",
    "#pred_labels\n",
    "#parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "for i in trained_list:\n",
    "    \n",
    "    # Get predicted results from test data\n",
    "    features = eval(i.features)\n",
    "    pred_labels = i.regressor.predict(x_test[features])\n",
    "    \n",
    "    # Append results to dataframe and sort by R^2\n",
    "    pred_dict = {\n",
    "        'regressor': i.method,\n",
    "        'features': i.features,\n",
    "        'params': i.params,\n",
    "        'r2': r2_score(y_true=y_test, y_pred=pred_labels)        \n",
    "    }\n",
    "    \n",
    "    results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "        .sort_values(by='r2', ascending=False, axis=0) \\\n",
    "        [['regressor', 'params', 'features', 'r2']]\n",
    "\n",
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
