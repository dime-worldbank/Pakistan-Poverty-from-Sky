{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict household income from satellite imagery data\n",
    "\n",
    "First pass.\n",
    "\n",
    "General ML pipeline steps:\n",
    "1. Import data\n",
    "2. Split data into test/train sets\n",
    "3. Preprocess test/train sets separately\n",
    "4. Generate features from data\n",
    "5. For each regressor-hyperparameter combination:\n",
    "    - Train regressor with given hyperparameters and training data and labels\n",
    "    - Generate predicted labels for test data with trained regressor\n",
    "    - Evaluate regressor-hyperparameter performance against actual test labels and get $R^2$\n",
    "6. Explore best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import configuration file\n",
    "import config as cf\n",
    "\n",
    "# Display options \n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = -1\n",
    "\n",
    "# Turn off big pink warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data file path \n",
    "final_data_file_path = \"/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/FinalData\"\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test grid to make sure everything works - limited models and parameters\n",
    "GRID_TEST_CLASS = {\n",
    "    'regressors': ['LinearSVC','DecisionTreeClassifier', 'BaggingClassifier',\n",
    "                    'GradientBoostingClassifier', 'RandomForestClassifier'],\n",
    "    'LinearSVC': [\n",
    "        {'penalty': penalty, 'C': C, 'loss': loss, 'max_iter': max_iter,\n",
    "        'random_state': 0} \\\n",
    "        for penalty in ('l2', ) \\\n",
    "        for C in (1e-2, 1e2) \\\n",
    "        for loss in ('epsilon_insensitive', ) \\\n",
    "        for max_iter in (1e3, 1e5)\n",
    "    ],\n",
    "    'DecisionTreeClassifier': [\n",
    "        {'criterion': criterion, 'splitter': splitter, 'max_depth': max_depth,\n",
    "        'max_features': max_features, 'random_state': 0} \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for splitter in ('best', ) \\\n",
    "        for max_depth in (1, 5, 10, 20, 30) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ],\n",
    "    'BaggingClassifier': [\n",
    "        {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "        'random_state': 0, 'n_jobs': -1} \\\n",
    "        for n_estimators in (100, 1000, 10000) \\\n",
    "        for max_features in (0.3, 0.5, 1.0)\n",
    "    ],\n",
    "    'GradientBoostingClassifier': [\n",
    "        {'loss': loss, 'learning_rate': rate, 'n_estimators': n_estimators,\n",
    "        'criterion': criterion, 'max_features': max_features,\n",
    "        'random_state': 0} \\\n",
    "        for loss in ('deviance', ) \\\n",
    "        for rate in (1e-4, )\n",
    "        for n_estimators in (100, ) \\\n",
    "        for criterion in ('friedman_mse', ) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ],\n",
    "    'RandomForestClassifier': [\n",
    "        {'n_estimators': n_estimators, 'criterion': criterion,\n",
    "        'max_depth': max_depth, 'max_features': max_features, 'n_jobs': -1,\n",
    "        'random_state': 0} \\\n",
    "        for n_estimators in (10, 100, 1000) \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for max_depth in (1, ) \\\n",
    "        for max_features in ('sqrt', )\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data and drop \"future\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5416, 46)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(final_data_file_path, 'Outputs for Analysis TEMP', 'bisp_sat_pov_data.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>viirs_2013</th>\n",
       "      <th>viirs_2014</th>\n",
       "      <th>viirs_2015</th>\n",
       "      <th>viirs_2016</th>\n",
       "      <th>viirs_2017</th>\n",
       "      <th>viirs_2018</th>\n",
       "      <th>dmspols_1992</th>\n",
       "      <th>dmspols_1993</th>\n",
       "      <th>dmspols_1994</th>\n",
       "      <th>dmspols_1995</th>\n",
       "      <th>dmspols_1996</th>\n",
       "      <th>dmspols_1997</th>\n",
       "      <th>dmspols_1998</th>\n",
       "      <th>dmspols_1999</th>\n",
       "      <th>dmspols_2000</th>\n",
       "      <th>dmspols_2001</th>\n",
       "      <th>dmspols_2002</th>\n",
       "      <th>dmspols_2003</th>\n",
       "      <th>dmspols_2004</th>\n",
       "      <th>dmspols_2005</th>\n",
       "      <th>dmspols_2006</th>\n",
       "      <th>dmspols_2007</th>\n",
       "      <th>dmspols_2008</th>\n",
       "      <th>dmspols_2009</th>\n",
       "      <th>dmspols_2010</th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>dmspols_2012</th>\n",
       "      <th>dmspols_2013</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>l7_2013_1</th>\n",
       "      <th>l7_2013_2</th>\n",
       "      <th>l7_2013_3</th>\n",
       "      <th>l7_2013_4</th>\n",
       "      <th>l7_2013_5</th>\n",
       "      <th>l7_2013_6</th>\n",
       "      <th>l7_2013_7</th>\n",
       "      <th>pscores_2011</th>\n",
       "      <th>pscores_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100389</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>2.141392</td>\n",
       "      <td>2.089507</td>\n",
       "      <td>2.307763</td>\n",
       "      <td>2.850603</td>\n",
       "      <td>3.653005</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>902.331348</td>\n",
       "      <td>1224.739396</td>\n",
       "      <td>1393.123911</td>\n",
       "      <td>2555.792708</td>\n",
       "      <td>2474.174317</td>\n",
       "      <td>3005.856769</td>\n",
       "      <td>1922.539802</td>\n",
       "      <td>951.897734</td>\n",
       "      <td>1282.748257</td>\n",
       "      <td>1417.251598</td>\n",
       "      <td>2574.000436</td>\n",
       "      <td>2469.137711</td>\n",
       "      <td>3000.408919</td>\n",
       "      <td>1889.609384</td>\n",
       "      <td>23.370001</td>\n",
       "      <td>29.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100401</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>2.133366</td>\n",
       "      <td>2.052437</td>\n",
       "      <td>2.296554</td>\n",
       "      <td>2.769960</td>\n",
       "      <td>3.702374</td>\n",
       "      <td>3.488333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>885.841488</td>\n",
       "      <td>1200.548350</td>\n",
       "      <td>1366.253764</td>\n",
       "      <td>2512.672843</td>\n",
       "      <td>2451.849595</td>\n",
       "      <td>3004.616242</td>\n",
       "      <td>1890.566155</td>\n",
       "      <td>941.063694</td>\n",
       "      <td>1268.392009</td>\n",
       "      <td>1402.777070</td>\n",
       "      <td>2547.212362</td>\n",
       "      <td>2463.117111</td>\n",
       "      <td>2998.701940</td>\n",
       "      <td>1876.871453</td>\n",
       "      <td>5.110000</td>\n",
       "      <td>2.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100581</td>\n",
       "      <td>1.824753</td>\n",
       "      <td>1.937131</td>\n",
       "      <td>1.875487</td>\n",
       "      <td>2.047540</td>\n",
       "      <td>2.557241</td>\n",
       "      <td>3.198625</td>\n",
       "      <td>3.286000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>34.25</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>38.25</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>37.750000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.75</td>\n",
       "      <td>33.75</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.75</td>\n",
       "      <td>42.5</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>45.5</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>886.021385</td>\n",
       "      <td>1206.745127</td>\n",
       "      <td>1373.031277</td>\n",
       "      <td>2550.999418</td>\n",
       "      <td>2462.909660</td>\n",
       "      <td>3006.164678</td>\n",
       "      <td>1900.649840</td>\n",
       "      <td>935.162060</td>\n",
       "      <td>1263.157696</td>\n",
       "      <td>1398.079866</td>\n",
       "      <td>2572.847832</td>\n",
       "      <td>2458.750073</td>\n",
       "      <td>2999.056008</td>\n",
       "      <td>1880.909223</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>5.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101101</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>2.133366</td>\n",
       "      <td>2.052437</td>\n",
       "      <td>2.296554</td>\n",
       "      <td>2.769960</td>\n",
       "      <td>3.702374</td>\n",
       "      <td>3.488333</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>886.196798</td>\n",
       "      <td>1201.037263</td>\n",
       "      <td>1366.468559</td>\n",
       "      <td>2514.479913</td>\n",
       "      <td>2450.865939</td>\n",
       "      <td>3004.699563</td>\n",
       "      <td>1890.108734</td>\n",
       "      <td>940.979913</td>\n",
       "      <td>1268.248763</td>\n",
       "      <td>1401.871616</td>\n",
       "      <td>2547.740466</td>\n",
       "      <td>2459.946143</td>\n",
       "      <td>2998.786463</td>\n",
       "      <td>1874.074672</td>\n",
       "      <td>8.190000</td>\n",
       "      <td>22.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101236</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>2.141392</td>\n",
       "      <td>2.089507</td>\n",
       "      <td>2.307763</td>\n",
       "      <td>2.850603</td>\n",
       "      <td>3.653005</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>35.50</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.166667</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>34.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>45.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>891.264553</td>\n",
       "      <td>1209.613090</td>\n",
       "      <td>1374.709528</td>\n",
       "      <td>2535.919345</td>\n",
       "      <td>2453.881552</td>\n",
       "      <td>3005.134086</td>\n",
       "      <td>1897.493484</td>\n",
       "      <td>943.113959</td>\n",
       "      <td>1271.824645</td>\n",
       "      <td>1403.386186</td>\n",
       "      <td>2563.689111</td>\n",
       "      <td>2453.279467</td>\n",
       "      <td>2999.725311</td>\n",
       "      <td>1869.047929</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  viirs_2012  viirs_2013  viirs_2014  viirs_2015  viirs_2016  \\\n",
       "0  100389  2.052018    2.141392    2.089507    2.307763    2.850603     \n",
       "1  100401  1.964332    2.133366    2.052437    2.296554    2.769960     \n",
       "2  100581  1.824753    1.937131    1.875487    2.047540    2.557241     \n",
       "3  101101  1.964332    2.133366    2.052437    2.296554    2.769960     \n",
       "4  101236  2.052018    2.141392    2.089507    2.307763    2.850603     \n",
       "\n",
       "   viirs_2017  viirs_2018  dmspols_1992  dmspols_1993  dmspols_1994  \\\n",
       "0  3.653005    3.750000    43.0          33.666667     35.50          \n",
       "1  3.702374    3.488333    43.0          33.666667     35.50          \n",
       "2  3.198625    3.286000    43.0          32.500000     34.25          \n",
       "3  3.702374    3.488333    43.0          33.666667     35.50          \n",
       "4  3.653005    3.750000    43.0          33.666667     35.50          \n",
       "\n",
       "   dmspols_1995  dmspols_1996  dmspols_1997  dmspols_1998  dmspols_1999  \\\n",
       "0  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "1  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "2  43.000000     38.0          31.750000     38.25         38.750000      \n",
       "3  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "4  45.333333     40.0          33.166667     39.50         40.333333      \n",
       "\n",
       "   dmspols_2000  dmspols_2001  dmspols_2002  dmspols_2003  dmspols_2004  \\\n",
       "0  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "1  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "2  36.000000     38.250000     37.750000     32.000000     32.75          \n",
       "3  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "4  37.333333     39.666667     38.833333     33.666667     34.00          \n",
       "\n",
       "   dmspols_2005  dmspols_2006  dmspols_2007  dmspols_2008  dmspols_2009  \\\n",
       "0  34.50         40.666667     45.00         43.0          30.333333      \n",
       "1  34.50         40.666667     45.00         43.0          30.333333      \n",
       "2  33.75         40.000000     43.75         42.5          30.000000      \n",
       "3  34.50         40.666667     45.00         43.0          30.333333      \n",
       "4  34.50         40.666667     45.00         43.0          30.333333      \n",
       "\n",
       "   dmspols_2010  dmspols_2011  dmspols_2012  dmspols_2013   l7_2011_1  \\\n",
       "0  46.0          32.666667     47.666667     45.333333     902.331348   \n",
       "1  46.0          32.666667     47.666667     45.333333     885.841488   \n",
       "2  45.5          30.500000     47.500000     44.500000     886.021385   \n",
       "3  46.0          32.666667     47.666667     45.333333     886.196798   \n",
       "4  46.0          32.666667     47.666667     45.333333     891.264553   \n",
       "\n",
       "     l7_2011_2    l7_2011_3    l7_2011_4    l7_2011_5    l7_2011_6  \\\n",
       "0  1224.739396  1393.123911  2555.792708  2474.174317  3005.856769   \n",
       "1  1200.548350  1366.253764  2512.672843  2451.849595  3004.616242   \n",
       "2  1206.745127  1373.031277  2550.999418  2462.909660  3006.164678   \n",
       "3  1201.037263  1366.468559  2514.479913  2450.865939  3004.699563   \n",
       "4  1209.613090  1374.709528  2535.919345  2453.881552  3005.134086   \n",
       "\n",
       "     l7_2011_7   l7_2013_1    l7_2013_2    l7_2013_3    l7_2013_4  \\\n",
       "0  1922.539802  951.897734  1282.748257  1417.251598  2574.000436   \n",
       "1  1890.566155  941.063694  1268.392009  1402.777070  2547.212362   \n",
       "2  1900.649840  935.162060  1263.157696  1398.079866  2572.847832   \n",
       "3  1890.108734  940.979913  1268.248763  1401.871616  2547.740466   \n",
       "4  1897.493484  943.113959  1271.824645  1403.386186  2563.689111   \n",
       "\n",
       "     l7_2013_5    l7_2013_6    l7_2013_7  pscores_2011  pscores_2013  \n",
       "0  2469.137711  3000.408919  1889.609384  23.370001     29.889999     \n",
       "1  2463.117111  2998.701940  1876.871453  5.110000      2.650000      \n",
       "2  2458.750073  2999.056008  1880.909223  4.300000      5.510000      \n",
       "3  2459.946143  2998.786463  1874.074672  8.190000      22.400000     \n",
       "4  2453.279467  2999.725311  1869.047929  40.750000    NaN            "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NAs\n",
    "df = df.loc[(df['pscores_2011'] >= 0)]\n",
    "df = df.loc[(df['pscores_2011'] <= 20000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DV as Quantiles\n",
    "#df['pscores_2011'] = pd.qcut(df['pscores_2011'], 3, labels=False)\n",
    "#df['pscores_2011'].value_counts()\n",
    "df['hhinc_2011'] = df['pscores_2011'] <= 16.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['pscores_2011'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>hhinc_2011</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>902.331348</td>\n",
       "      <td>1224.739396</td>\n",
       "      <td>1393.123911</td>\n",
       "      <td>2555.792708</td>\n",
       "      <td>2474.174317</td>\n",
       "      <td>3005.856769</td>\n",
       "      <td>1922.539802</td>\n",
       "      <td>False</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>100389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>885.841488</td>\n",
       "      <td>1200.548350</td>\n",
       "      <td>1366.253764</td>\n",
       "      <td>2512.672843</td>\n",
       "      <td>2451.849595</td>\n",
       "      <td>3004.616242</td>\n",
       "      <td>1890.566155</td>\n",
       "      <td>True</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>100401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.500000</td>\n",
       "      <td>886.021385</td>\n",
       "      <td>1206.745127</td>\n",
       "      <td>1373.031277</td>\n",
       "      <td>2550.999418</td>\n",
       "      <td>2462.909660</td>\n",
       "      <td>3006.164678</td>\n",
       "      <td>1900.649840</td>\n",
       "      <td>True</td>\n",
       "      <td>1.824753</td>\n",
       "      <td>100581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>886.196798</td>\n",
       "      <td>1201.037263</td>\n",
       "      <td>1366.468559</td>\n",
       "      <td>2514.479913</td>\n",
       "      <td>2450.865939</td>\n",
       "      <td>3004.699563</td>\n",
       "      <td>1890.108734</td>\n",
       "      <td>True</td>\n",
       "      <td>1.964332</td>\n",
       "      <td>101101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>891.264553</td>\n",
       "      <td>1209.613090</td>\n",
       "      <td>1374.709528</td>\n",
       "      <td>2535.919345</td>\n",
       "      <td>2453.881552</td>\n",
       "      <td>3005.134086</td>\n",
       "      <td>1897.493484</td>\n",
       "      <td>False</td>\n",
       "      <td>2.052018</td>\n",
       "      <td>101236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dmspols_2011   l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "0  32.666667     902.331348  1224.739396  1393.123911  2555.792708   \n",
       "1  32.666667     885.841488  1200.548350  1366.253764  2512.672843   \n",
       "2  30.500000     886.021385  1206.745127  1373.031277  2550.999418   \n",
       "3  32.666667     886.196798  1201.037263  1366.468559  2514.479913   \n",
       "4  32.666667     891.264553  1209.613090  1374.709528  2535.919345   \n",
       "\n",
       "     l7_2011_5    l7_2011_6    l7_2011_7  hhinc_2011  viirs_2012     uid  \n",
       "0  2474.174317  3005.856769  1922.539802  False       2.052018    100389  \n",
       "1  2451.849595  3004.616242  1890.566155  True        1.964332    100401  \n",
       "2  2462.909660  3006.164678  1900.649840  True        1.824753    100581  \n",
       "3  2450.865939  3004.699563  1890.108734  True        1.964332    101101  \n",
       "4  2453.881552  3005.134086  1897.493484  False       2.052018    101236  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only 2011 columns, but include viirs_2012\n",
    "df = df.filter(regex='_2011', axis=1).join(df[['viirs_2012','uid']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4829, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns where the label is missing\n",
    "df = df.loc[~pd.isnull(df['hhinc_2011'])]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'hhinc_2011'\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "# Separate feature sets from label sets\n",
    "x_df = df.drop(labels=[LABEL], axis=1)\n",
    "y_df = df[LABEL]\n",
    "\n",
    "# Split into test and train sets for features and labels\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x_df, y_df, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess data\n",
    "\n",
    "All vars are numeric - impute missing data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FEATURES MISSING:\n",
      "dmspols_2011    32\n",
      "l7_2011_1       0 \n",
      "l7_2011_2       0 \n",
      "l7_2011_3       0 \n",
      "l7_2011_4       0 \n",
      "l7_2011_5       0 \n",
      "l7_2011_6       0 \n",
      "l7_2011_7       0 \n",
      "viirs_2012      32\n",
      "uid             0 \n",
      "dtype: int64\n",
      "\n",
      "TEST FEATURES MISSING:\n",
      "dmspols_2011    20\n",
      "l7_2011_1       0 \n",
      "l7_2011_2       0 \n",
      "l7_2011_3       0 \n",
      "l7_2011_4       0 \n",
      "l7_2011_5       0 \n",
      "l7_2011_6       0 \n",
      "l7_2011_7       0 \n",
      "viirs_2012      20\n",
      "uid             0 \n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows are missing across columns\n",
    "print(\"TRAINING FEATURES MISSING:\")\n",
    "print(pd.isnull(x_train).sum())\n",
    "print(\"\")\n",
    "print(\"TEST FEATURES MISSING:\")\n",
    "print(pd.isnull(x_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (x_train, x_test):\n",
    "    for j in i.columns:\n",
    "        \n",
    "        if i[j].isnull().sum():\n",
    "            # Create imputed flag\n",
    "            new_name = i[j].name + '_imputed'\n",
    "            i[new_name] = pd.isnull(i[j]).astype('int')\n",
    "            # Fill with mean\n",
    "            i[j] = i[j].fillna(i[j].mean())\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FEATURES MISSING:\n",
      "dmspols_2011            0\n",
      "l7_2011_1               0\n",
      "l7_2011_2               0\n",
      "l7_2011_3               0\n",
      "l7_2011_4               0\n",
      "l7_2011_5               0\n",
      "l7_2011_6               0\n",
      "l7_2011_7               0\n",
      "viirs_2012              0\n",
      "uid                     0\n",
      "dmspols_2011_imputed    0\n",
      "viirs_2012_imputed      0\n",
      "dtype: int64\n",
      "\n",
      "TEST FEATURES MISSING:\n",
      "dmspols_2011            0\n",
      "l7_2011_1               0\n",
      "l7_2011_2               0\n",
      "l7_2011_3               0\n",
      "l7_2011_4               0\n",
      "l7_2011_5               0\n",
      "l7_2011_6               0\n",
      "l7_2011_7               0\n",
      "viirs_2012              0\n",
      "uid                     0\n",
      "dmspols_2011_imputed    0\n",
      "viirs_2012_imputed      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# All missing values were imputed\n",
    "print(\"TRAINING FEATURES MISSING:\")\n",
    "print(pd.isnull(x_train).sum())\n",
    "print(\"\")\n",
    "print(\"TEST FEATURES MISSING:\")\n",
    "print(pd.isnull(x_test).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Generation\n",
    "\n",
    "[Landsat 7 specs](https://landsat.usgs.gov/sites/default/files/documents/si_product_guide.pdf#page=14)\n",
    "\n",
    "Create indices from every possible pair of Landsat 7 band.\n",
    "- Normalized Difference Vegetation Index, NDVI = $\\frac{NIR - Red}{NIR + Red}$ is formed from the (NIR, Red) pair.\n",
    "- Normalized Difference Built-up Index, NDBI = $\\frac{SWIR1 - NIR}{SWIR1 + NIR}$ is formed from the (NIR, SWIR1) pair.\n",
    "- Normalized Difference Water Index, NDWO = $\\frac{NIR - SWIR1}{NIR + SWIR1}$ is also formed from the (NIR, SWIR1) pair.\n",
    "- Modified NDWI, MNDWI = $\\frac{Green - SWIR1}{Green + SWIR1}$ is formed from the (NIR, Green) pair. And so on.\n",
    "\n",
    "\n",
    "| Band | 1 | 2 | 3 | 4 | 5 | 6 | 7\n",
    "| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- \n",
    "| 1 | NA \n",
    "| 2 | ? | NA \n",
    "| 3 | ? | ? | NA \n",
    "| 4 | ? | ? | NDVI | NA\n",
    "| 5 | ? | MNDWI | ? | NDBI, NDWI | NA \n",
    "| 6 | ? | ? | ? | ? | ? | NA \n",
    "| 7 | ? | ? | ? | ? | ? | ? | NA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ratios \n",
    "# Note that ratio of Band A to Band B is the same as ratio of Band B to Band A\n",
    "# Solution: only create ratios where A < B\n",
    "for df in (x_train, x_test):\n",
    "    for i in range(1, 8):\n",
    "        for j in range(1, 8):\n",
    "\n",
    "            if i >= j:\n",
    "                continue\n",
    "            else:\n",
    "                band1 = f'l7_2011_{i}'\n",
    "                band2 = f'l7_2011_{j}'\n",
    "                new_var = f'ratio_{i}_{j}'\n",
    "                df[new_var] = abs((df[band1] - df[band2]) / (df[band1] + df[band2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>uid</th>\n",
       "      <th>dmspols_2011_imputed</th>\n",
       "      <th>viirs_2012_imputed</th>\n",
       "      <th>ratio_1_2</th>\n",
       "      <th>ratio_1_3</th>\n",
       "      <th>ratio_1_4</th>\n",
       "      <th>ratio_1_5</th>\n",
       "      <th>ratio_1_6</th>\n",
       "      <th>ratio_1_7</th>\n",
       "      <th>ratio_2_3</th>\n",
       "      <th>ratio_2_4</th>\n",
       "      <th>ratio_2_5</th>\n",
       "      <th>ratio_2_6</th>\n",
       "      <th>ratio_2_7</th>\n",
       "      <th>ratio_3_4</th>\n",
       "      <th>ratio_3_5</th>\n",
       "      <th>ratio_3_6</th>\n",
       "      <th>ratio_3_7</th>\n",
       "      <th>ratio_4_5</th>\n",
       "      <th>ratio_4_6</th>\n",
       "      <th>ratio_4_7</th>\n",
       "      <th>ratio_5_6</th>\n",
       "      <th>ratio_5_7</th>\n",
       "      <th>ratio_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>24.0</td>\n",
       "      <td>901.910885</td>\n",
       "      <td>1276.550363</td>\n",
       "      <td>1411.094775</td>\n",
       "      <td>2996.116401</td>\n",
       "      <td>2546.972714</td>\n",
       "      <td>3031.464877</td>\n",
       "      <td>1907.712192</td>\n",
       "      <td>1.229348</td>\n",
       "      <td>4900320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171974</td>\n",
       "      <td>0.220139</td>\n",
       "      <td>0.537248</td>\n",
       "      <td>0.476984</td>\n",
       "      <td>0.541406</td>\n",
       "      <td>0.357984</td>\n",
       "      <td>0.050060</td>\n",
       "      <td>0.402457</td>\n",
       "      <td>0.332265</td>\n",
       "      <td>0.407360</td>\n",
       "      <td>0.198213</td>\n",
       "      <td>0.359643</td>\n",
       "      <td>0.286978</td>\n",
       "      <td>0.364738</td>\n",
       "      <td>0.149637</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>0.221950</td>\n",
       "      <td>0.086851</td>\n",
       "      <td>0.143503</td>\n",
       "      <td>0.227518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1010.649942</td>\n",
       "      <td>1344.685760</td>\n",
       "      <td>1589.681990</td>\n",
       "      <td>2445.176189</td>\n",
       "      <td>2589.602233</td>\n",
       "      <td>3018.334252</td>\n",
       "      <td>2046.523202</td>\n",
       "      <td>4.102749</td>\n",
       "      <td>25703397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141821</td>\n",
       "      <td>0.222676</td>\n",
       "      <td>0.415104</td>\n",
       "      <td>0.438567</td>\n",
       "      <td>0.498310</td>\n",
       "      <td>0.338834</td>\n",
       "      <td>0.083492</td>\n",
       "      <td>0.290377</td>\n",
       "      <td>0.316427</td>\n",
       "      <td>0.383599</td>\n",
       "      <td>0.206958</td>\n",
       "      <td>0.212026</td>\n",
       "      <td>0.239256</td>\n",
       "      <td>0.310036</td>\n",
       "      <td>0.125637</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.104907</td>\n",
       "      <td>0.088753</td>\n",
       "      <td>0.076451</td>\n",
       "      <td>0.117141</td>\n",
       "      <td>0.191873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>6.5</td>\n",
       "      <td>1016.671152</td>\n",
       "      <td>1320.956019</td>\n",
       "      <td>1479.582899</td>\n",
       "      <td>2359.837384</td>\n",
       "      <td>2234.348958</td>\n",
       "      <td>3026.724826</td>\n",
       "      <td>1685.984520</td>\n",
       "      <td>0.301120</td>\n",
       "      <td>37700984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130168</td>\n",
       "      <td>0.185443</td>\n",
       "      <td>0.397797</td>\n",
       "      <td>0.374553</td>\n",
       "      <td>0.497120</td>\n",
       "      <td>0.247650</td>\n",
       "      <td>0.056642</td>\n",
       "      <td>0.282244</td>\n",
       "      <td>0.256910</td>\n",
       "      <td>0.392340</td>\n",
       "      <td>0.121395</td>\n",
       "      <td>0.229268</td>\n",
       "      <td>0.203226</td>\n",
       "      <td>0.343328</td>\n",
       "      <td>0.065202</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>0.123806</td>\n",
       "      <td>0.166555</td>\n",
       "      <td>0.150611</td>\n",
       "      <td>0.139877</td>\n",
       "      <td>0.284495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>0.0</td>\n",
       "      <td>617.041618</td>\n",
       "      <td>787.066415</td>\n",
       "      <td>809.077871</td>\n",
       "      <td>2105.904002</td>\n",
       "      <td>1763.348318</td>\n",
       "      <td>2938.720708</td>\n",
       "      <td>1204.052204</td>\n",
       "      <td>0.109788</td>\n",
       "      <td>39800512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121091</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.546784</td>\n",
       "      <td>0.481563</td>\n",
       "      <td>0.652934</td>\n",
       "      <td>0.322340</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>0.455877</td>\n",
       "      <td>0.382793</td>\n",
       "      <td>0.577503</td>\n",
       "      <td>0.209423</td>\n",
       "      <td>0.444883</td>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.568238</td>\n",
       "      <td>0.196199</td>\n",
       "      <td>0.088533</td>\n",
       "      <td>0.165090</td>\n",
       "      <td>0.272466</td>\n",
       "      <td>0.249969</td>\n",
       "      <td>0.188480</td>\n",
       "      <td>0.418722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>18.0</td>\n",
       "      <td>880.414847</td>\n",
       "      <td>1152.104803</td>\n",
       "      <td>1318.878894</td>\n",
       "      <td>2572.979330</td>\n",
       "      <td>2284.983406</td>\n",
       "      <td>3030.307132</td>\n",
       "      <td>1783.694032</td>\n",
       "      <td>1.105853</td>\n",
       "      <td>1702700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133672</td>\n",
       "      <td>0.199366</td>\n",
       "      <td>0.490116</td>\n",
       "      <td>0.443726</td>\n",
       "      <td>0.549743</td>\n",
       "      <td>0.339055</td>\n",
       "      <td>0.067493</td>\n",
       "      <td>0.381434</td>\n",
       "      <td>0.329604</td>\n",
       "      <td>0.449072</td>\n",
       "      <td>0.215134</td>\n",
       "      <td>0.322237</td>\n",
       "      <td>0.268075</td>\n",
       "      <td>0.393505</td>\n",
       "      <td>0.149816</td>\n",
       "      <td>0.059283</td>\n",
       "      <td>0.081618</td>\n",
       "      <td>0.181167</td>\n",
       "      <td>0.140223</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>0.258956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dmspols_2011    l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "374   24.0          901.910885   1276.550363  1411.094775  2996.116401   \n",
       "2388  31.0          1010.649942  1344.685760  1589.681990  2445.176189   \n",
       "3461  6.5           1016.671152  1320.956019  1479.582899  2359.837384   \n",
       "3662  0.0           617.041618   787.066415   809.077871   2105.904002   \n",
       "83    18.0          880.414847   1152.104803  1318.878894  2572.979330   \n",
       "\n",
       "        l7_2011_5    l7_2011_6    l7_2011_7  viirs_2012       uid  \\\n",
       "374   2546.972714  3031.464877  1907.712192  1.229348    4900320    \n",
       "2388  2589.602233  3018.334252  2046.523202  4.102749    25703397   \n",
       "3461  2234.348958  3026.724826  1685.984520  0.301120    37700984   \n",
       "3662  1763.348318  2938.720708  1204.052204  0.109788    39800512   \n",
       "83    2284.983406  3030.307132  1783.694032  1.105853    1702700    \n",
       "\n",
       "      dmspols_2011_imputed  viirs_2012_imputed  ratio_1_2  ratio_1_3  \\\n",
       "374   0                     0                   0.171974   0.220139    \n",
       "2388  0                     0                   0.141821   0.222676    \n",
       "3461  0                     0                   0.130168   0.185443    \n",
       "3662  0                     0                   0.121091   0.134656    \n",
       "83    0                     0                   0.133672   0.199366    \n",
       "\n",
       "      ratio_1_4  ratio_1_5  ratio_1_6  ratio_1_7  ratio_2_3  ratio_2_4  \\\n",
       "374   0.537248   0.476984   0.541406   0.357984   0.050060   0.402457    \n",
       "2388  0.415104   0.438567   0.498310   0.338834   0.083492   0.290377    \n",
       "3461  0.397797   0.374553   0.497120   0.247650   0.056642   0.282244    \n",
       "3662  0.546784   0.481563   0.652934   0.322340   0.013790   0.455877    \n",
       "83    0.490116   0.443726   0.549743   0.339055   0.067493   0.381434    \n",
       "\n",
       "      ratio_2_5  ratio_2_6  ratio_2_7  ratio_3_4  ratio_3_5  ratio_3_6  \\\n",
       "374   0.332265   0.407360   0.198213   0.359643   0.286978   0.364738    \n",
       "2388  0.316427   0.383599   0.206958   0.212026   0.239256   0.310036    \n",
       "3461  0.256910   0.392340   0.121395   0.229268   0.203226   0.343328    \n",
       "3662  0.382793   0.577503   0.209423   0.444883   0.370961   0.568238    \n",
       "83    0.329604   0.449072   0.215134   0.322237   0.268075   0.393505    \n",
       "\n",
       "      ratio_3_7  ratio_4_5  ratio_4_6  ratio_4_7  ratio_5_6  ratio_5_7  \\\n",
       "374   0.149637   0.081028   0.005864   0.221950   0.086851   0.143503    \n",
       "2388  0.125637   0.028686   0.104907   0.088753   0.076451   0.117141    \n",
       "3461  0.065202   0.027315   0.123806   0.166555   0.150611   0.139877    \n",
       "3662  0.196199   0.088533   0.165090   0.272466   0.249969   0.188480    \n",
       "83    0.149816   0.059283   0.081618   0.181167   0.140223   0.123207    \n",
       "\n",
       "      ratio_6_7  \n",
       "374   0.227518   \n",
       "2388  0.191873   \n",
       "3461  0.284495   \n",
       "3662  0.418722   \n",
       "83    0.258956   "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dmspols_2011</th>\n",
       "      <th>l7_2011_1</th>\n",
       "      <th>l7_2011_2</th>\n",
       "      <th>l7_2011_3</th>\n",
       "      <th>l7_2011_4</th>\n",
       "      <th>l7_2011_5</th>\n",
       "      <th>l7_2011_6</th>\n",
       "      <th>l7_2011_7</th>\n",
       "      <th>viirs_2012</th>\n",
       "      <th>uid</th>\n",
       "      <th>dmspols_2011_imputed</th>\n",
       "      <th>viirs_2012_imputed</th>\n",
       "      <th>ratio_1_2</th>\n",
       "      <th>ratio_1_3</th>\n",
       "      <th>ratio_1_4</th>\n",
       "      <th>ratio_1_5</th>\n",
       "      <th>ratio_1_6</th>\n",
       "      <th>ratio_1_7</th>\n",
       "      <th>ratio_2_3</th>\n",
       "      <th>ratio_2_4</th>\n",
       "      <th>ratio_2_5</th>\n",
       "      <th>ratio_2_6</th>\n",
       "      <th>ratio_2_7</th>\n",
       "      <th>ratio_3_4</th>\n",
       "      <th>ratio_3_5</th>\n",
       "      <th>ratio_3_6</th>\n",
       "      <th>ratio_3_7</th>\n",
       "      <th>ratio_4_5</th>\n",
       "      <th>ratio_4_6</th>\n",
       "      <th>ratio_4_7</th>\n",
       "      <th>ratio_5_6</th>\n",
       "      <th>ratio_5_7</th>\n",
       "      <th>ratio_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1067.911645</td>\n",
       "      <td>1347.568656</td>\n",
       "      <td>1496.182648</td>\n",
       "      <td>2448.161935</td>\n",
       "      <td>2328.447567</td>\n",
       "      <td>3004.758980</td>\n",
       "      <td>1737.813586</td>\n",
       "      <td>0.337368</td>\n",
       "      <td>34902063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115777</td>\n",
       "      <td>0.167026</td>\n",
       "      <td>0.392554</td>\n",
       "      <td>0.371143</td>\n",
       "      <td>0.475572</td>\n",
       "      <td>0.238762</td>\n",
       "      <td>0.052260</td>\n",
       "      <td>0.289956</td>\n",
       "      <td>0.266832</td>\n",
       "      <td>0.380760</td>\n",
       "      <td>0.126482</td>\n",
       "      <td>0.241353</td>\n",
       "      <td>0.217607</td>\n",
       "      <td>0.335169</td>\n",
       "      <td>0.074716</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>0.102073</td>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.126811</td>\n",
       "      <td>0.145252</td>\n",
       "      <td>0.267143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>909.066599</td>\n",
       "      <td>1054.835316</td>\n",
       "      <td>1108.651480</td>\n",
       "      <td>1493.869704</td>\n",
       "      <td>1341.081399</td>\n",
       "      <td>2903.133198</td>\n",
       "      <td>1080.304266</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>43301419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>0.098916</td>\n",
       "      <td>0.243370</td>\n",
       "      <td>0.191994</td>\n",
       "      <td>0.523075</td>\n",
       "      <td>0.086076</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.172258</td>\n",
       "      <td>0.119472</td>\n",
       "      <td>0.466981</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>0.148017</td>\n",
       "      <td>0.094880</td>\n",
       "      <td>0.447303</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.053895</td>\n",
       "      <td>0.320505</td>\n",
       "      <td>0.160659</td>\n",
       "      <td>0.368043</td>\n",
       "      <td>0.107697</td>\n",
       "      <td>0.457602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>7.666667</td>\n",
       "      <td>843.911082</td>\n",
       "      <td>1138.947636</td>\n",
       "      <td>1333.943429</td>\n",
       "      <td>2591.361184</td>\n",
       "      <td>2285.129243</td>\n",
       "      <td>3031.391065</td>\n",
       "      <td>1782.293734</td>\n",
       "      <td>0.276674</td>\n",
       "      <td>14502621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148794</td>\n",
       "      <td>0.225007</td>\n",
       "      <td>0.508679</td>\n",
       "      <td>0.460594</td>\n",
       "      <td>0.564467</td>\n",
       "      <td>0.357315</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.389355</td>\n",
       "      <td>0.334742</td>\n",
       "      <td>0.453787</td>\n",
       "      <td>0.220230</td>\n",
       "      <td>0.320336</td>\n",
       "      <td>0.262826</td>\n",
       "      <td>0.388847</td>\n",
       "      <td>0.143876</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.078259</td>\n",
       "      <td>0.184987</td>\n",
       "      <td>0.140367</td>\n",
       "      <td>0.123625</td>\n",
       "      <td>0.259489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1188.818870</td>\n",
       "      <td>1759.164822</td>\n",
       "      <td>2251.561736</td>\n",
       "      <td>3211.930984</td>\n",
       "      <td>3842.226267</td>\n",
       "      <td>3058.202097</td>\n",
       "      <td>3118.564065</td>\n",
       "      <td>0.925885</td>\n",
       "      <td>36901045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193470</td>\n",
       "      <td>0.308903</td>\n",
       "      <td>0.459720</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>0.440163</td>\n",
       "      <td>0.448009</td>\n",
       "      <td>0.122770</td>\n",
       "      <td>0.292243</td>\n",
       "      <td>0.371883</td>\n",
       "      <td>0.269657</td>\n",
       "      <td>0.278695</td>\n",
       "      <td>0.175779</td>\n",
       "      <td>0.261031</td>\n",
       "      <td>0.151916</td>\n",
       "      <td>0.161449</td>\n",
       "      <td>0.089351</td>\n",
       "      <td>0.024518</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>0.113620</td>\n",
       "      <td>0.103963</td>\n",
       "      <td>0.009772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1543.693146</td>\n",
       "      <td>2214.106303</td>\n",
       "      <td>2833.584665</td>\n",
       "      <td>3405.777374</td>\n",
       "      <td>4622.612692</td>\n",
       "      <td>3047.386146</td>\n",
       "      <td>3561.186030</td>\n",
       "      <td>0.158197</td>\n",
       "      <td>61200110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178406</td>\n",
       "      <td>0.294679</td>\n",
       "      <td>0.376219</td>\n",
       "      <td>0.499313</td>\n",
       "      <td>0.327525</td>\n",
       "      <td>0.395209</td>\n",
       "      <td>0.122725</td>\n",
       "      <td>0.212046</td>\n",
       "      <td>0.352290</td>\n",
       "      <td>0.158373</td>\n",
       "      <td>0.233249</td>\n",
       "      <td>0.091707</td>\n",
       "      <td>0.239938</td>\n",
       "      <td>0.036355</td>\n",
       "      <td>0.113781</td>\n",
       "      <td>0.151567</td>\n",
       "      <td>0.055537</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.205375</td>\n",
       "      <td>0.129699</td>\n",
       "      <td>0.077747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dmspols_2011    l7_2011_1    l7_2011_2    l7_2011_3    l7_2011_4  \\\n",
       "3145  6.000000      1067.911645  1347.568656  1496.182648  2448.161935   \n",
       "3888  0.000000      909.066599   1054.835316  1108.651480  1493.869704   \n",
       "1117  7.666667      843.911082   1138.947636  1333.943429  2591.361184   \n",
       "3348  10.000000     1188.818870  1759.164822  2251.561736  3211.930984   \n",
       "5245  2.000000      1543.693146  2214.106303  2833.584665  3405.777374   \n",
       "\n",
       "        l7_2011_5    l7_2011_6    l7_2011_7  viirs_2012       uid  \\\n",
       "3145  2328.447567  3004.758980  1737.813586  0.337368    34902063   \n",
       "3888  1341.081399  2903.133198  1080.304266  0.173900    43301419   \n",
       "1117  2285.129243  3031.391065  1782.293734  0.276674    14502621   \n",
       "3348  3842.226267  3058.202097  3118.564065  0.925885    36901045   \n",
       "5245  4622.612692  3047.386146  3561.186030  0.158197    61200110   \n",
       "\n",
       "      dmspols_2011_imputed  viirs_2012_imputed  ratio_1_2  ratio_1_3  \\\n",
       "3145  0                     0                   0.115777   0.167026    \n",
       "3888  0                     0                   0.074224   0.098916    \n",
       "1117  0                     0                   0.148794   0.225007    \n",
       "3348  0                     0                   0.193470   0.308903    \n",
       "5245  0                     0                   0.178406   0.294679    \n",
       "\n",
       "      ratio_1_4  ratio_1_5  ratio_1_6  ratio_1_7  ratio_2_3  ratio_2_4  \\\n",
       "3145  0.392554   0.371143   0.475572   0.238762   0.052260   0.289956    \n",
       "3888  0.243370   0.191994   0.523075   0.086076   0.024875   0.172258    \n",
       "1117  0.508679   0.460594   0.564467   0.357315   0.078853   0.389355    \n",
       "3348  0.459720   0.527407   0.440163   0.448009   0.122770   0.292243    \n",
       "5245  0.376219   0.499313   0.327525   0.395209   0.122725   0.212046    \n",
       "\n",
       "      ratio_2_5  ratio_2_6  ratio_2_7  ratio_3_4  ratio_3_5  ratio_3_6  \\\n",
       "3145  0.266832   0.380760   0.126482   0.241353   0.217607   0.335169    \n",
       "3888  0.119472   0.466981   0.011928   0.148017   0.094880   0.447303    \n",
       "1117  0.334742   0.453787   0.220230   0.320336   0.262826   0.388847    \n",
       "3348  0.371883   0.269657   0.278695   0.175779   0.261031   0.151916    \n",
       "5245  0.352290   0.158373   0.233249   0.091707   0.239938   0.036355    \n",
       "\n",
       "      ratio_3_7  ratio_4_5  ratio_4_6  ratio_4_7  ratio_5_6  ratio_5_7  \\\n",
       "3145  0.074716   0.025063   0.102073   0.169697   0.126811   0.145252    \n",
       "3888  0.012950   0.053895   0.320505   0.160659   0.368043   0.107697    \n",
       "1117  0.143876   0.062798   0.078259   0.184987   0.140367   0.123625    \n",
       "3348  0.161449   0.089351   0.024518   0.014749   0.113620   0.103963    \n",
       "5245  0.113781   0.151567   0.055537   0.022307   0.205375   0.129699    \n",
       "\n",
       "      ratio_6_7  \n",
       "3145  0.267143   \n",
       "3888  0.457602   \n",
       "1117  0.259489   \n",
       "3348  0.009772   \n",
       "5245  0.077747   "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check that lengths match\n",
    "print(len(x_train) == len(y_train))\n",
    "print(len(x_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define feature groups\n",
    "\n",
    "1. Daytime-only: Landsat 7 band data and computed indices\n",
    "2. Nighttime-only: DMSP and VIIRS data + imputed flags\n",
    "3. All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day-only: ['l7_2011_1', 'l7_2011_2', 'l7_2011_3', 'l7_2011_4', 'l7_2011_5', 'l7_2011_6', 'l7_2011_7', 'ratio_1_2', 'ratio_1_3', 'ratio_1_4', 'ratio_1_5', 'ratio_1_6', 'ratio_1_7', 'ratio_2_3', 'ratio_2_4', 'ratio_2_5', 'ratio_2_6', 'ratio_2_7', 'ratio_3_4', 'ratio_3_5', 'ratio_3_6', 'ratio_3_7', 'ratio_4_5', 'ratio_4_6', 'ratio_4_7', 'ratio_5_6', 'ratio_5_7', 'ratio_6_7']\n",
      "-----\n",
      "Night-only: ['dmspols_2011', 'viirs_2012', 'dmspols_2011_imputed', 'viirs_2012_imputed']\n"
     ]
    }
   ],
   "source": [
    "DAY_FEATURES = df.filter(regex='l7|ratio', axis=1).columns.tolist()\n",
    "NIGHT_FEATURES = ['dmspols_2011', 'viirs_2012', 'dmspols_2011_imputed', 'viirs_2012_imputed']\n",
    "ALL_FEATURES = df.columns.tolist()\n",
    "\n",
    "print(\"Day-only:\", DAY_FEATURES)\n",
    "print(\"-----\")\n",
    "print(\"Night-only:\", NIGHT_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pickle cleaned data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [x_train, x_test, y_train, y_test]\n",
    "\n",
    "output_path = os.path.join('output', 'final_data.pkl')\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(obj=clean_data,\n",
    "                file=f,\n",
    "                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Regressors\n",
    "\n",
    "### 5.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = x_test.append(x_train)\n",
    "y_all = y_test.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a TrainedRegressor object to hold key results information\n",
    "class TrainedRegressor:\n",
    "    \n",
    "    def __init__(self, method, params, features, regressor):\n",
    "        self.method = method\n",
    "        self.params = params\n",
    "        self.regressor = regressor\n",
    "        self.features = features\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Trained {self.method} on feature set {self.features} with params {self.params}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 1: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 2: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 3: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 4: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 5: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 6: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 7: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 8: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 1000.0, 'random_state': 0}\n",
      "Model 9: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 10: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 11: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 100.0, 'loss': 'epsilon_insensitive', 'max_iter': 100000.0, 'random_state': 0}\n",
      "Model 12: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 13: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 14: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 15: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 16: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 17: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 18: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 19: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 20: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 21: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 22: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 23: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 24: Training DecisionTreeClassifier on DAY_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 25: Training DecisionTreeClassifier on NIGHT_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 26: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 27: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 28: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 29: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 30: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 31: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 32: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 33: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 34: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 35: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 36: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 37: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 38: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 39: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 40: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 41: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 42: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 43: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 44: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 45: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 10000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 46: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 10000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 47: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 48: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 10000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 49: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 10000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 50: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 51: Training BaggingClassifier on DAY_FEATURES with params {'n_estimators': 10000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 52: Training BaggingClassifier on NIGHT_FEATURES with params {'n_estimators': 10000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 53: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "Model 54: Training GradientBoostingClassifier on DAY_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 55: Training GradientBoostingClassifier on NIGHT_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 56: Training GradientBoostingClassifier on ALL_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "Model 57: Training RandomForestClassifier on DAY_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 58: Training RandomForestClassifier on NIGHT_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 59: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 60: Training RandomForestClassifier on DAY_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 61: Training RandomForestClassifier on NIGHT_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 62: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 63: Training RandomForestClassifier on DAY_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 64: Training RandomForestClassifier on NIGHT_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "Model 65: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "# Use GRID_MAIN for full grid search\n",
    "# parameters = cf.GRID_TEST_CLASS\n",
    "parameters = GRID_TEST_CLASS\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df_all = pd.DataFrame()\n",
    "results_df_trainedonly_all = pd.DataFrame()\n",
    "\n",
    "x_trainedonly_all = x_all.copy()\n",
    "\n",
    "trained_list = []\n",
    "trained_list_all = []\n",
    "count = 0\n",
    "# print('Training model ', end='')\n",
    "for i in parameters['regressors']:\n",
    "    for j in parameters[i]:\n",
    "        for k in ('DAY_FEATURES', 'NIGHT_FEATURES', 'ALL_FEATURES'):\n",
    "        \n",
    "            print(f'Model {count}: Training {i} on {k} with params {str(j)}')\n",
    "\n",
    "            # A. Train ------------------------------------\n",
    "            # Initialize regressor, fit data, then append TrainedRegressor object to list\n",
    "            # 1. Train Data\n",
    "            regressor = eval(i)(**j)\n",
    "            trained = regressor.fit(x_train[eval(k)], y_train)\n",
    "            trained_list.append(TrainedRegressor(i, str(j), k, trained))\n",
    "\n",
    "            # 2. All Data\n",
    "            trained_all = regressor.fit(x_all[eval(k)], y_all)\n",
    "            trained_list_all.append(TrainedRegressor(i, str(j), k, trained_all))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # B. Results -------------------------------------\n",
    "            # 1. Trained Model on Test Data - - - - - - - - - -\n",
    "            pred_labels = trained_list[count].regressor.predict(x_test[eval(k)])\n",
    "\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list[count].method,\n",
    "                'features': trained_list[count].features,\n",
    "                'params': trained_list[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_test, y_pred=pred_labels)        \n",
    "            }\n",
    "    \n",
    "            results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            results_df.to_csv(\"/Users/robmarty/Desktop/pov_results.csv\")\n",
    "            \n",
    "            x_test['y_true'] = y_test\n",
    "            x_test['y_predict_' + str(count)] = pred_labels\n",
    "            x_test.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_traineddatamodel_testdatapredict.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 2. Trained All Model on All Data - - - - - - - - - -\n",
    "            pred_labels_all = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list_all[count].method,\n",
    "                'features': trained_list_all[count].features,\n",
    "                'params': trained_list_all[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_all)        \n",
    "            }\n",
    "    \n",
    "            results_df_all = results_df_all.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            results_df_all.to_csv(\"/Users/robmarty/Desktop/pov_results_all.csv\")\n",
    "\n",
    "            # ALL\n",
    "            x_trainedonly_all['y_true'] = y_all\n",
    "            x_trainedonly_all['y_predict_' + str(count)] = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "            x_trainedonly_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_alldatamodel_alldatapredict.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 3. Trained Model on All Data - - - - - - - - - -\n",
    "            pred_labels_trainedonly_all = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list[count].method,\n",
    "                'features': trained_list[count].features,\n",
    "                'params': trained_list[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_trainedonly_all)        \n",
    "            }\n",
    "    \n",
    "            results_df_trainedonly_all = results_df_trainedonly_all.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            results_df_trainedonly_all.to_csv(\"/Users/robmarty/Desktop/pov_results_trainedonly_all.csv\")\n",
    "\n",
    "            # ALL\n",
    "            x_all['y_true'] = y_all\n",
    "            x_all['y_predict_' + str(count)] = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "            x_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_testdatamodel_alldatapredict.csv'))\n",
    "\n",
    "            ####\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test\n",
    "#pred_labels\n",
    "#parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "for i in trained_list:\n",
    "    \n",
    "    # Get predicted results from test data\n",
    "    features = eval(i.features)\n",
    "    pred_labels = i.regressor.predict(x_test[features])\n",
    "    \n",
    "    # Append results to dataframe and sort by R^2\n",
    "    pred_dict = {\n",
    "        'regressor': i.method,\n",
    "        'features': i.features,\n",
    "        'params': i.params,\n",
    "        'r2': r2_score(y_true=y_test, y_pred=pred_labels)        \n",
    "    }\n",
    "    \n",
    "    results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "        .sort_values(by='r2', ascending=False, axis=0) \\\n",
    "        [['regressor', 'params', 'features', 'r2']]\n",
    "\n",
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
