{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict household income from satellite imagery data\n",
    "\n",
    "First pass.\n",
    "\n",
    "General ML pipeline steps:\n",
    "1. Import data\n",
    "2. Split data into test/train sets\n",
    "3. Preprocess test/train sets separately\n",
    "4. Generate features from data\n",
    "5. For each regressor-hyperparameter combination:\n",
    "    - Train regressor with given hyperparameters and training data and labels\n",
    "    - Generate predicted labels for test data with trained regressor\n",
    "    - Evaluate regressor-hyperparameter performance against actual test labels and get $R^2$\n",
    "6. Explore best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import configuration file\n",
    "import config as cf\n",
    "\n",
    "# Display options \n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = -1\n",
    "\n",
    "# Turn off big pink warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data file path \n",
    "final_data_file_path = \"/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/FinalData\"\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test grid to make sure everything works - limited models and parameters\n",
    "# 'BaggingClassifier'\n",
    "GRID_TEST_CLASS = {\n",
    "    'regressors': ['LinearSVC','SVC', 'DecisionTreeClassifier',\n",
    "                    'GradientBoostingClassifier', 'RandomForestClassifier'],\n",
    "    'LinearSVC': [\n",
    "        {'penalty': penalty, 'C': C, 'loss': loss, 'max_iter': max_iter,\n",
    "        'random_state': 0} \\\n",
    "        for penalty in ('l2', ) \\\n",
    "        for C in (1e-2,1,2) \\\n",
    "        for loss in ('epsilon_insensitive','squared_hinge', ) \\\n",
    "        for max_iter in (1e1, )\n",
    "    ],\n",
    "    'SVC': [\n",
    "        {'kernel': kernel, 'C': C, 'class_weight': class_weight,         \n",
    "        'random_state': 0} \\\n",
    "        for C in (1e-2,1,2) \\\n",
    "        for class_weight in c(None, 'balanced',)\n",
    "        for kernel in ('linear','poly','rbf','sigmoid', ) \\\n",
    "    ],\n",
    "    'DecisionTreeClassifier': [\n",
    "        {'criterion': criterion, 'splitter': splitter, 'max_depth': max_depth,\n",
    "        'max_features': max_features, 'random_state': 0} \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for splitter in ('best', ) \\\n",
    "        for max_depth in (1,2,3,4, 5, 10, 20, 30, 50, 70, 100, ) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ],\n",
    "    #'BaggingClassifier': [\n",
    "    #    {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "    #    'random_state': 0, 'n_jobs': -1} \\\n",
    "    #    for n_estimators in (10, 100, 1000,) \\\n",
    "    #    for max_features in (0.1, 0.2, 0.3,0.4, 0.5, 1.0,)\n",
    "    #],\n",
    "    'RandomForestClassifier': [\n",
    "        {'n_estimators': n_estimators, 'criterion': criterion,\n",
    "        'max_depth': max_depth, 'max_features': max_features, 'n_jobs': -1,\n",
    "        'random_state': 0} \\\n",
    "        for n_estimators in (5, 10, 100, 1000, 5000) \\\n",
    "        for criterion in ('gini', ) \\\n",
    "        for max_depth in (1,2,3,4,5,6,7,8,9,10, ) \\\n",
    "        for max_features in ('sqrt','log2',None, )\n",
    "    ],\n",
    "    'GradientBoostingClassifier': [\n",
    "        {'loss': loss, 'learning_rate': rate, 'n_estimators': n_estimators,\n",
    "        'criterion': criterion, 'max_features': max_features,\n",
    "        'random_state': 0} \\\n",
    "        for loss in ('deviance', ) \\\n",
    "        for rate in (1e-4, )\n",
    "        for n_estimators in (100, ) \\\n",
    "        for criterion in ('friedman_mse', ) \\\n",
    "        for max_features in ('sqrt', ) \\\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data and drop \"future\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predict Changes\n",
    "#DATA_PATH = os.path.join(final_data_file_path, 'BISP','Merged Datasets', 'bisp_socioeconomic_satellite_firstdiff_r13.csv')\n",
    "#DATA_PATH = os.path.join('/Users/robmarty/Desktop/', 'bisp_socioeconomic_satellite_firstdiff_r13.csv')\n",
    "\n",
    "#### Predict Levels\n",
    "DATA_PATH = os.path.join(final_data_file_path, 'BISP','Merged Datasets', 'bisp_socioeconomic_satellite_panel_full_satPovNAsRemoved.csv')\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['pscores_poor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Changes\n",
    "#df['pscores_bin'] = df['pscores'] < 0\n",
    "\n",
    "#### Levels\n",
    "#df = df.loc[df['survey_round'] != 1]\n",
    "#df['pscores_bin'] = df['pscores'] <= 16.17\n",
    "df['pscores_bin'] = df['pscores_poor']\n",
    "\n",
    "# DV as Quantiles\n",
    "#df['pscores_2011'] = pd.qcut(df['pscores_2011'], 3, labels=False)\n",
    "#df['pscores_2011'].value_counts()\n",
    "#df['pscores_bin'] = df['pscores'] < 0\n",
    "\n",
    "df.pscores_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Restrict to Year\n",
    "df = df[df['year'] == 2013]\n",
    "df.pscores_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Select Columns\n",
    "df_viirs = df.filter(regex='viirs').filter(regex='_2km')\n",
    "df_landsat = df.filter(regex='^b').filter(regex='_1km')\n",
    "df_osm = df.filter(regex='fclass').filter(regex='meters')\n",
    "df_facebook = df.filter(regex='au$')\n",
    "\n",
    "df_y = df.filter(regex='^pscores_bin$')\n",
    "\n",
    "df_all = df_y.join(df_viirs).join(df_landsat).join(df_osm).join(df_facebook)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns where the label is missing\n",
    "#df = df.loc[~pd.isnull(df['hhinc_2011'])]\n",
    "\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'pscores_bin'\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Separate feature sets from label sets\n",
    "x_df = df_all.drop(labels=[LABEL], axis=1)\n",
    "y_df = df_all[LABEL]\n",
    "\n",
    "# Split into test and train sets for features and labels\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x_df, y_df, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False    2300\n",
      "True     1194\n",
      "Name: pscores_bin, dtype: int64\n",
      "False    615\n",
      "True     259\n",
      "Name: pscores_bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train.head()\n",
    "x_test.head()\n",
    "\n",
    "# check that lengths match\n",
    "print(len(x_train) == len(y_train))\n",
    "print(len(x_test) == len(y_test))\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_FEATURES = df_all.filter(regex='^b', axis=1).columns.tolist()\n",
    "NIGHT_FEATURES = df_all.filter(regex='viirs', axis=1).columns.tolist()\n",
    "SATELLITE_FEATURES = df_all.filter(regex='^b|viirs').columns.tolist()\n",
    "NONSATELLITE_FEATURES = df_all.filter(regex='dist_osm|estimate_').columns.tolist()\n",
    "ALL_FEATURES = x_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate Regressors\n",
    "\n",
    "### 5.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = x_test.append(x_train)\n",
    "y_all = y_test.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a TrainedRegressor object to hold key results information\n",
    "class TrainedRegressor:\n",
    "    \n",
    "    def __init__(self, method, params, features, regressor):\n",
    "        self.method = method\n",
    "        self.params = params\n",
    "        self.regressor = regressor\n",
    "        self.features = features\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Trained {self.method} on feature set {self.features} with params {self.params}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 1: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 2: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 3: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 4: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 5: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 6: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 7: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 8: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 9: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 10: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 11: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 12: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 13: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 14: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 15: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 16: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 17: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 18: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 19: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 20: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 21: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 22: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 23: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 24: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 25: Training LinearSVC on DAY_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 26: Training LinearSVC on NIGHT_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 27: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 28: Training LinearSVC on SATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 29: Training LinearSVC on NONSATELLITE_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "Model 30: Training SVC on DAY_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'random_state': 0}\n",
      "Model 31: Training SVC on NIGHT_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'random_state': 0}\n",
      "Model 32: Training SVC on ALL_FEATURES with params {'kernel': 'linear', 'C': 0.01, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "# Use GRID_MAIN for full grid search\n",
    "# parameters = cf.GRID_TEST_CLASS\n",
    "parameters = GRID_TEST_CLASS\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "results_df_all = pd.DataFrame()\n",
    "results_df_trainedonly_all = pd.DataFrame()\n",
    "\n",
    "x_trainedonly_all = x_all.copy()\n",
    "\n",
    "trained_list = []\n",
    "trained_list_all = []\n",
    "count = 0\n",
    "# print('Training model ', end='')\n",
    "for i in parameters['regressors']:\n",
    "    for j in parameters[i]:\n",
    "        for k in ('DAY_FEATURES', 'NIGHT_FEATURES', 'ALL_FEATURES', 'SATELLITE_FEATURES', 'NONSATELLITE_FEATURES'):\n",
    "        \n",
    "            print(f'Model {count}: Training {i} on {k} with params {str(j)}')\n",
    "\n",
    "            # A. Train Models --------------------------\n",
    "            regressor = eval(i)(**j)\n",
    "            \n",
    "            trained = regressor.fit(x_train[eval(k)], y_train)\n",
    "            trained_list.append(TrainedRegressor(i, str(j), k, trained))\n",
    "            \n",
    "            # B. Results -------------------------------------\n",
    "            pred_labels = trained_list[count].regressor.predict(x_test[eval(k)])\n",
    "\n",
    "            pred_dict = {\n",
    "                'regressor': trained_list[count].method,\n",
    "                'features': trained_list[count].features,\n",
    "                'params': trained_list[count].params,\n",
    "                'accuracy_score': accuracy_score(y_true=y_test, y_pred=pred_labels),\n",
    "                'average_precision_score': average_precision_score(y_test, pred_labels),\n",
    "                'recall_score': recall_score(y_test, pred_labels)\n",
    "            }\n",
    "    \n",
    "            results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "                .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "                [['regressor', 'params', 'features', 'accuracy_score','average_precision_score',\n",
    "                 'recall_score']]\n",
    "        \n",
    "            results_df.to_csv(\"/Users/robmarty/Desktop/pov_results_r13.csv\")\n",
    "            \n",
    "            x_test['y_true'] = y_test\n",
    "            x_test['y_predict_' + str(count)] = pred_labels\n",
    "            #x_test.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_traineddatamodel_testdatapredict_r13.csv'))\n",
    "            x_test.to_csv(os.path.join('/Users/robmarty/Desktop', 'pov_opm_data_with_predictions.csv'))\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "  \n",
    "            # A. Train ------------------------------------\n",
    "            # Initialize regressor, fit data, then append TrainedRegressor object to list\n",
    "            # 1. Train Data\n",
    "            #regressor = eval(i)(**j)\n",
    "            #trained = regressor.fit(x_train[eval(k)], y_train)\n",
    "            #trained_list.append(TrainedRegressor(i, str(j), k, trained))\n",
    "\n",
    "            # 2. All Data\n",
    "            #trained_all = trained\n",
    "            #trained_list_all = trained_list\n",
    "\n",
    "            \n",
    "            #trained_all = regressor.fit(x_all[eval(k)], y_all)\n",
    "            #trained_list_all.append(TrainedRegressor(i, str(j), k, trained_all))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # B. Results -------------------------------------\n",
    "            # 1. Trained Model on Test Data - - - - - - - - - -\n",
    "            #pred_labels = trained_list[count].regressor.predict(x_test[eval(k)])\n",
    "\n",
    "            #pred_dict = {\n",
    "            #    'regressor': trained_list[count].method,\n",
    "            #    'features': trained_list[count].features,\n",
    "            #    'params': trained_list[count].params,\n",
    "            #    'accuracy_score': accuracy_score(y_true=y_test, y_pred=pred_labels)        \n",
    "            #}\n",
    "    \n",
    "            #results_df = results_df.append(pred_dict, ignore_index=True) \\\n",
    "            #    .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "            #    [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            #results_df.to_csv(\"/Users/robmarty/Desktop/pov_results_r13.csv\")\n",
    "            \n",
    "            #x_test['y_true'] = y_test\n",
    "            #x_test['y_predict_' + str(count)] = pred_labels\n",
    "            #x_test.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_traineddatamodel_testdatapredict_r13.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 2. Trained All Model on All Data - - - - - - - - - -\n",
    "            #pred_labels_all = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            #pred_dict = {\n",
    "            #    'regressor': trained_list_all[count].method,\n",
    "            #    'features': trained_list_all[count].features,\n",
    "            #    'params': trained_list_all[count].params,\n",
    "            #    'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_all)        \n",
    "            #}\n",
    "    \n",
    "            #results_df_all = results_df_all.append(pred_dict, ignore_index=True) \\\n",
    "            #    .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "            #    [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            #results_df_all.to_csv(\"/Users/robmarty/Desktop/pov_results_all_r13.csv\")\n",
    "\n",
    "            # ALL\n",
    "            #x_trainedonly_all['y_true'] = y_all\n",
    "            #x_trainedonly_all['y_predict_' + str(count)] = trained_list_all[count].regressor.predict(x_all[eval(k)])\n",
    "            #x_trainedonly_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_alldatamodel_alldatapredict_r13.csv'))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # 3. Trained Model on All Data - - - - - - - - - -\n",
    "            #pred_labels_trainedonly_all = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "\n",
    "            # Append results to dataframe and sort by R^2\n",
    "            #pred_dict = {\n",
    "            #    'regressor': trained_list[count].method,\n",
    "            #    'features': trained_list[count].features,\n",
    "            #    'params': trained_list[count].params,\n",
    "            #    'accuracy_score': accuracy_score(y_true=y_all, y_pred=pred_labels_trainedonly_all)        \n",
    "            #}\n",
    "    \n",
    "            #results_df_trainedonly_all = results_df_trainedonly_all.append(pred_dict, ignore_index=True) \\\n",
    "            #    .sort_values(by='accuracy_score', ascending=False, axis=0) \\\n",
    "            #    [['regressor', 'params', 'features', 'accuracy_score']]\n",
    "        \n",
    "            #results_df_trainedonly_all.to_csv(\"/Users/robmarty/Desktop/pov_results_trainedonly_all_r13.csv\")\n",
    "\n",
    "            # ALL\n",
    "            #x_all['y_true'] = y_all\n",
    "            #x_all['y_predict_' + str(count)] = trained_list[count].regressor.predict(x_all[eval(k)])\n",
    "            #x_all.to_csv(os.path.join(final_data_file_path, 'Data with Predicted Income', 'pov_opm_data_with_predictions_testdatamodel_alldatapredict_r13.csv'))\n",
    "\n",
    "            ####\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
